{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5385279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecde9019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BIT\\Desktop\\mmr\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa1d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!uv pip list | grep -i moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5813f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video_path: str, output_dir: str = \"../data/raw/\", output_ext='.wav'):\n",
    "    \"\"\"\n",
    "    Extracts audio from the video and saves it as a WAV file. \n",
    "    \"\"\"\n",
    "    # create the output directory if it does not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # generate the file name\n",
    "    filename = os.path.basename(video_path).split('.')[0]\n",
    "    output_path = os.path.join(output_dir, f'{filename}{output_ext}')\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Audio already exists at : {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    try:\n",
    "        video_clip = VideoFileClip(video_path)\n",
    "        \n",
    "        if video_clip.audio is None:\n",
    "            print(\"Error: This video has no sound\")\n",
    "            return None\n",
    "        \n",
    "        video_clip.audio.write_audiofile(output_path, logger='bar')\n",
    "        video_clip.close()\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2396a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = extract_audio(video_path=\"../data/raw/Interview_2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660c5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"../data/raw/Interview_2.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd542a7",
   "metadata": {},
   "source": [
    "## Feature Engineering for Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e26379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b3299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(\"../data/raw/Interview_1.wav\", sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72638eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43538b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15259922,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3afb0b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd7e3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.767166288737718"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]/(sr*60) # this should give the duration of the visdeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d59adcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_layers(audio_path: str, segment_length: float=0.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        audio_path: path to the audio file\n",
    "        segment_length: time window in secs (same as video dataframe)\n",
    "    Output:\n",
    "        au_data: dataframe with TS features for analysis (Ready to go to the data analysis pipeline)\n",
    "    \"\"\"\n",
    "    # check is the audio file exists\n",
    "    if not os.path.exists(audio_path):\n",
    "        print(f\"Error: {audio_path} does not exit\")\n",
    "        return None\n",
    "    \n",
    "    # loading audio file\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    \n",
    "    # total duration\n",
    "    total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "    \n",
    "    au_data = []\n",
    "    \n",
    "    # iterating through the audio chunks\n",
    "    for t in np.arange(0, total_duration, segment_length):\n",
    "        \n",
    "        # calculating the starting and ending indexes for this chunk\n",
    "        start_sample = int(t * sr)\n",
    "        end_sample = int((t + segment_length)*sr)\n",
    "        \n",
    "        # getting the chunk for this iteration\n",
    "        chunk = y[start_sample:end_sample]\n",
    "        \n",
    "        # check if the file ended\n",
    "        if len(chunk) == 0: break\n",
    "        \n",
    "        # FEATURE - 1: AMPLITUDE (Confidence/Volume)\n",
    "        rms = np.mean(librosa.feature.rms(y=chunk))\n",
    "        \n",
    "        # FEATURE - 2: SILENCE DETECTION\n",
    "        # Threshold: 0.005 is a standard \"noise floor\" for webcams\n",
    "        is_silent = rms < 0.005\n",
    "        \n",
    "        # FEATURE 3 & 4: PITCH TRACKING (Monotone vs Expressive)\n",
    "        avg_pitch = 0\n",
    "        pitch_var = 0\n",
    "        \n",
    "        # if not silent\n",
    "        if not is_silent:\n",
    "            f0, voiced_flag, _ = librosa.pyin(\n",
    "                chunk,\n",
    "                fmin=librosa.note_to_hz('C2'),\n",
    "                fmax=librosa.note_to_hz('C5'),\n",
    "                sr=sr,\n",
    "                frame_length=2048\n",
    "            )\n",
    "            \n",
    "            # filtering out the NaNs (moments of unvoiced sound)\n",
    "            valid_pitch = f0[~np.isnan(f0)]\n",
    "            \n",
    "            if len(valid_pitch) > 0:\n",
    "                avg_pitch = np.mean(valid_pitch)\n",
    "                # I think this is super cool this pitch var effectively measures you expressiveness\n",
    "                pitch_var = np.std(valid_pitch) \n",
    "                \n",
    "        # creating the row\n",
    "        au_data.append({\n",
    "            \"Time\": round(t, 2),\n",
    "            \"audio_rms(volumn)\": round(rms, 4),\n",
    "            \"audio_pitch_avg\": round(avg_pitch, 2),\n",
    "            \"audio_pitch_var(expressiveness)\": round(pitch_var, 2),\n",
    "            \"is_silent\": is_silent\n",
    "        })\n",
    "        \n",
    "    # converting into a dataframe\n",
    "    au_data = pd.DataFrame(au_data)\n",
    "    au_data = au_data.sort_values('Time').reset_index(drop=True)\n",
    "    \n",
    "    return au_data\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22acbc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_audio_layers(audio_path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c831b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>audio_rms(volumn)</th>\n",
       "      <th>audio_pitch_avg</th>\n",
       "      <th>audio_pitch_var(expressiveness)</th>\n",
       "      <th>is_silent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>169.25</td>\n",
       "      <td>11.45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>179.94</td>\n",
       "      <td>14.03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>237.84</td>\n",
       "      <td>56.17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>220.10</td>\n",
       "      <td>60.33</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>388.20</td>\n",
       "      <td>7.03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>220.93</td>\n",
       "      <td>24.25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>247.08</td>\n",
       "      <td>31.90</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>243.60</td>\n",
       "      <td>65.59</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time  audio_rms(volumn)  audio_pitch_avg  audio_pitch_var(expressiveness)  \\\n",
       "0   0.0             0.0373             0.00                             0.00   \n",
       "1   0.5             0.0533           169.25                            11.45   \n",
       "2   1.0             0.0006             0.00                             0.00   \n",
       "3   1.5             0.0593           179.94                            14.03   \n",
       "4   2.0             0.0646           237.84                            56.17   \n",
       "5   2.5             0.0497           220.10                            60.33   \n",
       "6   3.0             0.0114           388.20                             7.03   \n",
       "7   3.5             0.0705           220.93                            24.25   \n",
       "8   4.0             0.0591           247.08                            31.90   \n",
       "9   4.5             0.0461           243.60                            65.59   \n",
       "\n",
       "   is_silent  \n",
       "0      False  \n",
       "1      False  \n",
       "2       True  \n",
       "3      False  \n",
       "4      False  \n",
       "5      False  \n",
       "6      False  \n",
       "7      False  \n",
       "8      False  \n",
       "9      False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe0dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/technical_data/Interview_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b52b239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>audio_rms(volumn)</th>\n",
       "      <th>audio_pitch_avg</th>\n",
       "      <th>audio_pitch_var(expressiveness)</th>\n",
       "      <th>is_silent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>629.5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>630.0</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>318.96</td>\n",
       "      <td>73.03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>630.5</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>274.32</td>\n",
       "      <td>2.10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>631.0</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>270.77</td>\n",
       "      <td>9.63</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>631.5</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>337.66</td>\n",
       "      <td>48.11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  audio_rms(volumn)  audio_pitch_avg  \\\n",
       "1259  629.5             0.0014             0.00   \n",
       "1260  630.0             0.0991           318.96   \n",
       "1261  630.5             0.0959           274.32   \n",
       "1262  631.0             0.1130           270.77   \n",
       "1263  631.5             0.0675           337.66   \n",
       "\n",
       "      audio_pitch_var(expressiveness)  is_silent  \n",
       "1259                             0.00       True  \n",
       "1260                            73.03      False  \n",
       "1261                             2.10      False  \n",
       "1262                             9.63      False  \n",
       "1263                            48.11      False  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7892640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to the system path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(\"Added project root to the system path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dbcf6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\BIT\\\\Desktop\\\\mmr\\\\notebooks'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.plot_graphs import plot_beautiful\n",
    "\n",
    "plot_beautiful(x=df['Time'], y=df['audio_rms(volumn)'], title=\"audio_rms(volumn)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cca439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beautiful(x=df['Time'], y=df['audio_pitch_var(expressiveness)'], title=\"audio_pitch_var(expressiveness)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15fc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beautiful(x=df['Time'], y=df['audio_pitch_avg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce4a4e",
   "metadata": {},
   "source": [
    "## Trying to Build the 3rd layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model\n",
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio = whisper.load_audio(file=\"../data/raw/Interview_1.wav\")\n",
    "# trim_audio = whisper.pad_or_trim(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel = whisper.log_mel_spectrogram(trim_audio, n_mels=model.dims.n_mels).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb94089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detecting the language\n",
    "# _, probs = model.detect_language(mel)\n",
    "# print(f\"Detected language: {max(probs, key=probs.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # decoding the audio\n",
    "# options = whisper.DecodingOptions()\n",
    "# result = whisper.decode(model, mel=mel, options=options)\n",
    "# print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(audio=\"../data/raw/Interview_1.wav\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83980215",
   "metadata": {},
   "source": [
    "## Using Another version of whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea91401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper_timestamped as wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a001c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = wp.load_audio(file=audio_path)\n",
    "model = wp.load_model('small', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a347c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63183/63183 [06:40<00:00, 157.61frames/s]\n"
     ]
    }
   ],
   "source": [
    "result = wp.transcribe_timestamped(\n",
    "    model=model,\n",
    "    audio=audio,\n",
    "    language=None,\n",
    "    detect_disfluencies=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9e21f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" We're starting now. So welcome to the interview. Let's begin with a simple question. Can you tell me a little bit about your background and what got you interested in ML engineering? Yeah, so right now I'm in third year of my college. I mean, I'm going to be in the sixth semester, but yeah, from the start of my college, I think from my second semester towards the end of it, I got interested in like machine learning. I got to know about machine learning from some channels, from YouTube channels and all. And I thought, yeah, it is an interesting field. I got to know some things about it. I took a course, a very famous course from Andrew Ng, which is ML specialization course, which is on course era. So in the break, in the summer break, which I've got in the college, I actually completed that course. And actually I was very intrigued by how like we do all this stuff, what we do in the like machine learning field, right? So it was very interesting. And like after that, I was just doing some courses, then I got into deep learning. I then got into some NLP. I like, I learned NLP or like Transformers about all these things from some YouTube channel from a very famous guy called like Andrej Karpathy, his famous, famous playlist on neural networks. That was amazing. So I built, I tried like I did some projects, I got into some hackathons with my friends and all, we worked on some ideas and all. So yeah, that was pretty amazing. And that got me into this journey on ML and then DL and JNAI stuff. And that's how I thought that, yeah, this is the field for me. I'm very interested in this field. I like, I, I like it is amazing what we do. And I saw the possibilities that what we can build from this ever growing field, right? So that's why I like choose this field. And that's why I'm in front of interviewing for this role here. That's a great background. And it's always awesome to hear how those initial courses and projects really hooked you in. Now, let me dive a bit deeper into the technical side. So for the next question, imagine you're working on a machine learning project where you have a data set that isn't perfectly clean. How would you go about handling missing data or noisy data in that data set before you actually train your model? Yeah, so handling or cleaning the data set is obviously one of the major parts of any, any ML project or whatever I'm doing. But it really depends on what type of data I'm working with. Right. So for some data, actually missing data might be a new info. So you don't, you can't do like you, you don't have to remove it. But for some, for some like field or for some data, you actually have to remove it. And it also depends on what algorithm I'm using. Right. So if I'm, if I'm using, for example, for example, if I'm using linear regression, you, you don't want these like NAN values in your data set. So you, what we can do is what we can simply fill them up with the mean values or like mode values. But those are not always the right choices. Right. And you can like, there are many like choices here about how, how would you clean the data? And if the, if the data is like, if the data is what, if the data is like time series data, right? If the data is time series data, then you can fill the, fill the NAN values with only the previous, previous time period value. Right. This is also a way or if you, like, so there are multiple ways. And if you want one single answer, it is a bit difficult to give one because it highly depends on which model are you using and what type of data you have got and what the data is related to which field. Right. So there are multiple types of data, cross-sectional data and panel data. So it highly depends on what type of data you are working with, which model are we trying to use. And accordingly, I'll try to like clean the data. Yeah. Absolutely. That makes a lot of sense. And I think you nailed it. It's all about the context of the data and the model you're using. There's definitely no one size fits all solution. So your approach of considering the type of data and the algorithm is spot on. All right. Let's move on to another question. Suppose you're working on a project where you need to evaluate how well your ML model is performing. Could you walk me through how you would choose evaluation metrics and what metrics you might consider depending on the type of problem? Yeah. So this also depends on what, like, on what type of data or what type of application I'm working with. So for example, the most common one. So most common one, you can say, for example, like some regression tasks. So you are actually predict predicting some actual value about what actual value that variable could be. So for example, for housing crisis, for example, you are making a model that predicts the housing crisis given some features, right? So what you do to like evaluate how well your model is performing, a simple metric is that like a simple matrix is that that we do is like we could like we calculate the cost and cost is nothing but cumulated errors, right? But that is not a very like good metric because initially, when we got the data, we like split the data into two parts. We got the training data, not two parts, it actually it is three parts. So the training data, the dev data and then the test data, right? So the best way to like evaluate it, evaluate the model you are working with is to like first define these like metrics, these cost. So for example, root mean square cost, right? So it measures the overall error. I'm talking about the regression task. So in this case, what you do is that what we do while we are choosing the model, we try different models and we train the model. And on the training set, we try to minimize the cost as much as we can, right? But the problem here is the training cost error, if it is minimized, if it is too much minimized, then there is chances of overfitting. Then we test it in from the test data. And here is the thing in the test data, you want the data in the test should be a production quality data. I mean, the data on which the model is going to be on which the model is going to work on. So in the actual production, what kind of data you will get and what kind of data you are expecting the model to do well on, right? You will put that data into the test data. So test it and you will check the errors or root mean square error, how much error is the model giving on that set. So that is how you'll know that how well the model is generalized, right? So this is the in the case of regression task. For example, you get classification task. In the case of classification task, it is very tough, not very tough, but the thing is you can't just check if it is correct or non-correct, right? Because if the data set is skewed, so you know the 70% of the data is like it is a classification task. So for example, you are testing if the patient has a heart disease or not. And the data set actually has 70% patients which have like diseases and they have a heart disease. So if the model just predicts all two, if the model just predicts that all have heart disease, still it gets 70% accuracy, right? So we don't want that. So here what we do is that we calculate this confusion matrix and what this confusion matrix gives us is that we what we do is that we calculate false positive, like false negatives, true positive, true negatives and then we calculate recall, precision and F1 score. So recall, precision, these are very like important metrics, especially for the classification tasks and they actually tell you, precision tells you how much like how much correct answer it gives for the answer which were actually correct, correct, right? So these are some of the matrix that I would use and they are all like there are also multiple matrix, new matrix for multiple applications. You can actually, if I if I'm like for certain applications, I can also like go through or custom like I'll try to create some custom matrix like matrix not like matrix on which I'll test the system. So it also highly depends on what type of application I'm working with here and what type of model I'm working with here. Absolutely and that's a fantastic breakdown. You're spot on that the choice of evaluation metrics really depends on the type of problem you're tackling, whether it's regression, classification or something else. And it's great that you brought up things like the confusion matrix, precision, recall, those are super critical in classification. And like you said, for regression, you might go with something like RMSE or MAE, but it all depends on what you're trying to measure and how you want to balance things like bias and variance. So yeah, that's a really solid approach.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': np.float64(0.0),\n",
       "   'end': np.float64(5.69),\n",
       "   'text': \" We're starting now. So welcome to the interview. Let's begin with a simple question. Can you tell\",\n",
       "   'tokens': [50364,\n",
       "    492,\n",
       "    434,\n",
       "    2891,\n",
       "    586,\n",
       "    13,\n",
       "    407,\n",
       "    2928,\n",
       "    281,\n",
       "    264,\n",
       "    4049,\n",
       "    13,\n",
       "    961,\n",
       "    311,\n",
       "    1841,\n",
       "    365,\n",
       "    257,\n",
       "    2199,\n",
       "    1168,\n",
       "    13,\n",
       "    1664,\n",
       "    291,\n",
       "    980,\n",
       "    50648],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14936956425303036,\n",
       "   'compression_ratio': 1.5732217573221758,\n",
       "   'no_speech_prob': 0.10543079674243927,\n",
       "   'confidence': 0.837,\n",
       "   'words': [{'text': \"We're\",\n",
       "     'start': np.float64(0.0),\n",
       "     'end': np.float64(0.32),\n",
       "     'confidence': 0.483},\n",
       "    {'text': 'starting',\n",
       "     'start': np.float64(0.32),\n",
       "     'end': np.float64(0.62),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'now.',\n",
       "     'start': np.float64(0.62),\n",
       "     'end': np.float64(0.94),\n",
       "     'confidence': 0.993},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(0.94),\n",
       "     'end': np.float64(1.72),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(1.72),\n",
       "     'end': np.float64(1.76),\n",
       "     'confidence': 0.708},\n",
       "    {'text': 'welcome',\n",
       "     'start': np.float64(1.76),\n",
       "     'end': np.float64(2.18),\n",
       "     'confidence': 0.815},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(2.18),\n",
       "     'end': np.float64(2.38),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(2.38),\n",
       "     'end': np.float64(2.5),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'interview.',\n",
       "     'start': np.float64(2.5),\n",
       "     'end': np.float64(2.86),\n",
       "     'confidence': 0.98},\n",
       "    {'text': \"Let's\",\n",
       "     'start': np.float64(3.08),\n",
       "     'end': np.float64(3.68),\n",
       "     'confidence': 0.906},\n",
       "    {'text': 'begin',\n",
       "     'start': np.float64(3.68),\n",
       "     'end': np.float64(3.9),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'with',\n",
       "     'start': np.float64(3.9),\n",
       "     'end': np.float64(4.08),\n",
       "     'confidence': 0.935},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(4.08),\n",
       "     'end': np.float64(4.2),\n",
       "     'confidence': 0.932},\n",
       "    {'text': 'simple',\n",
       "     'start': np.float64(4.2),\n",
       "     'end': np.float64(4.42),\n",
       "     'confidence': 0.951},\n",
       "    {'text': 'question.',\n",
       "     'start': np.float64(4.42),\n",
       "     'end': np.float64(4.84),\n",
       "     'confidence': 0.831},\n",
       "    {'text': 'Can',\n",
       "     'start': np.float64(5.1),\n",
       "     'end': np.float64(5.46),\n",
       "     'confidence': 0.698},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(5.46),\n",
       "     'end': np.float64(5.56),\n",
       "     'confidence': 0.943},\n",
       "    {'text': 'tell',\n",
       "     'start': np.float64(5.56),\n",
       "     'end': np.float64(5.69),\n",
       "     'confidence': 0.716}]},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': np.float64(5.69),\n",
       "   'end': np.float64(9.36),\n",
       "   'text': ' me a little bit about your background and what got you interested in ML engineering?',\n",
       "   'tokens': [50648,\n",
       "    385,\n",
       "    257,\n",
       "    707,\n",
       "    857,\n",
       "    466,\n",
       "    428,\n",
       "    3678,\n",
       "    293,\n",
       "    437,\n",
       "    658,\n",
       "    291,\n",
       "    3102,\n",
       "    294,\n",
       "    21601,\n",
       "    7043,\n",
       "    30,\n",
       "    50840],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14936956425303036,\n",
       "   'compression_ratio': 1.5732217573221758,\n",
       "   'no_speech_prob': 0.10543079674243927,\n",
       "   'confidence': 0.973,\n",
       "   'words': [{'text': 'me',\n",
       "     'start': np.float64(5.69),\n",
       "     'end': np.float64(5.86),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(5.86),\n",
       "     'end': np.float64(5.96),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'little',\n",
       "     'start': np.float64(5.96),\n",
       "     'end': np.float64(6.08),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'bit',\n",
       "     'start': np.float64(6.08),\n",
       "     'end': np.float64(6.26),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(6.26),\n",
       "     'end': np.float64(6.42),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'your',\n",
       "     'start': np.float64(6.42),\n",
       "     'end': np.float64(6.62),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'background',\n",
       "     'start': np.float64(6.62),\n",
       "     'end': np.float64(6.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(6.98),\n",
       "     'end': np.float64(7.36),\n",
       "     'confidence': 0.925},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(7.36),\n",
       "     'end': np.float64(7.6),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(7.6),\n",
       "     'end': np.float64(7.8),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(7.8),\n",
       "     'end': np.float64(7.96),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'interested',\n",
       "     'start': np.float64(7.96),\n",
       "     'end': np.float64(8.36),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(8.36),\n",
       "     'end': np.float64(8.66),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'ML',\n",
       "     'start': np.float64(8.66),\n",
       "     'end': np.float64(8.96),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'engineering?',\n",
       "     'start': np.float64(8.96),\n",
       "     'end': np.float64(9.36),\n",
       "     'confidence': 0.745}]},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': np.float64(11.18),\n",
       "   'end': np.float64(18.06),\n",
       "   'text': \" Yeah, so right now I'm in third year of my college. I mean, I'm going to be in the sixth semester,\",\n",
       "   'tokens': [50916,\n",
       "    865,\n",
       "    11,\n",
       "    370,\n",
       "    558,\n",
       "    586,\n",
       "    286,\n",
       "    478,\n",
       "    294,\n",
       "    2636,\n",
       "    1064,\n",
       "    295,\n",
       "    452,\n",
       "    3859,\n",
       "    13,\n",
       "    286,\n",
       "    914,\n",
       "    11,\n",
       "    286,\n",
       "    478,\n",
       "    516,\n",
       "    281,\n",
       "    312,\n",
       "    294,\n",
       "    264,\n",
       "    15102,\n",
       "    11894,\n",
       "    11,\n",
       "    51272],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14936956425303036,\n",
       "   'compression_ratio': 1.5732217573221758,\n",
       "   'no_speech_prob': 0.10543079674243927,\n",
       "   'confidence': 0.887,\n",
       "   'words': [{'text': 'Yeah,',\n",
       "     'start': np.float64(11.18),\n",
       "     'end': np.float64(11.36),\n",
       "     'confidence': 0.974},\n",
       "    {'text': 'so',\n",
       "     'start': np.float64(11.48),\n",
       "     'end': np.float64(11.88),\n",
       "     'confidence': 0.951},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(11.88),\n",
       "     'end': np.float64(12.58),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'right',\n",
       "     'start': np.float64(12.58),\n",
       "     'end': np.float64(13.04),\n",
       "     'confidence': 0.45},\n",
       "    {'text': 'now',\n",
       "     'start': np.float64(13.04),\n",
       "     'end': np.float64(13.38),\n",
       "     'confidence': 0.997},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(13.38),\n",
       "     'end': np.float64(13.56),\n",
       "     'confidence': 0.793},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(13.56),\n",
       "     'end': np.float64(13.74),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'third',\n",
       "     'start': np.float64(13.74),\n",
       "     'end': np.float64(14.14),\n",
       "     'confidence': 0.903},\n",
       "    {'text': 'year',\n",
       "     'start': np.float64(14.14),\n",
       "     'end': np.float64(14.38),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(14.38),\n",
       "     'end': np.float64(14.56),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'my',\n",
       "     'start': np.float64(14.56),\n",
       "     'end': np.float64(14.74),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(14.74),\n",
       "     'end': np.float64(14.76),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'college.',\n",
       "     'start': np.float64(14.76),\n",
       "     'end': np.float64(15.08),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(15.86),\n",
       "     'end': np.float64(15.9),\n",
       "     'confidence': 0.908},\n",
       "    {'text': 'mean,',\n",
       "     'start': np.float64(15.9),\n",
       "     'end': np.float64(16.08),\n",
       "     'confidence': 0.784},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(16.16),\n",
       "     'end': np.float64(16.58),\n",
       "     'confidence': 0.757},\n",
       "    {'text': 'going',\n",
       "     'start': np.float64(16.58),\n",
       "     'end': np.float64(16.76),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(16.76),\n",
       "     'end': np.float64(17.0),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'be',\n",
       "     'start': np.float64(17.0),\n",
       "     'end': np.float64(17.16),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(17.16),\n",
       "     'end': np.float64(17.34),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(17.34),\n",
       "     'end': np.float64(17.48),\n",
       "     'confidence': 0.963},\n",
       "    {'text': 'sixth',\n",
       "     'start': np.float64(17.48),\n",
       "     'end': np.float64(17.7),\n",
       "     'confidence': 0.824},\n",
       "    {'text': 'semester,',\n",
       "     'start': np.float64(17.7),\n",
       "     'end': np.float64(18.06),\n",
       "     'confidence': 0.891}]},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': np.float64(18.76),\n",
       "   'end': np.float64(25.44),\n",
       "   'text': ' but yeah, from the start of my college, I think from my second semester towards the end of it,',\n",
       "   'tokens': [51304,\n",
       "    457,\n",
       "    1338,\n",
       "    11,\n",
       "    490,\n",
       "    264,\n",
       "    722,\n",
       "    295,\n",
       "    452,\n",
       "    3859,\n",
       "    11,\n",
       "    286,\n",
       "    519,\n",
       "    490,\n",
       "    452,\n",
       "    1150,\n",
       "    11894,\n",
       "    3030,\n",
       "    264,\n",
       "    917,\n",
       "    295,\n",
       "    309,\n",
       "    11,\n",
       "    51656],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14936956425303036,\n",
       "   'compression_ratio': 1.5732217573221758,\n",
       "   'no_speech_prob': 0.10543079674243927,\n",
       "   'confidence': 0.906,\n",
       "   'words': [{'text': 'but',\n",
       "     'start': np.float64(18.76),\n",
       "     'end': np.float64(19.12),\n",
       "     'confidence': 0.993},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(19.12),\n",
       "     'end': np.float64(19.68),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'yeah,',\n",
       "     'start': np.float64(19.68),\n",
       "     'end': np.float64(19.96),\n",
       "     'confidence': 0.631},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(19.96),\n",
       "     'end': np.float64(20.66),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'from',\n",
       "     'start': np.float64(20.66),\n",
       "     'end': np.float64(20.76),\n",
       "     'confidence': 0.99},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(20.76),\n",
       "     'end': np.float64(20.92),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(20.92),\n",
       "     'end': np.float64(21.08),\n",
       "     'confidence': 0.616},\n",
       "    {'text': 'start',\n",
       "     'start': np.float64(21.08),\n",
       "     'end': np.float64(21.34),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(21.34),\n",
       "     'end': np.float64(21.56),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'my',\n",
       "     'start': np.float64(21.56),\n",
       "     'end': np.float64(21.72),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(21.72),\n",
       "     'end': np.float64(21.9),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'college,',\n",
       "     'start': np.float64(21.9),\n",
       "     'end': np.float64(22.04),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(22.12),\n",
       "     'end': np.float64(22.22),\n",
       "     'confidence': 0.97},\n",
       "    {'text': 'think',\n",
       "     'start': np.float64(22.22),\n",
       "     'end': np.float64(22.4),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'from',\n",
       "     'start': np.float64(22.4),\n",
       "     'end': np.float64(22.66),\n",
       "     'confidence': 0.792},\n",
       "    {'text': 'my',\n",
       "     'start': np.float64(22.66),\n",
       "     'end': np.float64(23.04),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'second',\n",
       "     'start': np.float64(23.04),\n",
       "     'end': np.float64(23.38),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'semester',\n",
       "     'start': np.float64(23.38),\n",
       "     'end': np.float64(23.84),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'towards',\n",
       "     'start': np.float64(23.84),\n",
       "     'end': np.float64(24.2),\n",
       "     'confidence': 0.967},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(24.2),\n",
       "     'end': np.float64(24.58),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(24.58),\n",
       "     'end': np.float64(24.72),\n",
       "     'confidence': 0.644},\n",
       "    {'text': 'end',\n",
       "     'start': np.float64(24.72),\n",
       "     'end': np.float64(24.74),\n",
       "     'confidence': 0.948},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(24.74),\n",
       "     'end': np.float64(25.12),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(25.12),\n",
       "     'end': np.float64(25.22),\n",
       "     'confidence': 0.935},\n",
       "    {'text': 'it,',\n",
       "     'start': np.float64(25.22),\n",
       "     'end': np.float64(25.44),\n",
       "     'confidence': 0.978}]},\n",
       "  {'id': 4,\n",
       "   'seek': 2584,\n",
       "   'start': np.float64(25.94),\n",
       "   'end': np.float64(33.45),\n",
       "   'text': ' I got interested in like machine learning. I got to know about machine learning from some channels,',\n",
       "   'tokens': [50364,\n",
       "    286,\n",
       "    658,\n",
       "    3102,\n",
       "    294,\n",
       "    411,\n",
       "    3479,\n",
       "    2539,\n",
       "    13,\n",
       "    286,\n",
       "    658,\n",
       "    281,\n",
       "    458,\n",
       "    466,\n",
       "    3479,\n",
       "    2539,\n",
       "    490,\n",
       "    512,\n",
       "    9235,\n",
       "    11,\n",
       "    50748],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12076215242084704,\n",
       "   'compression_ratio': 1.7534883720930232,\n",
       "   'no_speech_prob': 0.026963256299495697,\n",
       "   'confidence': 0.885,\n",
       "   'words': [{'text': 'I',\n",
       "     'start': np.float64(25.94),\n",
       "     'end': np.float64(26.2),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(26.2),\n",
       "     'end': np.float64(26.62),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'interested',\n",
       "     'start': np.float64(26.62),\n",
       "     'end': np.float64(27.06),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(27.06),\n",
       "     'end': np.float64(27.4),\n",
       "     'confidence': 0.991},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(27.4),\n",
       "     'end': np.float64(28.0),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(28.0),\n",
       "     'end': np.float64(28.18),\n",
       "     'confidence': 0.527},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(28.18),\n",
       "     'end': np.float64(28.62),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'machine',\n",
       "     'start': np.float64(28.62),\n",
       "     'end': np.float64(29.12),\n",
       "     'confidence': 0.903},\n",
       "    {'text': 'learning.',\n",
       "     'start': np.float64(29.12),\n",
       "     'end': np.float64(29.5),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(29.82),\n",
       "     'end': np.float64(29.84),\n",
       "     'confidence': 0.992},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(29.84),\n",
       "     'end': np.float64(30.18),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(30.18),\n",
       "     'end': np.float64(30.34),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(30.34),\n",
       "     'end': np.float64(30.58),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'know',\n",
       "     'start': np.float64(30.58),\n",
       "     'end': np.float64(30.82),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(30.82),\n",
       "     'end': np.float64(31.18),\n",
       "     'confidence': 0.997},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(31.18),\n",
       "     'end': np.float64(31.6),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'machine',\n",
       "     'start': np.float64(31.6),\n",
       "     'end': np.float64(31.72),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'learning',\n",
       "     'start': np.float64(31.72),\n",
       "     'end': np.float64(32.1),\n",
       "     'confidence': 0.981},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(32.1),\n",
       "     'end': np.float64(32.52),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'from',\n",
       "     'start': np.float64(32.52),\n",
       "     'end': np.float64(32.82),\n",
       "     'confidence': 0.691},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(32.82),\n",
       "     'end': np.float64(33.02),\n",
       "     'confidence': 0.766},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(33.02),\n",
       "     'end': np.float64(33.04),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'channels,',\n",
       "     'start': np.float64(33.04),\n",
       "     'end': np.float64(33.45),\n",
       "     'confidence': 0.544}]},\n",
       "  {'id': 5,\n",
       "   'seek': 2584,\n",
       "   'start': np.float64(33.45),\n",
       "   'end': np.float64(38.6),\n",
       "   'text': ' from YouTube channels and all. And I thought, yeah, it is an interesting field. I got to know',\n",
       "   'tokens': [50748,\n",
       "    490,\n",
       "    3088,\n",
       "    9235,\n",
       "    293,\n",
       "    439,\n",
       "    13,\n",
       "    400,\n",
       "    286,\n",
       "    1194,\n",
       "    11,\n",
       "    1338,\n",
       "    11,\n",
       "    309,\n",
       "    307,\n",
       "    364,\n",
       "    1880,\n",
       "    2519,\n",
       "    13,\n",
       "    286,\n",
       "    658,\n",
       "    281,\n",
       "    458,\n",
       "    51000],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12076215242084704,\n",
       "   'compression_ratio': 1.7534883720930232,\n",
       "   'no_speech_prob': 0.026963256299495697,\n",
       "   'confidence': 0.929,\n",
       "   'words': [{'text': 'from',\n",
       "     'start': np.float64(33.45),\n",
       "     'end': np.float64(33.82),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'YouTube',\n",
       "     'start': np.float64(33.82),\n",
       "     'end': np.float64(34.06),\n",
       "     'confidence': 0.928},\n",
       "    {'text': 'channels',\n",
       "     'start': np.float64(34.06),\n",
       "     'end': np.float64(34.54),\n",
       "     'confidence': 0.967},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(34.54),\n",
       "     'end': np.float64(34.8),\n",
       "     'confidence': 0.843},\n",
       "    {'text': 'all.',\n",
       "     'start': np.float64(34.8),\n",
       "     'end': np.float64(35.02),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(35.02),\n",
       "     'end': np.float64(35.76),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(35.76),\n",
       "     'end': np.float64(35.8),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(35.8),\n",
       "     'end': np.float64(36.02),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'thought,',\n",
       "     'start': np.float64(36.02),\n",
       "     'end': np.float64(36.24),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'yeah,',\n",
       "     'start': np.float64(36.44),\n",
       "     'end': np.float64(36.56),\n",
       "     'confidence': 0.831},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(36.64),\n",
       "     'end': np.float64(36.76),\n",
       "     'confidence': 0.962},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(36.76),\n",
       "     'end': np.float64(36.92),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'an',\n",
       "     'start': np.float64(36.92),\n",
       "     'end': np.float64(37.08),\n",
       "     'confidence': 0.826},\n",
       "    {'text': 'interesting',\n",
       "     'start': np.float64(37.08),\n",
       "     'end': np.float64(37.48),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'field.',\n",
       "     'start': np.float64(37.48),\n",
       "     'end': np.float64(37.88),\n",
       "     'confidence': 0.974},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(38.02),\n",
       "     'end': np.float64(38.08),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(38.08),\n",
       "     'end': np.float64(38.28),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(38.28),\n",
       "     'end': np.float64(38.46),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'know',\n",
       "     'start': np.float64(38.46),\n",
       "     'end': np.float64(38.6),\n",
       "     'confidence': 0.604}]},\n",
       "  {'id': 6,\n",
       "   'seek': 2584,\n",
       "   'start': np.float64(38.6),\n",
       "   'end': np.float64(45.94),\n",
       "   'text': ' some things about it. I took a course, a very famous course from Andrew Ng, which is ML',\n",
       "   'tokens': [51000,\n",
       "    512,\n",
       "    721,\n",
       "    466,\n",
       "    309,\n",
       "    13,\n",
       "    286,\n",
       "    1890,\n",
       "    257,\n",
       "    1164,\n",
       "    11,\n",
       "    257,\n",
       "    588,\n",
       "    4618,\n",
       "    1164,\n",
       "    490,\n",
       "    10110,\n",
       "    21198,\n",
       "    11,\n",
       "    597,\n",
       "    307,\n",
       "    21601,\n",
       "    51376],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12076215242084704,\n",
       "   'compression_ratio': 1.7534883720930232,\n",
       "   'no_speech_prob': 0.026963256299495697,\n",
       "   'confidence': 0.892,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(38.6),\n",
       "     'end': np.float64(38.7),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(38.7),\n",
       "     'end': np.float64(38.82),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'things',\n",
       "     'start': np.float64(38.82),\n",
       "     'end': np.float64(39.06),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(39.06),\n",
       "     'end': np.float64(39.36),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(39.36),\n",
       "     'end': np.float64(39.82),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'it.',\n",
       "     'start': np.float64(39.82),\n",
       "     'end': np.float64(40.0),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(40.34),\n",
       "     'end': np.float64(40.88),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'took',\n",
       "     'start': np.float64(40.88),\n",
       "     'end': np.float64(41.22),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(41.22),\n",
       "     'end': np.float64(41.62),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(41.62),\n",
       "     'end': np.float64(41.92),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'course,',\n",
       "     'start': np.float64(41.92),\n",
       "     'end': np.float64(42.24),\n",
       "     'confidence': 0.911},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(42.38),\n",
       "     'end': np.float64(42.56),\n",
       "     'confidence': 0.973},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(42.56),\n",
       "     'end': np.float64(42.76),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'famous',\n",
       "     'start': np.float64(42.76),\n",
       "     'end': np.float64(43.04),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'course',\n",
       "     'start': np.float64(43.04),\n",
       "     'end': np.float64(43.4),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'from',\n",
       "     'start': np.float64(43.4),\n",
       "     'end': np.float64(43.72),\n",
       "     'confidence': 0.922},\n",
       "    {'text': 'Andrew',\n",
       "     'start': np.float64(43.72),\n",
       "     'end': np.float64(44.2),\n",
       "     'confidence': 0.527},\n",
       "    {'text': 'Ng,',\n",
       "     'start': np.float64(44.2),\n",
       "     'end': np.float64(44.48),\n",
       "     'confidence': 0.38},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(44.66),\n",
       "     'end': np.float64(45.0),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(45.0),\n",
       "     'end': np.float64(45.4),\n",
       "     'confidence': 0.921},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(45.4),\n",
       "     'end': np.float64(45.58),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'ML',\n",
       "     'start': np.float64(45.58),\n",
       "     'end': np.float64(45.94),\n",
       "     'confidence': 0.899}]},\n",
       "  {'id': 7,\n",
       "   'seek': 2584,\n",
       "   'start': np.float64(45.94),\n",
       "   'end': np.float64(51.57),\n",
       "   'text': \" specialization course, which is on course era. So in the break, in the summer break, which I've\",\n",
       "   'tokens': [51376,\n",
       "    2121,\n",
       "    2144,\n",
       "    1164,\n",
       "    11,\n",
       "    597,\n",
       "    307,\n",
       "    322,\n",
       "    1164,\n",
       "    4249,\n",
       "    13,\n",
       "    407,\n",
       "    294,\n",
       "    264,\n",
       "    1821,\n",
       "    11,\n",
       "    294,\n",
       "    264,\n",
       "    4266,\n",
       "    1821,\n",
       "    11,\n",
       "    597,\n",
       "    286,\n",
       "    600,\n",
       "    51648],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12076215242084704,\n",
       "   'compression_ratio': 1.7534883720930232,\n",
       "   'no_speech_prob': 0.026963256299495697,\n",
       "   'confidence': 0.904,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(45.94),\n",
       "     'end': np.float64(46.24),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'specialization',\n",
       "     'start': np.float64(46.24),\n",
       "     'end': np.float64(46.86),\n",
       "     'confidence': 0.84},\n",
       "    {'text': 'course,',\n",
       "     'start': np.float64(46.86),\n",
       "     'end': np.float64(47.22),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(47.8),\n",
       "     'end': np.float64(47.96),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(47.96),\n",
       "     'end': np.float64(48.08),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(48.08),\n",
       "     'end': np.float64(48.24),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'course',\n",
       "     'start': np.float64(48.24),\n",
       "     'end': np.float64(48.46),\n",
       "     'confidence': 0.931},\n",
       "    {'text': 'era.',\n",
       "     'start': np.float64(48.46),\n",
       "     'end': np.float64(48.7),\n",
       "     'confidence': 0.52},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(48.84),\n",
       "     'end': np.float64(49.46),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(49.46),\n",
       "     'end': np.float64(49.76),\n",
       "     'confidence': 0.972},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(49.76),\n",
       "     'end': np.float64(49.96),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(49.96),\n",
       "     'end': np.float64(50.02),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'break,',\n",
       "     'start': np.float64(50.02),\n",
       "     'end': np.float64(50.26),\n",
       "     'confidence': 0.868},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(50.4),\n",
       "     'end': np.float64(50.58),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(50.58),\n",
       "     'end': np.float64(50.7),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'summer',\n",
       "     'start': np.float64(50.7),\n",
       "     'end': np.float64(50.88),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'break,',\n",
       "     'start': np.float64(50.88),\n",
       "     'end': np.float64(51.18),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(51.24),\n",
       "     'end': np.float64(51.42),\n",
       "     'confidence': 0.636},\n",
       "    {'text': \"I've\",\n",
       "     'start': np.float64(51.42),\n",
       "     'end': np.float64(51.57),\n",
       "     'confidence': 0.919}]},\n",
       "  {'id': 8,\n",
       "   'seek': 5152,\n",
       "   'start': np.float64(51.57),\n",
       "   'end': np.float64(58.96),\n",
       "   'text': ' got in the college, I actually completed that course. And actually I was very intrigued by how',\n",
       "   'tokens': [50364,\n",
       "    658,\n",
       "    294,\n",
       "    264,\n",
       "    3859,\n",
       "    11,\n",
       "    286,\n",
       "    767,\n",
       "    7365,\n",
       "    300,\n",
       "    1164,\n",
       "    13,\n",
       "    400,\n",
       "    767,\n",
       "    286,\n",
       "    390,\n",
       "    588,\n",
       "    35140,\n",
       "    538,\n",
       "    577,\n",
       "    50736],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14000203575886472,\n",
       "   'compression_ratio': 1.615819209039548,\n",
       "   'no_speech_prob': 0.048917971551418304,\n",
       "   'confidence': 0.924,\n",
       "   'words': [{'text': 'got',\n",
       "     'start': np.float64(51.57),\n",
       "     'end': np.float64(51.78),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(51.78),\n",
       "     'end': np.float64(52.0),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(52.0),\n",
       "     'end': np.float64(52.12),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'college,',\n",
       "     'start': np.float64(52.12),\n",
       "     'end': np.float64(52.46),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(52.66),\n",
       "     'end': np.float64(52.92),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(52.92),\n",
       "     'end': np.float64(53.46),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'completed',\n",
       "     'start': np.float64(53.46),\n",
       "     'end': np.float64(53.92),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(53.92),\n",
       "     'end': np.float64(54.26),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'course.',\n",
       "     'start': np.float64(54.26),\n",
       "     'end': np.float64(54.56),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(54.8),\n",
       "     'end': np.float64(55.06),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(55.06),\n",
       "     'end': np.float64(55.46),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(55.46),\n",
       "     'end': np.float64(55.8),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(55.8),\n",
       "     'end': np.float64(55.98),\n",
       "     'confidence': 0.515},\n",
       "    {'text': 'was',\n",
       "     'start': np.float64(55.98),\n",
       "     'end': np.float64(56.12),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(56.12),\n",
       "     'end': np.float64(56.42),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'intrigued',\n",
       "     'start': np.float64(56.42),\n",
       "     'end': np.float64(56.8),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(56.8),\n",
       "     'end': np.float64(57.34),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'by',\n",
       "     'start': np.float64(57.34),\n",
       "     'end': np.float64(57.8),\n",
       "     'confidence': 0.95},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(57.8),\n",
       "     'end': np.float64(58.78),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(58.78),\n",
       "     'end': np.float64(58.96),\n",
       "     'confidence': 0.571}]},\n",
       "  {'id': 9,\n",
       "   'seek': 5152,\n",
       "   'start': np.float64(60.04),\n",
       "   'end': np.float64(66.16),\n",
       "   'text': ' like we do all this stuff, what we do in the like machine learning field, right? So it was very',\n",
       "   'tokens': [50788,\n",
       "    411,\n",
       "    321,\n",
       "    360,\n",
       "    439,\n",
       "    341,\n",
       "    1507,\n",
       "    11,\n",
       "    437,\n",
       "    321,\n",
       "    360,\n",
       "    294,\n",
       "    264,\n",
       "    411,\n",
       "    3479,\n",
       "    2539,\n",
       "    2519,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    407,\n",
       "    309,\n",
       "    390,\n",
       "    588,\n",
       "    51096],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14000203575886472,\n",
       "   'compression_ratio': 1.615819209039548,\n",
       "   'no_speech_prob': 0.048917971551418304,\n",
       "   'confidence': 0.89,\n",
       "   'words': [{'text': 'like',\n",
       "     'start': np.float64(60.04),\n",
       "     'end': np.float64(60.28),\n",
       "     'confidence': 0.947},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(60.28),\n",
       "     'end': np.float64(60.6),\n",
       "     'confidence': 0.869},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(60.6),\n",
       "     'end': np.float64(60.8),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'all',\n",
       "     'start': np.float64(60.8),\n",
       "     'end': np.float64(60.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(60.98),\n",
       "     'end': np.float64(61.16),\n",
       "     'confidence': 0.669},\n",
       "    {'text': 'stuff,',\n",
       "     'start': np.float64(61.16),\n",
       "     'end': np.float64(61.36),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(61.44),\n",
       "     'end': np.float64(61.58),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(61.58),\n",
       "     'end': np.float64(61.74),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(61.74),\n",
       "     'end': np.float64(61.88),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(61.88),\n",
       "     'end': np.float64(62.04),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(62.04),\n",
       "     'end': np.float64(62.18),\n",
       "     'confidence': 0.971},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(62.18),\n",
       "     'end': np.float64(62.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(62.56),\n",
       "     'end': np.float64(62.7),\n",
       "     'confidence': 0.61},\n",
       "    {'text': 'machine',\n",
       "     'start': np.float64(62.7),\n",
       "     'end': np.float64(63.4),\n",
       "     'confidence': 0.842},\n",
       "    {'text': 'learning',\n",
       "     'start': np.float64(63.4),\n",
       "     'end': np.float64(63.72),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'field,',\n",
       "     'start': np.float64(63.72),\n",
       "     'end': np.float64(64.02),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(64.18),\n",
       "     'end': np.float64(64.3),\n",
       "     'confidence': 0.981},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(64.7),\n",
       "     'end': np.float64(65.06),\n",
       "     'confidence': 0.73},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(65.06),\n",
       "     'end': np.float64(65.36),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(65.36),\n",
       "     'end': np.float64(65.8),\n",
       "     'confidence': 0.713},\n",
       "    {'text': 'was',\n",
       "     'start': np.float64(65.8),\n",
       "     'end': np.float64(65.94),\n",
       "     'confidence': 0.965},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(65.94),\n",
       "     'end': np.float64(66.16),\n",
       "     'confidence': 0.757}]},\n",
       "  {'id': 10,\n",
       "   'seek': 5152,\n",
       "   'start': np.float64(66.18),\n",
       "   'end': np.float64(73.36),\n",
       "   'text': ' interesting. And like after that, I was just doing some courses, then I got into deep learning.',\n",
       "   'tokens': [51096,\n",
       "    1880,\n",
       "    13,\n",
       "    400,\n",
       "    411,\n",
       "    934,\n",
       "    300,\n",
       "    11,\n",
       "    286,\n",
       "    390,\n",
       "    445,\n",
       "    884,\n",
       "    512,\n",
       "    7712,\n",
       "    11,\n",
       "    550,\n",
       "    286,\n",
       "    658,\n",
       "    666,\n",
       "    2452,\n",
       "    2539,\n",
       "    13,\n",
       "    51456],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14000203575886472,\n",
       "   'compression_ratio': 1.615819209039548,\n",
       "   'no_speech_prob': 0.048917971551418304,\n",
       "   'confidence': 0.937,\n",
       "   'words': [{'text': 'interesting.',\n",
       "     'start': np.float64(66.18),\n",
       "     'end': np.float64(66.62),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(66.62),\n",
       "     'end': np.float64(67.06),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(67.06),\n",
       "     'end': np.float64(67.14),\n",
       "     'confidence': 0.991},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(67.14),\n",
       "     'end': np.float64(68.08),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(68.08),\n",
       "     'end': np.float64(68.4),\n",
       "     'confidence': 0.939},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(68.4),\n",
       "     'end': np.float64(69.0),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'after',\n",
       "     'start': np.float64(69.0),\n",
       "     'end': np.float64(69.12),\n",
       "     'confidence': 0.54},\n",
       "    {'text': 'that,',\n",
       "     'start': np.float64(69.12),\n",
       "     'end': np.float64(69.48),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(69.56),\n",
       "     'end': np.float64(69.74),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'was',\n",
       "     'start': np.float64(69.74),\n",
       "     'end': np.float64(69.9),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'just',\n",
       "     'start': np.float64(69.9),\n",
       "     'end': np.float64(70.2),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'doing',\n",
       "     'start': np.float64(70.2),\n",
       "     'end': np.float64(70.82),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(70.82),\n",
       "     'end': np.float64(71.14),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'courses,',\n",
       "     'start': np.float64(71.14),\n",
       "     'end': np.float64(71.56),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'then',\n",
       "     'start': np.float64(71.74),\n",
       "     'end': np.float64(71.98),\n",
       "     'confidence': 0.679},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(71.98),\n",
       "     'end': np.float64(72.14),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(72.14),\n",
       "     'end': np.float64(72.32),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'into',\n",
       "     'start': np.float64(72.32),\n",
       "     'end': np.float64(72.62),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'deep',\n",
       "     'start': np.float64(72.62),\n",
       "     'end': np.float64(73.04),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'learning.',\n",
       "     'start': np.float64(73.04),\n",
       "     'end': np.float64(73.36),\n",
       "     'confidence': 0.989}]},\n",
       "  {'id': 11,\n",
       "   'seek': 7336,\n",
       "   'start': np.float64(74.08),\n",
       "   'end': np.float64(83.2),\n",
       "   'text': ' I then got into some NLP. I like, I learned NLP or like Transformers about all these things from',\n",
       "   'tokens': [50396,\n",
       "    286,\n",
       "    550,\n",
       "    658,\n",
       "    666,\n",
       "    512,\n",
       "    426,\n",
       "    45196,\n",
       "    13,\n",
       "    286,\n",
       "    411,\n",
       "    11,\n",
       "    286,\n",
       "    3264,\n",
       "    426,\n",
       "    45196,\n",
       "    420,\n",
       "    411,\n",
       "    27938,\n",
       "    433,\n",
       "    466,\n",
       "    439,\n",
       "    613,\n",
       "    721,\n",
       "    490,\n",
       "    50864],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17077101670302353,\n",
       "   'compression_ratio': 1.4924623115577889,\n",
       "   'no_speech_prob': 0.45082274079322815,\n",
       "   'confidence': 0.887,\n",
       "   'words': [{'text': 'I',\n",
       "     'start': np.float64(74.08),\n",
       "     'end': np.float64(74.24),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'then',\n",
       "     'start': np.float64(74.24),\n",
       "     'end': np.float64(74.5),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(74.5),\n",
       "     'end': np.float64(74.82),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'into',\n",
       "     'start': np.float64(74.82),\n",
       "     'end': np.float64(75.16),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(75.16),\n",
       "     'end': np.float64(75.52),\n",
       "     'confidence': 0.988},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(75.52),\n",
       "     'end': np.float64(76.5),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'NLP.',\n",
       "     'start': np.float64(76.5),\n",
       "     'end': np.float64(76.96),\n",
       "     'confidence': 0.965},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(77.42),\n",
       "     'end': np.float64(77.56),\n",
       "     'confidence': 0.952},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(77.56),\n",
       "     'end': np.float64(77.74),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like,',\n",
       "     'start': np.float64(77.74),\n",
       "     'end': np.float64(78.12),\n",
       "     'confidence': 0.679},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(78.38),\n",
       "     'end': np.float64(78.7),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(78.7),\n",
       "     'end': np.float64(78.88),\n",
       "     'confidence': 0.904},\n",
       "    {'text': 'learned',\n",
       "     'start': np.float64(78.88),\n",
       "     'end': np.float64(79.18),\n",
       "     'confidence': 0.962},\n",
       "    {'text': 'NLP',\n",
       "     'start': np.float64(79.18),\n",
       "     'end': np.float64(79.72),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(79.72),\n",
       "     'end': np.float64(80.18),\n",
       "     'confidence': 0.903},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(80.18),\n",
       "     'end': np.float64(80.42),\n",
       "     'confidence': 0.97},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(80.42),\n",
       "     'end': np.float64(80.64),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'Transformers',\n",
       "     'start': np.float64(80.64),\n",
       "     'end': np.float64(81.26),\n",
       "     'confidence': 0.681},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(81.26),\n",
       "     'end': np.float64(81.62),\n",
       "     'confidence': 0.871},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(81.62),\n",
       "     'end': np.float64(81.92),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'all',\n",
       "     'start': np.float64(81.92),\n",
       "     'end': np.float64(82.2),\n",
       "     'confidence': 0.927},\n",
       "    {'text': 'these',\n",
       "     'start': np.float64(82.2),\n",
       "     'end': np.float64(82.48),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'things',\n",
       "     'start': np.float64(82.48),\n",
       "     'end': np.float64(82.86),\n",
       "     'confidence': 0.914},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(82.86),\n",
       "     'end': np.float64(83.12),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'from',\n",
       "     'start': np.float64(83.12),\n",
       "     'end': np.float64(83.2),\n",
       "     'confidence': 0.487}]},\n",
       "  {'id': 12,\n",
       "   'seek': 7336,\n",
       "   'start': np.float64(83.2),\n",
       "   'end': np.float64(91.1),\n",
       "   'text': ' some YouTube channel from a very famous guy called like Andrej Karpathy, his famous, famous playlist',\n",
       "   'tokens': [50864,\n",
       "    512,\n",
       "    3088,\n",
       "    2269,\n",
       "    490,\n",
       "    257,\n",
       "    588,\n",
       "    4618,\n",
       "    2146,\n",
       "    1219,\n",
       "    411,\n",
       "    20667,\n",
       "    73,\n",
       "    591,\n",
       "    6529,\n",
       "    9527,\n",
       "    11,\n",
       "    702,\n",
       "    4618,\n",
       "    11,\n",
       "    4618,\n",
       "    16788,\n",
       "    51260],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17077101670302353,\n",
       "   'compression_ratio': 1.4924623115577889,\n",
       "   'no_speech_prob': 0.45082274079322815,\n",
       "   'confidence': 0.801,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(83.2),\n",
       "     'end': np.float64(83.5),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(83.5),\n",
       "     'end': np.float64(83.6),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'YouTube',\n",
       "     'start': np.float64(83.6),\n",
       "     'end': np.float64(83.9),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'channel',\n",
       "     'start': np.float64(83.9),\n",
       "     'end': np.float64(84.32),\n",
       "     'confidence': 0.988},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(84.32),\n",
       "     'end': np.float64(84.88),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'from',\n",
       "     'start': np.float64(84.88),\n",
       "     'end': np.float64(85.0),\n",
       "     'confidence': 0.503},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(85.0),\n",
       "     'end': np.float64(85.14),\n",
       "     'confidence': 0.857},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(85.14),\n",
       "     'end': np.float64(85.3),\n",
       "     'confidence': 0.814},\n",
       "    {'text': 'famous',\n",
       "     'start': np.float64(85.3),\n",
       "     'end': np.float64(86.02),\n",
       "     'confidence': 0.934},\n",
       "    {'text': 'guy',\n",
       "     'start': np.float64(86.02),\n",
       "     'end': np.float64(86.38),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'called',\n",
       "     'start': np.float64(86.38),\n",
       "     'end': np.float64(86.7),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(86.7),\n",
       "     'end': np.float64(87.0),\n",
       "     'confidence': 0.844},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(87.0),\n",
       "     'end': np.float64(87.74),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'Andrej',\n",
       "     'start': np.float64(87.74),\n",
       "     'end': np.float64(88.06),\n",
       "     'confidence': 0.735},\n",
       "    {'text': 'Karpathy,',\n",
       "     'start': np.float64(88.06),\n",
       "     'end': np.float64(88.58),\n",
       "     'confidence': 0.68},\n",
       "    {'text': 'his',\n",
       "     'start': np.float64(88.74),\n",
       "     'end': np.float64(89.58),\n",
       "     'confidence': 0.816},\n",
       "    {'text': 'famous,',\n",
       "     'start': np.float64(89.58),\n",
       "     'end': np.float64(89.94),\n",
       "     'confidence': 0.982},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(90.14),\n",
       "     'end': np.float64(90.46),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'famous',\n",
       "     'start': np.float64(90.46),\n",
       "     'end': np.float64(90.6),\n",
       "     'confidence': 0.637},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(90.6),\n",
       "     'end': np.float64(90.66),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'playlist',\n",
       "     'start': np.float64(90.66),\n",
       "     'end': np.float64(91.1),\n",
       "     'confidence': 0.637}]},\n",
       "  {'id': 13,\n",
       "   'seek': 7336,\n",
       "   'start': np.float64(91.3),\n",
       "   'end': np.float64(98.66),\n",
       "   'text': ' on neural networks. That was amazing. So I built, I tried like I did some projects, I got into some',\n",
       "   'tokens': [51260,\n",
       "    322,\n",
       "    18161,\n",
       "    9590,\n",
       "    13,\n",
       "    663,\n",
       "    390,\n",
       "    2243,\n",
       "    13,\n",
       "    407,\n",
       "    286,\n",
       "    3094,\n",
       "    11,\n",
       "    286,\n",
       "    3031,\n",
       "    411,\n",
       "    286,\n",
       "    630,\n",
       "    512,\n",
       "    4455,\n",
       "    11,\n",
       "    286,\n",
       "    658,\n",
       "    666,\n",
       "    512,\n",
       "    51628],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17077101670302353,\n",
       "   'compression_ratio': 1.4924623115577889,\n",
       "   'no_speech_prob': 0.45082274079322815,\n",
       "   'confidence': 0.933,\n",
       "   'words': [{'text': 'on',\n",
       "     'start': np.float64(91.3),\n",
       "     'end': np.float64(91.56),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'neural',\n",
       "     'start': np.float64(91.56),\n",
       "     'end': np.float64(91.88),\n",
       "     'confidence': 0.967},\n",
       "    {'text': 'networks.',\n",
       "     'start': np.float64(91.88),\n",
       "     'end': np.float64(92.32),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'That',\n",
       "     'start': np.float64(92.78),\n",
       "     'end': np.float64(92.96),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'was',\n",
       "     'start': np.float64(92.96),\n",
       "     'end': np.float64(93.14),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'amazing.',\n",
       "     'start': np.float64(93.14),\n",
       "     'end': np.float64(93.54),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(94.08),\n",
       "     'end': np.float64(94.36),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(94.36),\n",
       "     'end': np.float64(94.58),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'built,',\n",
       "     'start': np.float64(94.58),\n",
       "     'end': np.float64(94.9),\n",
       "     'confidence': 0.887},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(95.18),\n",
       "     'end': np.float64(95.34),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'tried',\n",
       "     'start': np.float64(95.34),\n",
       "     'end': np.float64(95.66),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(95.66),\n",
       "     'end': np.float64(96.04),\n",
       "     'confidence': 0.553},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(96.04),\n",
       "     'end': np.float64(96.24),\n",
       "     'confidence': 0.89},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(96.24),\n",
       "     'end': np.float64(96.52),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'did',\n",
       "     'start': np.float64(96.52),\n",
       "     'end': np.float64(96.62),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(96.62),\n",
       "     'end': np.float64(96.88),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'projects,',\n",
       "     'start': np.float64(96.88),\n",
       "     'end': np.float64(97.44),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(97.62),\n",
       "     'end': np.float64(97.86),\n",
       "     'confidence': 0.892},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(97.86),\n",
       "     'end': np.float64(98.08),\n",
       "     'confidence': 0.978},\n",
       "    {'text': 'into',\n",
       "     'start': np.float64(98.08),\n",
       "     'end': np.float64(98.46),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(98.46),\n",
       "     'end': np.float64(98.66),\n",
       "     'confidence': 0.74}]},\n",
       "  {'id': 14,\n",
       "   'seek': 9864,\n",
       "   'start': np.float64(98.76),\n",
       "   'end': np.float64(104.24),\n",
       "   'text': ' hackathons with my friends and all, we worked on some ideas and all. So yeah, that was pretty',\n",
       "   'tokens': [50364,\n",
       "    10339,\n",
       "    998,\n",
       "    892,\n",
       "    365,\n",
       "    452,\n",
       "    1855,\n",
       "    293,\n",
       "    439,\n",
       "    11,\n",
       "    321,\n",
       "    2732,\n",
       "    322,\n",
       "    512,\n",
       "    3487,\n",
       "    293,\n",
       "    439,\n",
       "    13,\n",
       "    407,\n",
       "    1338,\n",
       "    11,\n",
       "    300,\n",
       "    390,\n",
       "    1238,\n",
       "    50644],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1541630336216518,\n",
       "   'compression_ratio': 1.6147186147186148,\n",
       "   'no_speech_prob': 0.028110891580581665,\n",
       "   'confidence': 0.961,\n",
       "   'words': [{'text': 'hackathons',\n",
       "     'start': np.float64(98.76),\n",
       "     'end': np.float64(99.3),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'with',\n",
       "     'start': np.float64(99.3),\n",
       "     'end': np.float64(99.56),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'my',\n",
       "     'start': np.float64(99.56),\n",
       "     'end': np.float64(99.74),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'friends',\n",
       "     'start': np.float64(99.74),\n",
       "     'end': np.float64(100.04),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(100.04),\n",
       "     'end': np.float64(100.3),\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'all,',\n",
       "     'start': np.float64(100.3),\n",
       "     'end': np.float64(100.52),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(100.96),\n",
       "     'end': np.float64(101.06),\n",
       "     'confidence': 0.616},\n",
       "    {'text': 'worked',\n",
       "     'start': np.float64(101.06),\n",
       "     'end': np.float64(101.26),\n",
       "     'confidence': 0.906},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(101.26),\n",
       "     'end': np.float64(101.44),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(101.44),\n",
       "     'end': np.float64(101.62),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'ideas',\n",
       "     'start': np.float64(101.62),\n",
       "     'end': np.float64(101.98),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(101.98),\n",
       "     'end': np.float64(102.3),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'all.',\n",
       "     'start': np.float64(102.3),\n",
       "     'end': np.float64(102.52),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(102.82),\n",
       "     'end': np.float64(103.24),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'yeah,',\n",
       "     'start': np.float64(103.24),\n",
       "     'end': np.float64(103.56),\n",
       "     'confidence': 0.898},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(103.6),\n",
       "     'end': np.float64(103.8),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'was',\n",
       "     'start': np.float64(103.8),\n",
       "     'end': np.float64(103.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'pretty',\n",
       "     'start': np.float64(103.98),\n",
       "     'end': np.float64(104.24),\n",
       "     'confidence': 0.998}]},\n",
       "  {'id': 15,\n",
       "   'seek': 9864,\n",
       "   'start': np.float64(104.24),\n",
       "   'end': np.float64(113.92),\n",
       "   'text': \" amazing. And that got me into this journey on ML and then DL and JNAI stuff. And that's how I\",\n",
       "   'tokens': [50644,\n",
       "    2243,\n",
       "    13,\n",
       "    400,\n",
       "    300,\n",
       "    658,\n",
       "    385,\n",
       "    666,\n",
       "    341,\n",
       "    4671,\n",
       "    322,\n",
       "    21601,\n",
       "    293,\n",
       "    550,\n",
       "    413,\n",
       "    43,\n",
       "    293,\n",
       "    508,\n",
       "    5321,\n",
       "    40,\n",
       "    1507,\n",
       "    13,\n",
       "    400,\n",
       "    300,\n",
       "    311,\n",
       "    577,\n",
       "    286,\n",
       "    51132],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1541630336216518,\n",
       "   'compression_ratio': 1.6147186147186148,\n",
       "   'no_speech_prob': 0.028110891580581665,\n",
       "   'confidence': 0.812,\n",
       "   'words': [{'text': 'amazing.',\n",
       "     'start': np.float64(104.24),\n",
       "     'end': np.float64(104.66),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(104.8),\n",
       "     'end': np.float64(105.02),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(105.02),\n",
       "     'end': np.float64(105.9),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(105.9),\n",
       "     'end': np.float64(106.2),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(106.2),\n",
       "     'end': np.float64(106.44),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'me',\n",
       "     'start': np.float64(106.44),\n",
       "     'end': np.float64(106.68),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'into',\n",
       "     'start': np.float64(106.68),\n",
       "     'end': np.float64(106.9),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(106.9),\n",
       "     'end': np.float64(107.24),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(107.24),\n",
       "     'end': np.float64(107.28),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'journey',\n",
       "     'start': np.float64(107.28),\n",
       "     'end': np.float64(108.2),\n",
       "     'confidence': 0.994},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(108.2),\n",
       "     'end': np.float64(108.72),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(108.72),\n",
       "     'end': np.float64(109.14),\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'ML',\n",
       "     'start': np.float64(109.14),\n",
       "     'end': np.float64(109.58),\n",
       "     'confidence': 0.947},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(109.58),\n",
       "     'end': np.float64(109.96),\n",
       "     'confidence': 0.852},\n",
       "    {'text': 'then',\n",
       "     'start': np.float64(109.96),\n",
       "     'end': np.float64(110.28),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'DL',\n",
       "     'start': np.float64(110.28),\n",
       "     'end': np.float64(110.84),\n",
       "     'confidence': 0.865},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(110.84),\n",
       "     'end': np.float64(111.02),\n",
       "     'confidence': 0.978},\n",
       "    {'text': 'JNAI',\n",
       "     'start': np.float64(111.02),\n",
       "     'end': np.float64(111.52),\n",
       "     'confidence': 0.264},\n",
       "    {'text': 'stuff.',\n",
       "     'start': np.float64(111.52),\n",
       "     'end': np.float64(111.8),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(112.24),\n",
       "     'end': np.float64(112.26),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(112.26),\n",
       "     'end': np.float64(113.16),\n",
       "     'confidence': 0.0},\n",
       "    {'text': \"that's\",\n",
       "     'start': np.float64(113.16),\n",
       "     'end': np.float64(113.5),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(113.5),\n",
       "     'end': np.float64(113.68),\n",
       "     'confidence': 0.917},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(113.68),\n",
       "     'end': np.float64(113.92),\n",
       "     'confidence': 0.762}]},\n",
       "  {'id': 16,\n",
       "   'seek': 9864,\n",
       "   'start': np.float64(113.92),\n",
       "   'end': np.float64(119.14),\n",
       "   'text': \" thought that, yeah, this is the field for me. I'm very interested in this field. I like, I,\",\n",
       "   'tokens': [51132,\n",
       "    1194,\n",
       "    300,\n",
       "    11,\n",
       "    1338,\n",
       "    11,\n",
       "    341,\n",
       "    307,\n",
       "    264,\n",
       "    2519,\n",
       "    337,\n",
       "    385,\n",
       "    13,\n",
       "    286,\n",
       "    478,\n",
       "    588,\n",
       "    3102,\n",
       "    294,\n",
       "    341,\n",
       "    2519,\n",
       "    13,\n",
       "    286,\n",
       "    411,\n",
       "    11,\n",
       "    286,\n",
       "    11,\n",
       "    51408],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1541630336216518,\n",
       "   'compression_ratio': 1.6147186147186148,\n",
       "   'no_speech_prob': 0.028110891580581665,\n",
       "   'confidence': 0.923,\n",
       "   'words': [{'text': 'thought',\n",
       "     'start': np.float64(113.92),\n",
       "     'end': np.float64(114.24),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'that,',\n",
       "     'start': np.float64(114.24),\n",
       "     'end': np.float64(114.48),\n",
       "     'confidence': 0.952},\n",
       "    {'text': 'yeah,',\n",
       "     'start': np.float64(114.54),\n",
       "     'end': np.float64(114.68),\n",
       "     'confidence': 0.935},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(114.78),\n",
       "     'end': np.float64(114.86),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(114.86),\n",
       "     'end': np.float64(114.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(114.98),\n",
       "     'end': np.float64(115.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'field',\n",
       "     'start': np.float64(115.1),\n",
       "     'end': np.float64(115.32),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(115.32),\n",
       "     'end': np.float64(115.52),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'me.',\n",
       "     'start': np.float64(115.52),\n",
       "     'end': np.float64(115.66),\n",
       "     'confidence': 1.0},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(115.74),\n",
       "     'end': np.float64(115.88),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(115.88),\n",
       "     'end': np.float64(116.06),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'interested',\n",
       "     'start': np.float64(116.06),\n",
       "     'end': np.float64(116.44),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(116.44),\n",
       "     'end': np.float64(116.84),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(116.84),\n",
       "     'end': np.float64(117.14),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'field.',\n",
       "     'start': np.float64(117.14),\n",
       "     'end': np.float64(117.64),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(117.9),\n",
       "     'end': np.float64(118.32),\n",
       "     'confidence': 0.747},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(118.32),\n",
       "     'end': np.float64(118.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like,',\n",
       "     'start': np.float64(118.56),\n",
       "     'end': np.float64(118.84),\n",
       "     'confidence': 0.692},\n",
       "    {'text': 'I,',\n",
       "     'start': np.float64(119.12),\n",
       "     'end': np.float64(119.14),\n",
       "     'confidence': 0.492}]},\n",
       "  {'id': 17,\n",
       "   'seek': 9864,\n",
       "   'start': np.float64(119.14),\n",
       "   'end': np.float64(126.18),\n",
       "   'text': ' I like it is amazing what we do. And I saw the possibilities that what we can build from this',\n",
       "   'tokens': [51408,\n",
       "    286,\n",
       "    411,\n",
       "    309,\n",
       "    307,\n",
       "    2243,\n",
       "    437,\n",
       "    321,\n",
       "    360,\n",
       "    13,\n",
       "    400,\n",
       "    286,\n",
       "    1866,\n",
       "    264,\n",
       "    12178,\n",
       "    300,\n",
       "    437,\n",
       "    321,\n",
       "    393,\n",
       "    1322,\n",
       "    490,\n",
       "    341,\n",
       "    51740],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1541630336216518,\n",
       "   'compression_ratio': 1.6147186147186148,\n",
       "   'no_speech_prob': 0.028110891580581665,\n",
       "   'confidence': 0.897,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(119.14),\n",
       "     'end': np.float64(119.62),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(119.62),\n",
       "     'end': np.float64(119.8),\n",
       "     'confidence': 0.961},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(119.8),\n",
       "     'end': np.float64(120.42),\n",
       "     'confidence': 0.756},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(120.42),\n",
       "     'end': np.float64(120.62),\n",
       "     'confidence': 0.629},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(120.62),\n",
       "     'end': np.float64(120.78),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'amazing',\n",
       "     'start': np.float64(120.78),\n",
       "     'end': np.float64(121.12),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(121.12),\n",
       "     'end': np.float64(121.56),\n",
       "     'confidence': 0.417},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(121.56),\n",
       "     'end': np.float64(121.76),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'do.',\n",
       "     'start': np.float64(121.76),\n",
       "     'end': np.float64(121.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(122.42),\n",
       "     'end': np.float64(122.86),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(122.86),\n",
       "     'end': np.float64(123.16),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(123.16),\n",
       "     'end': np.float64(123.38),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'saw',\n",
       "     'start': np.float64(123.38),\n",
       "     'end': np.float64(123.68),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(123.68),\n",
       "     'end': np.float64(123.86),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(123.86),\n",
       "     'end': np.float64(124.16),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'possibilities',\n",
       "     'start': np.float64(124.16),\n",
       "     'end': np.float64(124.42),\n",
       "     'confidence': 0.72},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(124.42),\n",
       "     'end': np.float64(124.76),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(124.76),\n",
       "     'end': np.float64(124.98),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(124.98),\n",
       "     'end': np.float64(125.22),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'can',\n",
       "     'start': np.float64(125.22),\n",
       "     'end': np.float64(125.4),\n",
       "     'confidence': 0.947},\n",
       "    {'text': 'build',\n",
       "     'start': np.float64(125.4),\n",
       "     'end': np.float64(125.68),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'from',\n",
       "     'start': np.float64(125.68),\n",
       "     'end': np.float64(125.9),\n",
       "     'confidence': 0.964},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(125.9),\n",
       "     'end': np.float64(126.18),\n",
       "     'confidence': 0.985}]},\n",
       "  {'id': 18,\n",
       "   'seek': 12616,\n",
       "   'start': np.float64(127.12),\n",
       "   'end': np.float64(134.62),\n",
       "   'text': \" ever growing field, right? So that's why I like choose this field. And that's why I'm in front\",\n",
       "   'tokens': [50408,\n",
       "    1562,\n",
       "    4194,\n",
       "    2519,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    407,\n",
       "    300,\n",
       "    311,\n",
       "    983,\n",
       "    286,\n",
       "    411,\n",
       "    2826,\n",
       "    341,\n",
       "    2519,\n",
       "    13,\n",
       "    400,\n",
       "    300,\n",
       "    311,\n",
       "    983,\n",
       "    286,\n",
       "    478,\n",
       "    294,\n",
       "    1868,\n",
       "    50788],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0942841387809591,\n",
       "   'compression_ratio': 1.5789473684210527,\n",
       "   'no_speech_prob': 0.001733751967549324,\n",
       "   'confidence': 0.878,\n",
       "   'words': [{'text': 'ever',\n",
       "     'start': np.float64(127.12),\n",
       "     'end': np.float64(127.34),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'growing',\n",
       "     'start': np.float64(127.34),\n",
       "     'end': np.float64(127.7),\n",
       "     'confidence': 0.634},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(127.7),\n",
       "     'end': np.float64(128.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'field,',\n",
       "     'start': np.float64(128.32),\n",
       "     'end': np.float64(128.8),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(129.14),\n",
       "     'end': np.float64(129.36),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(129.7),\n",
       "     'end': np.float64(130.02),\n",
       "     'confidence': 0.997},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(130.02),\n",
       "     'end': np.float64(130.92),\n",
       "     'confidence': 0.0},\n",
       "    {'text': \"that's\",\n",
       "     'start': np.float64(130.92),\n",
       "     'end': np.float64(131.28),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'why',\n",
       "     'start': np.float64(131.28),\n",
       "     'end': np.float64(131.46),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(131.46),\n",
       "     'end': np.float64(131.8),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(131.8),\n",
       "     'end': np.float64(132.0),\n",
       "     'confidence': 0.662},\n",
       "    {'text': 'choose',\n",
       "     'start': np.float64(132.0),\n",
       "     'end': np.float64(132.32),\n",
       "     'confidence': 0.485},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(132.32),\n",
       "     'end': np.float64(132.6),\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'field.',\n",
       "     'start': np.float64(132.6),\n",
       "     'end': np.float64(132.9),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(133.1),\n",
       "     'end': np.float64(133.12),\n",
       "     'confidence': 0.981},\n",
       "    {'text': \"that's\",\n",
       "     'start': np.float64(133.12),\n",
       "     'end': np.float64(133.44),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'why',\n",
       "     'start': np.float64(133.44),\n",
       "     'end': np.float64(133.6),\n",
       "     'confidence': 0.951},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(133.6),\n",
       "     'end': np.float64(133.76),\n",
       "     'confidence': 0.859},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(133.76),\n",
       "     'end': np.float64(134.14),\n",
       "     'confidence': 0.73},\n",
       "    {'text': 'front',\n",
       "     'start': np.float64(134.14),\n",
       "     'end': np.float64(134.62),\n",
       "     'confidence': 0.729}]},\n",
       "  {'id': 19,\n",
       "   'seek': 12616,\n",
       "   'start': np.float64(134.76),\n",
       "   'end': np.float64(142.66),\n",
       "   'text': \" of interviewing for this role here. That's a great background. And it's always awesome to hear how\",\n",
       "   'tokens': [50788,\n",
       "    295,\n",
       "    26524,\n",
       "    337,\n",
       "    341,\n",
       "    3090,\n",
       "    510,\n",
       "    13,\n",
       "    663,\n",
       "    311,\n",
       "    257,\n",
       "    869,\n",
       "    3678,\n",
       "    13,\n",
       "    400,\n",
       "    309,\n",
       "    311,\n",
       "    1009,\n",
       "    3476,\n",
       "    281,\n",
       "    1568,\n",
       "    577,\n",
       "    51200],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0942841387809591,\n",
       "   'compression_ratio': 1.5789473684210527,\n",
       "   'no_speech_prob': 0.001733751967549324,\n",
       "   'confidence': 0.936,\n",
       "   'words': [{'text': 'of',\n",
       "     'start': np.float64(134.76),\n",
       "     'end': np.float64(134.88),\n",
       "     'confidence': 0.997},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(134.88),\n",
       "     'end': np.float64(135.24),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'interviewing',\n",
       "     'start': np.float64(135.24),\n",
       "     'end': np.float64(135.36),\n",
       "     'confidence': 0.883},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(135.36),\n",
       "     'end': np.float64(135.74),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(135.74),\n",
       "     'end': np.float64(135.96),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'role',\n",
       "     'start': np.float64(135.96),\n",
       "     'end': np.float64(136.16),\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'here.',\n",
       "     'start': np.float64(136.16),\n",
       "     'end': np.float64(136.36),\n",
       "     'confidence': 0.688},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(137.18),\n",
       "     'end': np.float64(139.46),\n",
       "     'confidence': 0.0},\n",
       "    {'text': \"That's\",\n",
       "     'start': np.float64(139.46),\n",
       "     'end': np.float64(139.86),\n",
       "     'confidence': 0.916},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(139.86),\n",
       "     'end': np.float64(139.98),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'great',\n",
       "     'start': np.float64(139.98),\n",
       "     'end': np.float64(140.1),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'background.',\n",
       "     'start': np.float64(140.1),\n",
       "     'end': np.float64(140.56),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(141.02),\n",
       "     'end': np.float64(141.24),\n",
       "     'confidence': 0.995},\n",
       "    {'text': \"it's\",\n",
       "     'start': np.float64(141.24),\n",
       "     'end': np.float64(141.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'always',\n",
       "     'start': np.float64(141.38),\n",
       "     'end': np.float64(141.6),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'awesome',\n",
       "     'start': np.float64(141.6),\n",
       "     'end': np.float64(141.94),\n",
       "     'confidence': 0.956},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(141.94),\n",
       "     'end': np.float64(142.16),\n",
       "     'confidence': 0.929},\n",
       "    {'text': 'hear',\n",
       "     'start': np.float64(142.16),\n",
       "     'end': np.float64(142.34),\n",
       "     'confidence': 0.791},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(142.34),\n",
       "     'end': np.float64(142.66),\n",
       "     'confidence': 0.829}]},\n",
       "  {'id': 20,\n",
       "   'seek': 12616,\n",
       "   'start': np.float64(143.04),\n",
       "   'end': np.float64(147.8),\n",
       "   'text': ' those initial courses and projects really hooked you in. Now, let me dive a bit deeper into the',\n",
       "   'tokens': [51200,\n",
       "    729,\n",
       "    5883,\n",
       "    7712,\n",
       "    293,\n",
       "    4455,\n",
       "    534,\n",
       "    20410,\n",
       "    291,\n",
       "    294,\n",
       "    13,\n",
       "    823,\n",
       "    11,\n",
       "    718,\n",
       "    385,\n",
       "    9192,\n",
       "    257,\n",
       "    857,\n",
       "    7731,\n",
       "    666,\n",
       "    264,\n",
       "    51448],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0942841387809591,\n",
       "   'compression_ratio': 1.5789473684210527,\n",
       "   'no_speech_prob': 0.001733751967549324,\n",
       "   'confidence': 0.94,\n",
       "   'words': [{'text': 'those',\n",
       "     'start': np.float64(143.04),\n",
       "     'end': np.float64(143.18),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'initial',\n",
       "     'start': np.float64(143.18),\n",
       "     'end': np.float64(143.54),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'courses',\n",
       "     'start': np.float64(143.54),\n",
       "     'end': np.float64(143.92),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(143.92),\n",
       "     'end': np.float64(144.24),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'projects',\n",
       "     'start': np.float64(144.24),\n",
       "     'end': np.float64(144.64),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'really',\n",
       "     'start': np.float64(144.64),\n",
       "     'end': np.float64(145.14),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'hooked',\n",
       "     'start': np.float64(145.14),\n",
       "     'end': np.float64(145.38),\n",
       "     'confidence': 0.49},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(145.38),\n",
       "     'end': np.float64(145.58),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'in.',\n",
       "     'start': np.float64(145.58),\n",
       "     'end': np.float64(145.78),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'Now,',\n",
       "     'start': np.float64(145.94),\n",
       "     'end': np.float64(146.52),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'let',\n",
       "     'start': np.float64(146.62),\n",
       "     'end': np.float64(146.82),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'me',\n",
       "     'start': np.float64(146.82),\n",
       "     'end': np.float64(146.92),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'dive',\n",
       "     'start': np.float64(146.92),\n",
       "     'end': np.float64(147.08),\n",
       "     'confidence': 0.917},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(147.08),\n",
       "     'end': np.float64(147.18),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'bit',\n",
       "     'start': np.float64(147.18),\n",
       "     'end': np.float64(147.32),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'deeper',\n",
       "     'start': np.float64(147.32),\n",
       "     'end': np.float64(147.58),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'into',\n",
       "     'start': np.float64(147.58),\n",
       "     'end': np.float64(147.78),\n",
       "     'confidence': 0.789},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(147.78),\n",
       "     'end': np.float64(147.8),\n",
       "     'confidence': 0.972}]},\n",
       "  {'id': 21,\n",
       "   'seek': 12616,\n",
       "   'start': np.float64(147.8),\n",
       "   'end': np.float64(153.36),\n",
       "   'text': \" technical side. So for the next question, imagine you're working on a machine learning project where\",\n",
       "   'tokens': [51448,\n",
       "    6191,\n",
       "    1252,\n",
       "    13,\n",
       "    407,\n",
       "    337,\n",
       "    264,\n",
       "    958,\n",
       "    1168,\n",
       "    11,\n",
       "    3811,\n",
       "    291,\n",
       "    434,\n",
       "    1364,\n",
       "    322,\n",
       "    257,\n",
       "    3479,\n",
       "    2539,\n",
       "    1716,\n",
       "    689,\n",
       "    51720],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0942841387809591,\n",
       "   'compression_ratio': 1.5789473684210527,\n",
       "   'no_speech_prob': 0.001733751967549324,\n",
       "   'confidence': 0.951,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(147.8),\n",
       "     'end': np.float64(148.0),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'technical',\n",
       "     'start': np.float64(148.0),\n",
       "     'end': np.float64(148.26),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'side.',\n",
       "     'start': np.float64(148.26),\n",
       "     'end': np.float64(148.66),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(149.02),\n",
       "     'end': np.float64(149.52),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(149.52),\n",
       "     'end': np.float64(149.8),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(149.8),\n",
       "     'end': np.float64(149.92),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'next',\n",
       "     'start': np.float64(149.92),\n",
       "     'end': np.float64(150.06),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'question,',\n",
       "     'start': np.float64(150.06),\n",
       "     'end': np.float64(150.52),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'imagine',\n",
       "     'start': np.float64(151.0),\n",
       "     'end': np.float64(151.32),\n",
       "     'confidence': 0.989},\n",
       "    {'text': \"you're\",\n",
       "     'start': np.float64(151.32),\n",
       "     'end': np.float64(151.62),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'working',\n",
       "     'start': np.float64(151.62),\n",
       "     'end': np.float64(151.76),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(151.76),\n",
       "     'end': np.float64(151.94),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(151.94),\n",
       "     'end': np.float64(152.02),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'machine',\n",
       "     'start': np.float64(152.02),\n",
       "     'end': np.float64(152.24),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'learning',\n",
       "     'start': np.float64(152.24),\n",
       "     'end': np.float64(152.5),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'project',\n",
       "     'start': np.float64(152.5),\n",
       "     'end': np.float64(152.94),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'where',\n",
       "     'start': np.float64(152.94),\n",
       "     'end': np.float64(153.36),\n",
       "     'confidence': 0.469}]},\n",
       "  {'id': 22,\n",
       "   'seek': 15328,\n",
       "   'start': np.float64(153.38),\n",
       "   'end': np.float64(158.74),\n",
       "   'text': \" you have a data set that isn't perfectly clean. How would you go about handling missing data or\",\n",
       "   'tokens': [50364,\n",
       "    291,\n",
       "    362,\n",
       "    257,\n",
       "    1412,\n",
       "    992,\n",
       "    300,\n",
       "    1943,\n",
       "    380,\n",
       "    6239,\n",
       "    2541,\n",
       "    13,\n",
       "    1012,\n",
       "    576,\n",
       "    291,\n",
       "    352,\n",
       "    466,\n",
       "    13175,\n",
       "    5361,\n",
       "    1412,\n",
       "    420,\n",
       "    50648],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09827694994338015,\n",
       "   'compression_ratio': 1.6276150627615062,\n",
       "   'no_speech_prob': 0.001981219742447138,\n",
       "   'confidence': 0.967,\n",
       "   'words': [{'text': 'you',\n",
       "     'start': np.float64(153.38),\n",
       "     'end': np.float64(153.5),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'have',\n",
       "     'start': np.float64(153.5),\n",
       "     'end': np.float64(153.64),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(153.64),\n",
       "     'end': np.float64(153.72),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(153.72),\n",
       "     'end': np.float64(153.9),\n",
       "     'confidence': 0.772},\n",
       "    {'text': 'set',\n",
       "     'start': np.float64(153.9),\n",
       "     'end': np.float64(154.2),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(154.2),\n",
       "     'end': np.float64(154.56),\n",
       "     'confidence': 0.994},\n",
       "    {'text': \"isn't\",\n",
       "     'start': np.float64(154.56),\n",
       "     'end': np.float64(155.06),\n",
       "     'confidence': 0.963},\n",
       "    {'text': 'perfectly',\n",
       "     'start': np.float64(155.06),\n",
       "     'end': np.float64(155.4),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'clean.',\n",
       "     'start': np.float64(155.4),\n",
       "     'end': np.float64(155.76),\n",
       "     'confidence': 0.988},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(155.76),\n",
       "     'end': np.float64(156.24),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'How',\n",
       "     'start': np.float64(156.24),\n",
       "     'end': np.float64(156.5),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'would',\n",
       "     'start': np.float64(156.5),\n",
       "     'end': np.float64(156.64),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(156.64),\n",
       "     'end': np.float64(156.78),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'go',\n",
       "     'start': np.float64(156.78),\n",
       "     'end': np.float64(156.9),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(156.9),\n",
       "     'end': np.float64(157.1),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'handling',\n",
       "     'start': np.float64(157.1),\n",
       "     'end': np.float64(157.52),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'missing',\n",
       "     'start': np.float64(157.52),\n",
       "     'end': np.float64(157.96),\n",
       "     'confidence': 0.968},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(157.96),\n",
       "     'end': np.float64(158.34),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(158.34),\n",
       "     'end': np.float64(158.74),\n",
       "     'confidence': 0.804}]},\n",
       "  {'id': 23,\n",
       "   'seek': 15328,\n",
       "   'start': np.float64(158.74),\n",
       "   'end': np.float64(165.8),\n",
       "   'text': ' noisy data in that data set before you actually train your model? Yeah, so handling or cleaning the',\n",
       "   'tokens': [50648,\n",
       "    24518,\n",
       "    1412,\n",
       "    294,\n",
       "    300,\n",
       "    1412,\n",
       "    992,\n",
       "    949,\n",
       "    291,\n",
       "    767,\n",
       "    3847,\n",
       "    428,\n",
       "    2316,\n",
       "    30,\n",
       "    865,\n",
       "    11,\n",
       "    370,\n",
       "    13175,\n",
       "    420,\n",
       "    8924,\n",
       "    264,\n",
       "    50992],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09827694994338015,\n",
       "   'compression_ratio': 1.6276150627615062,\n",
       "   'no_speech_prob': 0.001981219742447138,\n",
       "   'confidence': 0.911,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(158.74),\n",
       "     'end': np.float64(159.1),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'noisy',\n",
       "     'start': np.float64(159.1),\n",
       "     'end': np.float64(159.28),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(159.28),\n",
       "     'end': np.float64(159.62),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(159.62),\n",
       "     'end': np.float64(159.84),\n",
       "     'confidence': 0.945},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(159.84),\n",
       "     'end': np.float64(159.98),\n",
       "     'confidence': 0.946},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(159.98),\n",
       "     'end': np.float64(160.16),\n",
       "     'confidence': 0.931},\n",
       "    {'text': 'set',\n",
       "     'start': np.float64(160.16),\n",
       "     'end': np.float64(160.46),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(160.46),\n",
       "     'end': np.float64(160.86),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'before',\n",
       "     'start': np.float64(160.86),\n",
       "     'end': np.float64(161.0),\n",
       "     'confidence': 0.85},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(161.0),\n",
       "     'end': np.float64(161.2),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(161.2),\n",
       "     'end': np.float64(161.46),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'train',\n",
       "     'start': np.float64(161.46),\n",
       "     'end': np.float64(161.72),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'your',\n",
       "     'start': np.float64(161.72),\n",
       "     'end': np.float64(161.86),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'model?',\n",
       "     'start': np.float64(161.86),\n",
       "     'end': np.float64(162.1),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(162.44),\n",
       "     'end': np.float64(163.36),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'Yeah,',\n",
       "     'start': np.float64(163.36),\n",
       "     'end': np.float64(163.78),\n",
       "     'confidence': 0.549},\n",
       "    {'text': 'so',\n",
       "     'start': np.float64(163.82),\n",
       "     'end': np.float64(164.08),\n",
       "     'confidence': 0.968},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(164.08),\n",
       "     'end': np.float64(164.88),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'handling',\n",
       "     'start': np.float64(164.88),\n",
       "     'end': np.float64(165.08),\n",
       "     'confidence': 0.962},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(165.08),\n",
       "     'end': np.float64(165.38),\n",
       "     'confidence': 0.936},\n",
       "    {'text': 'cleaning',\n",
       "     'start': np.float64(165.38),\n",
       "     'end': np.float64(165.7),\n",
       "     'confidence': 0.893},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(165.7),\n",
       "     'end': np.float64(165.8),\n",
       "     'confidence': 0.631}]},\n",
       "  {'id': 24,\n",
       "   'seek': 15328,\n",
       "   'start': np.float64(165.8),\n",
       "   'end': np.float64(173.44),\n",
       "   'text': \" data set is obviously one of the major parts of any, any ML project or whatever I'm doing. But it\",\n",
       "   'tokens': [50992,\n",
       "    1412,\n",
       "    992,\n",
       "    307,\n",
       "    2745,\n",
       "    472,\n",
       "    295,\n",
       "    264,\n",
       "    2563,\n",
       "    3166,\n",
       "    295,\n",
       "    604,\n",
       "    11,\n",
       "    604,\n",
       "    21601,\n",
       "    1716,\n",
       "    420,\n",
       "    2035,\n",
       "    286,\n",
       "    478,\n",
       "    884,\n",
       "    13,\n",
       "    583,\n",
       "    309,\n",
       "    51368],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09827694994338015,\n",
       "   'compression_ratio': 1.6276150627615062,\n",
       "   'no_speech_prob': 0.001981219742447138,\n",
       "   'confidence': 0.903,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(165.8),\n",
       "     'end': np.float64(166.02),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(166.02),\n",
       "     'end': np.float64(166.16),\n",
       "     'confidence': 0.815},\n",
       "    {'text': 'set',\n",
       "     'start': np.float64(166.16),\n",
       "     'end': np.float64(166.4),\n",
       "     'confidence': 0.961},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(166.4),\n",
       "     'end': np.float64(166.56),\n",
       "     'confidence': 0.965},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(166.56),\n",
       "     'end': np.float64(166.58),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'obviously',\n",
       "     'start': np.float64(166.58),\n",
       "     'end': np.float64(167.04),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'one',\n",
       "     'start': np.float64(167.04),\n",
       "     'end': np.float64(167.48),\n",
       "     'confidence': 0.944},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(167.48),\n",
       "     'end': np.float64(167.66),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(167.66),\n",
       "     'end': np.float64(167.86),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'major',\n",
       "     'start': np.float64(167.86),\n",
       "     'end': np.float64(168.58),\n",
       "     'confidence': 0.604},\n",
       "    {'text': 'parts',\n",
       "     'start': np.float64(168.58),\n",
       "     'end': np.float64(169.0),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(169.0),\n",
       "     'end': np.float64(169.26),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'any,',\n",
       "     'start': np.float64(169.26),\n",
       "     'end': np.float64(169.54),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(169.98),\n",
       "     'end': np.float64(170.4),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'any',\n",
       "     'start': np.float64(170.4),\n",
       "     'end': np.float64(170.52),\n",
       "     'confidence': 0.983},\n",
       "    {'text': 'ML',\n",
       "     'start': np.float64(170.52),\n",
       "     'end': np.float64(170.82),\n",
       "     'confidence': 0.917},\n",
       "    {'text': 'project',\n",
       "     'start': np.float64(170.82),\n",
       "     'end': np.float64(171.26),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(171.26),\n",
       "     'end': np.float64(171.58),\n",
       "     'confidence': 0.971},\n",
       "    {'text': 'whatever',\n",
       "     'start': np.float64(171.58),\n",
       "     'end': np.float64(171.84),\n",
       "     'confidence': 0.999},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(171.84),\n",
       "     'end': np.float64(172.16),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'doing.',\n",
       "     'start': np.float64(172.16),\n",
       "     'end': np.float64(172.34),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'But',\n",
       "     'start': np.float64(172.86),\n",
       "     'end': np.float64(173.2),\n",
       "     'confidence': 0.516},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(173.2),\n",
       "     'end': np.float64(173.44),\n",
       "     'confidence': 0.637}]},\n",
       "  {'id': 25,\n",
       "   'seek': 15328,\n",
       "   'start': np.float64(173.44),\n",
       "   'end': np.float64(180.06),\n",
       "   'text': \" really depends on what type of data I'm working with. Right. So for some data, actually missing\",\n",
       "   'tokens': [51368,\n",
       "    534,\n",
       "    5946,\n",
       "    322,\n",
       "    437,\n",
       "    2010,\n",
       "    295,\n",
       "    1412,\n",
       "    286,\n",
       "    478,\n",
       "    1364,\n",
       "    365,\n",
       "    13,\n",
       "    1779,\n",
       "    13,\n",
       "    407,\n",
       "    337,\n",
       "    512,\n",
       "    1412,\n",
       "    11,\n",
       "    767,\n",
       "    5361,\n",
       "    51704],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09827694994338015,\n",
       "   'compression_ratio': 1.6276150627615062,\n",
       "   'no_speech_prob': 0.001981219742447138,\n",
       "   'confidence': 0.956,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(173.44),\n",
       "     'end': np.float64(173.46),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'really',\n",
       "     'start': np.float64(173.46),\n",
       "     'end': np.float64(173.72),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'depends',\n",
       "     'start': np.float64(173.72),\n",
       "     'end': np.float64(174.12),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(174.12),\n",
       "     'end': np.float64(174.56),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(174.56),\n",
       "     'end': np.float64(174.96),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(174.96),\n",
       "     'end': np.float64(175.18),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(175.18),\n",
       "     'end': np.float64(175.5),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(175.5),\n",
       "     'end': np.float64(175.68),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(175.68),\n",
       "     'end': np.float64(175.88),\n",
       "     'confidence': 0.983},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(175.88),\n",
       "     'end': np.float64(176.1),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'working',\n",
       "     'start': np.float64(176.1),\n",
       "     'end': np.float64(176.34),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'with.',\n",
       "     'start': np.float64(176.34),\n",
       "     'end': np.float64(176.62),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'Right.',\n",
       "     'start': np.float64(176.9),\n",
       "     'end': np.float64(177.0),\n",
       "     'confidence': 0.758},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(177.34),\n",
       "     'end': np.float64(177.66),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(177.66),\n",
       "     'end': np.float64(178.22),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(178.22),\n",
       "     'end': np.float64(178.42),\n",
       "     'confidence': 0.765},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(178.42),\n",
       "     'end': np.float64(178.72),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(178.72),\n",
       "     'end': np.float64(178.86),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(178.86),\n",
       "     'end': np.float64(179.2),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(179.66),\n",
       "     'end': np.float64(179.72),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'missing',\n",
       "     'start': np.float64(179.72),\n",
       "     'end': np.float64(180.06),\n",
       "     'confidence': 0.817}]},\n",
       "  {'id': 26,\n",
       "   'seek': 18008,\n",
       "   'start': np.float64(180.08),\n",
       "   'end': np.float64(185.91),\n",
       "   'text': \" data might be a new info. So you don't, you can't do like you, you don't have to remove it. But for\",\n",
       "   'tokens': [50364,\n",
       "    1412,\n",
       "    1062,\n",
       "    312,\n",
       "    257,\n",
       "    777,\n",
       "    13614,\n",
       "    13,\n",
       "    407,\n",
       "    291,\n",
       "    500,\n",
       "    380,\n",
       "    11,\n",
       "    291,\n",
       "    393,\n",
       "    380,\n",
       "    360,\n",
       "    411,\n",
       "    291,\n",
       "    11,\n",
       "    291,\n",
       "    500,\n",
       "    380,\n",
       "    362,\n",
       "    281,\n",
       "    4159,\n",
       "    309,\n",
       "    13,\n",
       "    583,\n",
       "    337,\n",
       "    50668],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10241747986186635,\n",
       "   'compression_ratio': 1.755952380952381,\n",
       "   'no_speech_prob': 0.050343211740255356,\n",
       "   'confidence': 0.932,\n",
       "   'words': [{'text': 'data',\n",
       "     'start': np.float64(180.08),\n",
       "     'end': np.float64(180.4),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'might',\n",
       "     'start': np.float64(180.4),\n",
       "     'end': np.float64(180.64),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'be',\n",
       "     'start': np.float64(180.64),\n",
       "     'end': np.float64(180.88),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(180.88),\n",
       "     'end': np.float64(180.98),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'new',\n",
       "     'start': np.float64(180.98),\n",
       "     'end': np.float64(181.12),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'info.',\n",
       "     'start': np.float64(181.12),\n",
       "     'end': np.float64(181.46),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(181.82),\n",
       "     'end': np.float64(182.06),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(182.06),\n",
       "     'end': np.float64(182.2),\n",
       "     'confidence': 0.977},\n",
       "    {'text': \"don't,\",\n",
       "     'start': np.float64(182.2),\n",
       "     'end': np.float64(182.36),\n",
       "     'confidence': 0.796},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(182.36),\n",
       "     'end': np.float64(182.5),\n",
       "     'confidence': 0.997},\n",
       "    {'text': \"can't\",\n",
       "     'start': np.float64(182.5),\n",
       "     'end': np.float64(182.82),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(182.82),\n",
       "     'end': np.float64(182.98),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(182.98),\n",
       "     'end': np.float64(183.32),\n",
       "     'confidence': 0.743},\n",
       "    {'text': 'you,',\n",
       "     'start': np.float64(183.32),\n",
       "     'end': np.float64(183.56),\n",
       "     'confidence': 0.77},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(183.58),\n",
       "     'end': np.float64(183.84),\n",
       "     'confidence': 0.98},\n",
       "    {'text': \"don't\",\n",
       "     'start': np.float64(183.84),\n",
       "     'end': np.float64(184.1),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'have',\n",
       "     'start': np.float64(184.1),\n",
       "     'end': np.float64(184.24),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(184.24),\n",
       "     'end': np.float64(184.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'remove',\n",
       "     'start': np.float64(184.38),\n",
       "     'end': np.float64(184.6),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'it.',\n",
       "     'start': np.float64(184.6),\n",
       "     'end': np.float64(184.84),\n",
       "     'confidence': 0.97},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(184.92),\n",
       "     'end': np.float64(185.44),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'But',\n",
       "     'start': np.float64(185.44),\n",
       "     'end': np.float64(185.68),\n",
       "     'confidence': 0.706},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(185.68),\n",
       "     'end': np.float64(185.91),\n",
       "     'confidence': 0.774}]},\n",
       "  {'id': 27,\n",
       "   'seek': 18008,\n",
       "   'start': np.float64(185.91),\n",
       "   'end': np.float64(194.88),\n",
       "   'text': ' some, for some like field or for some data, you actually have to remove it. And it also depends',\n",
       "   'tokens': [50668,\n",
       "    512,\n",
       "    11,\n",
       "    337,\n",
       "    512,\n",
       "    411,\n",
       "    2519,\n",
       "    420,\n",
       "    337,\n",
       "    512,\n",
       "    1412,\n",
       "    11,\n",
       "    291,\n",
       "    767,\n",
       "    362,\n",
       "    281,\n",
       "    4159,\n",
       "    309,\n",
       "    13,\n",
       "    400,\n",
       "    309,\n",
       "    611,\n",
       "    5946,\n",
       "    51108],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10241747986186635,\n",
       "   'compression_ratio': 1.755952380952381,\n",
       "   'no_speech_prob': 0.050343211740255356,\n",
       "   'confidence': 0.906,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(185.91),\n",
       "     'end': np.float64(186.28),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'some,',\n",
       "     'start': np.float64(186.28),\n",
       "     'end': np.float64(186.42),\n",
       "     'confidence': 0.912},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(186.56),\n",
       "     'end': np.float64(186.86),\n",
       "     'confidence': 0.973},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(186.86),\n",
       "     'end': np.float64(187.18),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(187.18),\n",
       "     'end': np.float64(187.66),\n",
       "     'confidence': 0.669},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(187.66),\n",
       "     'end': np.float64(188.58),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'field',\n",
       "     'start': np.float64(188.58),\n",
       "     'end': np.float64(188.7),\n",
       "     'confidence': 0.531},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(188.7),\n",
       "     'end': np.float64(189.02),\n",
       "     'confidence': 0.622},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(189.02),\n",
       "     'end': np.float64(189.16),\n",
       "     'confidence': 0.975},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(189.16),\n",
       "     'end': np.float64(189.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(189.38),\n",
       "     'end': np.float64(189.7),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(189.7),\n",
       "     'end': np.float64(190.28),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(190.28),\n",
       "     'end': np.float64(190.78),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(190.78),\n",
       "     'end': np.float64(191.06),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'have',\n",
       "     'start': np.float64(191.06),\n",
       "     'end': np.float64(191.28),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(191.28),\n",
       "     'end': np.float64(191.44),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'remove',\n",
       "     'start': np.float64(191.44),\n",
       "     'end': np.float64(191.66),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'it.',\n",
       "     'start': np.float64(191.66),\n",
       "     'end': np.float64(191.9),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(192.06),\n",
       "     'end': np.float64(192.62),\n",
       "     'confidence': 0.979},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(192.62),\n",
       "     'end': np.float64(193.68),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(193.68),\n",
       "     'end': np.float64(193.9),\n",
       "     'confidence': 0.924},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(193.9),\n",
       "     'end': np.float64(194.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'also',\n",
       "     'start': np.float64(194.32),\n",
       "     'end': np.float64(194.52),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'depends',\n",
       "     'start': np.float64(194.52),\n",
       "     'end': np.float64(194.88),\n",
       "     'confidence': 0.911}]},\n",
       "  {'id': 28,\n",
       "   'seek': 18008,\n",
       "   'start': np.float64(195.02),\n",
       "   'end': np.float64(202.22),\n",
       "   'text': \" on what algorithm I'm using. Right. So if I'm, if I'm using, for example, for example, if I'm using\",\n",
       "   'tokens': [51108,\n",
       "    322,\n",
       "    437,\n",
       "    9284,\n",
       "    286,\n",
       "    478,\n",
       "    1228,\n",
       "    13,\n",
       "    1779,\n",
       "    13,\n",
       "    407,\n",
       "    498,\n",
       "    286,\n",
       "    478,\n",
       "    11,\n",
       "    498,\n",
       "    286,\n",
       "    478,\n",
       "    1228,\n",
       "    11,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    498,\n",
       "    286,\n",
       "    478,\n",
       "    1228,\n",
       "    51472],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10241747986186635,\n",
       "   'compression_ratio': 1.755952380952381,\n",
       "   'no_speech_prob': 0.050343211740255356,\n",
       "   'confidence': 0.969,\n",
       "   'words': [{'text': 'on',\n",
       "     'start': np.float64(195.02),\n",
       "     'end': np.float64(195.22),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(195.22),\n",
       "     'end': np.float64(195.6),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(195.6),\n",
       "     'end': np.float64(195.92),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'algorithm',\n",
       "     'start': np.float64(195.92),\n",
       "     'end': np.float64(196.34),\n",
       "     'confidence': 0.983},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(196.34),\n",
       "     'end': np.float64(196.82),\n",
       "     'confidence': 0.976},\n",
       "    {'text': 'using.',\n",
       "     'start': np.float64(196.82),\n",
       "     'end': np.float64(197.12),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'Right.',\n",
       "     'start': np.float64(197.32),\n",
       "     'end': np.float64(197.56),\n",
       "     'confidence': 0.739},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(197.66),\n",
       "     'end': np.float64(197.82),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(197.82),\n",
       "     'end': np.float64(197.96),\n",
       "     'confidence': 0.987},\n",
       "    {'text': \"I'm,\",\n",
       "     'start': np.float64(197.96),\n",
       "     'end': np.float64(198.16),\n",
       "     'confidence': 0.973},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(198.18),\n",
       "     'end': np.float64(198.38),\n",
       "     'confidence': 0.997},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(198.38),\n",
       "     'end': np.float64(198.6),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'using,',\n",
       "     'start': np.float64(198.6),\n",
       "     'end': np.float64(198.86),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(198.96),\n",
       "     'end': np.float64(199.14),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(199.14),\n",
       "     'end': np.float64(199.36),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(199.36),\n",
       "     'end': np.float64(199.52),\n",
       "     'confidence': 1.0},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(200.16),\n",
       "     'end': np.float64(200.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(200.32),\n",
       "     'end': np.float64(200.6),\n",
       "     'confidence': 0.936},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(200.6),\n",
       "     'end': np.float64(201.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(201.32),\n",
       "     'end': np.float64(201.58),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(201.74),\n",
       "     'end': np.float64(201.84),\n",
       "     'confidence': 0.974},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(201.84),\n",
       "     'end': np.float64(202.0),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'using',\n",
       "     'start': np.float64(202.0),\n",
       "     'end': np.float64(202.22),\n",
       "     'confidence': 0.847}]},\n",
       "  {'id': 29,\n",
       "   'seek': 20224,\n",
       "   'start': np.float64(203.04),\n",
       "   'end': np.float64(210.45),\n",
       "   'text': \" linear regression, you, you don't want these like NAN values in your data set. So you, what we can\",\n",
       "   'tokens': [50400,\n",
       "    8213,\n",
       "    24590,\n",
       "    11,\n",
       "    291,\n",
       "    11,\n",
       "    291,\n",
       "    500,\n",
       "    380,\n",
       "    528,\n",
       "    613,\n",
       "    411,\n",
       "    426,\n",
       "    1770,\n",
       "    4190,\n",
       "    294,\n",
       "    428,\n",
       "    1412,\n",
       "    992,\n",
       "    13,\n",
       "    407,\n",
       "    291,\n",
       "    11,\n",
       "    437,\n",
       "    321,\n",
       "    393,\n",
       "    50776],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1374959574117289,\n",
       "   'compression_ratio': 1.6032608695652173,\n",
       "   'no_speech_prob': 0.10820125043392181,\n",
       "   'confidence': 0.87,\n",
       "   'words': [{'text': 'linear',\n",
       "     'start': np.float64(203.04),\n",
       "     'end': np.float64(203.32),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'regression,',\n",
       "     'start': np.float64(203.32),\n",
       "     'end': np.float64(203.82),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'you,',\n",
       "     'start': np.float64(204.0),\n",
       "     'end': np.float64(204.38),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(204.52),\n",
       "     'end': np.float64(204.72),\n",
       "     'confidence': 0.998},\n",
       "    {'text': \"don't\",\n",
       "     'start': np.float64(204.72),\n",
       "     'end': np.float64(205.02),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'want',\n",
       "     'start': np.float64(205.02),\n",
       "     'end': np.float64(205.26),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'these',\n",
       "     'start': np.float64(205.26),\n",
       "     'end': np.float64(205.66),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(205.66),\n",
       "     'end': np.float64(206.04),\n",
       "     'confidence': 0.896},\n",
       "    {'text': 'NAN',\n",
       "     'start': np.float64(206.04),\n",
       "     'end': np.float64(206.66),\n",
       "     'confidence': 0.464},\n",
       "    {'text': 'values',\n",
       "     'start': np.float64(206.66),\n",
       "     'end': np.float64(207.16),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(207.16),\n",
       "     'end': np.float64(207.82),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'your',\n",
       "     'start': np.float64(207.82),\n",
       "     'end': np.float64(207.98),\n",
       "     'confidence': 0.915},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(207.98),\n",
       "     'end': np.float64(208.26),\n",
       "     'confidence': 0.862},\n",
       "    {'text': 'set.',\n",
       "     'start': np.float64(208.26),\n",
       "     'end': np.float64(208.52),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(208.72),\n",
       "     'end': np.float64(209.12),\n",
       "     'confidence': 0.879},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(209.12),\n",
       "     'end': np.float64(209.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'you,',\n",
       "     'start': np.float64(209.56),\n",
       "     'end': np.float64(209.78),\n",
       "     'confidence': 0.747},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(209.88),\n",
       "     'end': np.float64(210.12),\n",
       "     'confidence': 0.773},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(210.12),\n",
       "     'end': np.float64(210.28),\n",
       "     'confidence': 0.873},\n",
       "    {'text': 'can',\n",
       "     'start': np.float64(210.28),\n",
       "     'end': np.float64(210.45),\n",
       "     'confidence': 0.851}]},\n",
       "  {'id': 30,\n",
       "   'seek': 20224,\n",
       "   'start': np.float64(210.45),\n",
       "   'end': np.float64(219.92),\n",
       "   'text': ' do is what we can simply fill them up with the mean values or like mode values. But those are not',\n",
       "   'tokens': [50776,\n",
       "    360,\n",
       "    307,\n",
       "    437,\n",
       "    321,\n",
       "    393,\n",
       "    2935,\n",
       "    2836,\n",
       "    552,\n",
       "    493,\n",
       "    365,\n",
       "    264,\n",
       "    914,\n",
       "    4190,\n",
       "    420,\n",
       "    411,\n",
       "    4391,\n",
       "    4190,\n",
       "    13,\n",
       "    583,\n",
       "    729,\n",
       "    366,\n",
       "    406,\n",
       "    51252],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1374959574117289,\n",
       "   'compression_ratio': 1.6032608695652173,\n",
       "   'no_speech_prob': 0.10820125043392181,\n",
       "   'confidence': 0.892,\n",
       "   'words': [{'text': 'do',\n",
       "     'start': np.float64(210.45),\n",
       "     'end': np.float64(210.72),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(210.72),\n",
       "     'end': np.float64(210.98),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(210.98),\n",
       "     'end': np.float64(211.22),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(211.22),\n",
       "     'end': np.float64(211.48),\n",
       "     'confidence': 0.884},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(211.48),\n",
       "     'end': np.float64(212.14),\n",
       "     'confidence': 0.786},\n",
       "    {'text': 'can',\n",
       "     'start': np.float64(212.14),\n",
       "     'end': np.float64(212.32),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'simply',\n",
       "     'start': np.float64(212.32),\n",
       "     'end': np.float64(212.66),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'fill',\n",
       "     'start': np.float64(212.66),\n",
       "     'end': np.float64(213.22),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'them',\n",
       "     'start': np.float64(213.22),\n",
       "     'end': np.float64(213.42),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'up',\n",
       "     'start': np.float64(213.42),\n",
       "     'end': np.float64(213.68),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'with',\n",
       "     'start': np.float64(213.68),\n",
       "     'end': np.float64(214.02),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(214.02),\n",
       "     'end': np.float64(214.18),\n",
       "     'confidence': 0.972},\n",
       "    {'text': 'mean',\n",
       "     'start': np.float64(214.18),\n",
       "     'end': np.float64(214.4),\n",
       "     'confidence': 0.872},\n",
       "    {'text': 'values',\n",
       "     'start': np.float64(214.4),\n",
       "     'end': np.float64(214.82),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(214.82),\n",
       "     'end': np.float64(215.18),\n",
       "     'confidence': 0.96},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(215.18),\n",
       "     'end': np.float64(215.4),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'mode',\n",
       "     'start': np.float64(215.4),\n",
       "     'end': np.float64(215.68),\n",
       "     'confidence': 0.529},\n",
       "    {'text': 'values.',\n",
       "     'start': np.float64(215.68),\n",
       "     'end': np.float64(216.12),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(216.38),\n",
       "     'end': np.float64(217.0),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'But',\n",
       "     'start': np.float64(217.0),\n",
       "     'end': np.float64(217.4),\n",
       "     'confidence': 0.978},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(217.4),\n",
       "     'end': np.float64(219.2),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'those',\n",
       "     'start': np.float64(219.2),\n",
       "     'end': np.float64(219.42),\n",
       "     'confidence': 0.523},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(219.42),\n",
       "     'end': np.float64(219.8),\n",
       "     'confidence': 0.924},\n",
       "    {'text': 'not',\n",
       "     'start': np.float64(219.8),\n",
       "     'end': np.float64(219.92),\n",
       "     'confidence': 0.673}]},\n",
       "  {'id': 31,\n",
       "   'seek': 20224,\n",
       "   'start': np.float64(219.92),\n",
       "   'end': np.float64(230.34),\n",
       "   'text': ' always the right choices. Right. And you can like, there are many like choices here about how, how',\n",
       "   'tokens': [51252,\n",
       "    1009,\n",
       "    264,\n",
       "    558,\n",
       "    7994,\n",
       "    13,\n",
       "    1779,\n",
       "    13,\n",
       "    400,\n",
       "    291,\n",
       "    393,\n",
       "    411,\n",
       "    11,\n",
       "    456,\n",
       "    366,\n",
       "    867,\n",
       "    411,\n",
       "    7994,\n",
       "    510,\n",
       "    466,\n",
       "    577,\n",
       "    11,\n",
       "    577,\n",
       "    51768],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1374959574117289,\n",
       "   'compression_ratio': 1.6032608695652173,\n",
       "   'no_speech_prob': 0.10820125043392181,\n",
       "   'confidence': 0.9,\n",
       "   'words': [{'text': 'always',\n",
       "     'start': np.float64(219.92),\n",
       "     'end': np.float64(220.42),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(220.42),\n",
       "     'end': np.float64(220.88),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'right',\n",
       "     'start': np.float64(220.88),\n",
       "     'end': np.float64(221.08),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'choices.',\n",
       "     'start': np.float64(221.08),\n",
       "     'end': np.float64(221.66),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(221.92),\n",
       "     'end': np.float64(223.96),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'Right.',\n",
       "     'start': np.float64(223.96),\n",
       "     'end': np.float64(224.18),\n",
       "     'confidence': 0.967},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(224.28),\n",
       "     'end': np.float64(224.54),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(224.54),\n",
       "     'end': np.float64(224.84),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'can',\n",
       "     'start': np.float64(224.84),\n",
       "     'end': np.float64(225.04),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(225.04),\n",
       "     'end': np.float64(225.2),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like,',\n",
       "     'start': np.float64(225.2),\n",
       "     'end': np.float64(225.46),\n",
       "     'confidence': 0.546},\n",
       "    {'text': 'there',\n",
       "     'start': np.float64(225.66),\n",
       "     'end': np.float64(225.7),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(225.7),\n",
       "     'end': np.float64(225.86),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(225.86),\n",
       "     'end': np.float64(226.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'many',\n",
       "     'start': np.float64(226.56),\n",
       "     'end': np.float64(226.74),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(226.74),\n",
       "     'end': np.float64(227.52),\n",
       "     'confidence': 0.504},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(227.52),\n",
       "     'end': np.float64(228.2),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'choices',\n",
       "     'start': np.float64(228.2),\n",
       "     'end': np.float64(228.3),\n",
       "     'confidence': 0.938},\n",
       "    {'text': 'here',\n",
       "     'start': np.float64(228.3),\n",
       "     'end': np.float64(228.92),\n",
       "     'confidence': 0.96},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(228.92),\n",
       "     'end': np.float64(229.58),\n",
       "     'confidence': 0.955},\n",
       "    {'text': 'how,',\n",
       "     'start': np.float64(229.58),\n",
       "     'end': np.float64(229.94),\n",
       "     'confidence': 0.888},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(230.04),\n",
       "     'end': np.float64(230.34),\n",
       "     'confidence': 0.759}]},\n",
       "  {'id': 32,\n",
       "   'seek': 23032,\n",
       "   'start': np.float64(230.42),\n",
       "   'end': np.float64(238.2),\n",
       "   'text': ' would you clean the data? And if the, if the data is like, if the data is what, if the data is like',\n",
       "   'tokens': [50364,\n",
       "    576,\n",
       "    291,\n",
       "    2541,\n",
       "    264,\n",
       "    1412,\n",
       "    30,\n",
       "    400,\n",
       "    498,\n",
       "    264,\n",
       "    11,\n",
       "    498,\n",
       "    264,\n",
       "    1412,\n",
       "    307,\n",
       "    411,\n",
       "    11,\n",
       "    498,\n",
       "    264,\n",
       "    1412,\n",
       "    307,\n",
       "    437,\n",
       "    11,\n",
       "    498,\n",
       "    264,\n",
       "    1412,\n",
       "    307,\n",
       "    411,\n",
       "    50756],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14291017601288944,\n",
       "   'compression_ratio': 1.8322981366459627,\n",
       "   'no_speech_prob': 0.04178939014673233,\n",
       "   'confidence': 0.963,\n",
       "   'words': [{'text': 'would',\n",
       "     'start': np.float64(230.42),\n",
       "     'end': np.float64(230.56),\n",
       "     'confidence': 0.922},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(230.56),\n",
       "     'end': np.float64(230.68),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'clean',\n",
       "     'start': np.float64(230.68),\n",
       "     'end': np.float64(230.92),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(230.92),\n",
       "     'end': np.float64(231.12),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'data?',\n",
       "     'start': np.float64(231.12),\n",
       "     'end': np.float64(231.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(231.56),\n",
       "     'end': np.float64(232.18),\n",
       "     'confidence': 0.938},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(232.18),\n",
       "     'end': np.float64(232.74),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'the,',\n",
       "     'start': np.float64(232.74),\n",
       "     'end': np.float64(232.9),\n",
       "     'confidence': 0.942},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(232.92),\n",
       "     'end': np.float64(233.08),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(233.08),\n",
       "     'end': np.float64(233.24),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(233.24),\n",
       "     'end': np.float64(233.48),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(233.48),\n",
       "     'end': np.float64(233.8),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'like,',\n",
       "     'start': np.float64(233.8),\n",
       "     'end': np.float64(234.18),\n",
       "     'confidence': 0.945},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(234.42),\n",
       "     'end': np.float64(234.94),\n",
       "     'confidence': 0.973},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(234.94),\n",
       "     'end': np.float64(235.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(235.56),\n",
       "     'end': np.float64(235.68),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(235.68),\n",
       "     'end': np.float64(235.92),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(235.92),\n",
       "     'end': np.float64(236.18),\n",
       "     'confidence': 0.993},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(236.18),\n",
       "     'end': np.float64(236.78),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'what,',\n",
       "     'start': np.float64(236.78),\n",
       "     'end': np.float64(236.92),\n",
       "     'confidence': 0.673},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(237.04),\n",
       "     'end': np.float64(237.38),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(237.38),\n",
       "     'end': np.float64(237.52),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(237.52),\n",
       "     'end': np.float64(237.76),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(237.76),\n",
       "     'end': np.float64(238.0),\n",
       "     'confidence': 0.969},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(238.0),\n",
       "     'end': np.float64(238.2),\n",
       "     'confidence': 0.917}]},\n",
       "  {'id': 33,\n",
       "   'seek': 23032,\n",
       "   'start': np.float64(239.3),\n",
       "   'end': np.float64(245.13),\n",
       "   'text': ' time series data, right? If the data is time series data, then you can fill the, fill the NAN',\n",
       "   'tokens': [50808,\n",
       "    565,\n",
       "    2638,\n",
       "    1412,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    759,\n",
       "    264,\n",
       "    1412,\n",
       "    307,\n",
       "    565,\n",
       "    2638,\n",
       "    1412,\n",
       "    11,\n",
       "    550,\n",
       "    291,\n",
       "    393,\n",
       "    2836,\n",
       "    264,\n",
       "    11,\n",
       "    2836,\n",
       "    264,\n",
       "    426,\n",
       "    1770,\n",
       "    51116],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14291017601288944,\n",
       "   'compression_ratio': 1.8322981366459627,\n",
       "   'no_speech_prob': 0.04178939014673233,\n",
       "   'confidence': 0.934,\n",
       "   'words': [{'text': 'time',\n",
       "     'start': np.float64(239.3),\n",
       "     'end': np.float64(239.5),\n",
       "     'confidence': 0.959},\n",
       "    {'text': 'series',\n",
       "     'start': np.float64(239.5),\n",
       "     'end': np.float64(239.76),\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(239.76),\n",
       "     'end': np.float64(240.08),\n",
       "     'confidence': 0.983},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(240.3),\n",
       "     'end': np.float64(240.66),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'If',\n",
       "     'start': np.float64(240.82),\n",
       "     'end': np.float64(241.16),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(241.16),\n",
       "     'end': np.float64(241.26),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(241.26),\n",
       "     'end': np.float64(241.46),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(241.46),\n",
       "     'end': np.float64(241.62),\n",
       "     'confidence': 0.981},\n",
       "    {'text': 'time',\n",
       "     'start': np.float64(241.62),\n",
       "     'end': np.float64(241.78),\n",
       "     'confidence': 0.978},\n",
       "    {'text': 'series',\n",
       "     'start': np.float64(241.78),\n",
       "     'end': np.float64(242.04),\n",
       "     'confidence': 0.978},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(242.04),\n",
       "     'end': np.float64(242.36),\n",
       "     'confidence': 0.969},\n",
       "    {'text': 'then',\n",
       "     'start': np.float64(242.48),\n",
       "     'end': np.float64(242.62),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(242.62),\n",
       "     'end': np.float64(242.76),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'can',\n",
       "     'start': np.float64(242.76),\n",
       "     'end': np.float64(242.98),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(242.98),\n",
       "     'end': np.float64(243.38),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'fill',\n",
       "     'start': np.float64(243.38),\n",
       "     'end': np.float64(243.64),\n",
       "     'confidence': 0.924},\n",
       "    {'text': 'the,',\n",
       "     'start': np.float64(243.64),\n",
       "     'end': np.float64(243.88),\n",
       "     'confidence': 0.816},\n",
       "    {'text': 'fill',\n",
       "     'start': np.float64(243.98),\n",
       "     'end': np.float64(244.26),\n",
       "     'confidence': 0.858},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(244.26),\n",
       "     'end': np.float64(244.52),\n",
       "     'confidence': 0.97},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(244.52),\n",
       "     'end': np.float64(245.02),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'NAN',\n",
       "     'start': np.float64(245.02),\n",
       "     'end': np.float64(245.13),\n",
       "     'confidence': 0.719}]},\n",
       "  {'id': 34,\n",
       "   'seek': 23032,\n",
       "   'start': np.float64(245.13),\n",
       "   'end': np.float64(254.04),\n",
       "   'text': ' values with only the previous, previous time period value. Right. This is also a way or if you, like,',\n",
       "   'tokens': [51116,\n",
       "    4190,\n",
       "    365,\n",
       "    787,\n",
       "    264,\n",
       "    3894,\n",
       "    11,\n",
       "    3894,\n",
       "    565,\n",
       "    2896,\n",
       "    2158,\n",
       "    13,\n",
       "    1779,\n",
       "    13,\n",
       "    639,\n",
       "    307,\n",
       "    611,\n",
       "    257,\n",
       "    636,\n",
       "    420,\n",
       "    498,\n",
       "    291,\n",
       "    11,\n",
       "    411,\n",
       "    11,\n",
       "    51548],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14291017601288944,\n",
       "   'compression_ratio': 1.8322981366459627,\n",
       "   'no_speech_prob': 0.04178939014673233,\n",
       "   'confidence': 0.873,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(245.13),\n",
       "     'end': np.float64(245.54),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'values',\n",
       "     'start': np.float64(245.54),\n",
       "     'end': np.float64(245.82),\n",
       "     'confidence': 0.997},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(245.82),\n",
       "     'end': np.float64(246.2),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'with',\n",
       "     'start': np.float64(246.2),\n",
       "     'end': np.float64(246.44),\n",
       "     'confidence': 0.971},\n",
       "    {'text': 'only',\n",
       "     'start': np.float64(246.44),\n",
       "     'end': np.float64(246.96),\n",
       "     'confidence': 0.96},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(246.96),\n",
       "     'end': np.float64(247.14),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'previous,',\n",
       "     'start': np.float64(247.14),\n",
       "     'end': np.float64(247.44),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'previous',\n",
       "     'start': np.float64(247.58),\n",
       "     'end': np.float64(248.02),\n",
       "     'confidence': 0.981},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(248.02),\n",
       "     'end': np.float64(248.8),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'time',\n",
       "     'start': np.float64(248.8),\n",
       "     'end': np.float64(248.94),\n",
       "     'confidence': 0.959},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(248.94),\n",
       "     'end': np.float64(249.46),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'period',\n",
       "     'start': np.float64(249.46),\n",
       "     'end': np.float64(249.56),\n",
       "     'confidence': 0.632},\n",
       "    {'text': 'value.',\n",
       "     'start': np.float64(249.56),\n",
       "     'end': np.float64(249.96),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'Right.',\n",
       "     'start': np.float64(250.24),\n",
       "     'end': np.float64(250.5),\n",
       "     'confidence': 0.989},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(250.5),\n",
       "     'end': np.float64(250.96),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'This',\n",
       "     'start': np.float64(250.96),\n",
       "     'end': np.float64(251.1),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(251.1),\n",
       "     'end': np.float64(251.22),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'also',\n",
       "     'start': np.float64(251.22),\n",
       "     'end': np.float64(251.48),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(251.48),\n",
       "     'end': np.float64(251.7),\n",
       "     'confidence': 0.9},\n",
       "    {'text': 'way',\n",
       "     'start': np.float64(251.7),\n",
       "     'end': np.float64(251.8),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(251.8),\n",
       "     'end': np.float64(252.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(252.56),\n",
       "     'end': np.float64(252.72),\n",
       "     'confidence': 0.436},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(252.72),\n",
       "     'end': np.float64(253.26),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(253.26),\n",
       "     'end': np.float64(253.46),\n",
       "     'confidence': 0.69},\n",
       "    {'text': 'you,',\n",
       "     'start': np.float64(253.46),\n",
       "     'end': np.float64(253.66),\n",
       "     'confidence': 0.786},\n",
       "    {'text': 'like,',\n",
       "     'start': np.float64(253.8),\n",
       "     'end': np.float64(254.04),\n",
       "     'confidence': 0.7}]},\n",
       "  {'id': 35,\n",
       "   'seek': 25400,\n",
       "   'start': np.float64(254.72),\n",
       "   'end': np.float64(261.61),\n",
       "   'text': ' so there are multiple ways. And if you want one single answer, it is a bit difficult to give one',\n",
       "   'tokens': [50412,\n",
       "    370,\n",
       "    456,\n",
       "    366,\n",
       "    3866,\n",
       "    2098,\n",
       "    13,\n",
       "    400,\n",
       "    498,\n",
       "    291,\n",
       "    528,\n",
       "    472,\n",
       "    2167,\n",
       "    1867,\n",
       "    11,\n",
       "    309,\n",
       "    307,\n",
       "    257,\n",
       "    857,\n",
       "    2252,\n",
       "    281,\n",
       "    976,\n",
       "    472,\n",
       "    50748],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10166075794967179,\n",
       "   'compression_ratio': 1.880952380952381,\n",
       "   'no_speech_prob': 0.042016398161649704,\n",
       "   'confidence': 0.926,\n",
       "   'words': [{'text': 'so',\n",
       "     'start': np.float64(254.72),\n",
       "     'end': np.float64(255.26),\n",
       "     'confidence': 0.941},\n",
       "    {'text': 'there',\n",
       "     'start': np.float64(255.26),\n",
       "     'end': np.float64(255.42),\n",
       "     'confidence': 0.975},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(255.42),\n",
       "     'end': np.float64(255.58),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'multiple',\n",
       "     'start': np.float64(255.58),\n",
       "     'end': np.float64(255.9),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'ways.',\n",
       "     'start': np.float64(255.9),\n",
       "     'end': np.float64(256.24),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(256.34),\n",
       "     'end': np.float64(256.54),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(256.54),\n",
       "     'end': np.float64(256.96),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(256.96),\n",
       "     'end': np.float64(257.1),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'want',\n",
       "     'start': np.float64(257.1),\n",
       "     'end': np.float64(257.34),\n",
       "     'confidence': 0.986},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(257.34),\n",
       "     'end': np.float64(258.36),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'one',\n",
       "     'start': np.float64(258.36),\n",
       "     'end': np.float64(258.52),\n",
       "     'confidence': 0.897},\n",
       "    {'text': 'single',\n",
       "     'start': np.float64(258.52),\n",
       "     'end': np.float64(258.82),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'answer,',\n",
       "     'start': np.float64(258.82),\n",
       "     'end': np.float64(259.18),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(259.3),\n",
       "     'end': np.float64(259.4),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(259.4),\n",
       "     'end': np.float64(259.52),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(259.52),\n",
       "     'end': np.float64(259.62),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'bit',\n",
       "     'start': np.float64(259.62),\n",
       "     'end': np.float64(259.78),\n",
       "     'confidence': 0.993},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(259.78),\n",
       "     'end': np.float64(260.72),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'difficult',\n",
       "     'start': np.float64(260.72),\n",
       "     'end': np.float64(260.96),\n",
       "     'confidence': 0.613},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(260.96),\n",
       "     'end': np.float64(261.26),\n",
       "     'confidence': 0.952},\n",
       "    {'text': 'give',\n",
       "     'start': np.float64(261.26),\n",
       "     'end': np.float64(261.46),\n",
       "     'confidence': 0.89},\n",
       "    {'text': 'one',\n",
       "     'start': np.float64(261.46),\n",
       "     'end': np.float64(261.61),\n",
       "     'confidence': 0.552}]},\n",
       "  {'id': 36,\n",
       "   'seek': 25400,\n",
       "   'start': np.float64(261.61),\n",
       "   'end': np.float64(267.42),\n",
       "   'text': ' because it highly depends on which model are you using and what type of data you have got and what',\n",
       "   'tokens': [50748,\n",
       "    570,\n",
       "    309,\n",
       "    5405,\n",
       "    5946,\n",
       "    322,\n",
       "    597,\n",
       "    2316,\n",
       "    366,\n",
       "    291,\n",
       "    1228,\n",
       "    293,\n",
       "    437,\n",
       "    2010,\n",
       "    295,\n",
       "    1412,\n",
       "    291,\n",
       "    362,\n",
       "    658,\n",
       "    293,\n",
       "    437,\n",
       "    51048],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10166075794967179,\n",
       "   'compression_ratio': 1.880952380952381,\n",
       "   'no_speech_prob': 0.042016398161649704,\n",
       "   'confidence': 0.922,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(261.61),\n",
       "     'end': np.float64(261.92),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'because',\n",
       "     'start': np.float64(261.92),\n",
       "     'end': np.float64(262.08),\n",
       "     'confidence': 1.0},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(262.08),\n",
       "     'end': np.float64(262.8),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(262.8),\n",
       "     'end': np.float64(262.92),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'highly',\n",
       "     'start': np.float64(262.92),\n",
       "     'end': np.float64(263.22),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'depends',\n",
       "     'start': np.float64(263.22),\n",
       "     'end': np.float64(263.58),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(263.58),\n",
       "     'end': np.float64(263.8),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(263.8),\n",
       "     'end': np.float64(263.96),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(263.96),\n",
       "     'end': np.float64(264.28),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(264.28),\n",
       "     'end': np.float64(264.52),\n",
       "     'confidence': 0.924},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(264.52),\n",
       "     'end': np.float64(264.64),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'using',\n",
       "     'start': np.float64(264.64),\n",
       "     'end': np.float64(264.94),\n",
       "     'confidence': 0.94},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(264.94),\n",
       "     'end': np.float64(265.22),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(265.22),\n",
       "     'end': np.float64(265.38),\n",
       "     'confidence': 0.805},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(265.38),\n",
       "     'end': np.float64(265.6),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(265.6),\n",
       "     'end': np.float64(265.92),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(265.92),\n",
       "     'end': np.float64(266.1),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(266.1),\n",
       "     'end': np.float64(266.32),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(266.32),\n",
       "     'end': np.float64(266.48),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'have',\n",
       "     'start': np.float64(266.48),\n",
       "     'end': np.float64(266.6),\n",
       "     'confidence': 0.974},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(266.6),\n",
       "     'end': np.float64(266.78),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(266.78),\n",
       "     'end': np.float64(267.2),\n",
       "     'confidence': 0.459},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(267.2),\n",
       "     'end': np.float64(267.42),\n",
       "     'confidence': 0.659}]},\n",
       "  {'id': 37,\n",
       "   'seek': 25400,\n",
       "   'start': np.float64(267.84),\n",
       "   'end': np.float64(272.78),\n",
       "   'text': ' the data is related to which field. Right. So there are multiple types of data, cross-sectional data',\n",
       "   'tokens': [51048,\n",
       "    264,\n",
       "    1412,\n",
       "    307,\n",
       "    4077,\n",
       "    281,\n",
       "    597,\n",
       "    2519,\n",
       "    13,\n",
       "    1779,\n",
       "    13,\n",
       "    407,\n",
       "    456,\n",
       "    366,\n",
       "    3866,\n",
       "    3467,\n",
       "    295,\n",
       "    1412,\n",
       "    11,\n",
       "    3278,\n",
       "    12,\n",
       "    11963,\n",
       "    304,\n",
       "    1412,\n",
       "    51308],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10166075794967179,\n",
       "   'compression_ratio': 1.880952380952381,\n",
       "   'no_speech_prob': 0.042016398161649704,\n",
       "   'confidence': 0.931,\n",
       "   'words': [{'text': 'the',\n",
       "     'start': np.float64(267.84),\n",
       "     'end': np.float64(267.96),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(267.96),\n",
       "     'end': np.float64(268.2),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(268.2),\n",
       "     'end': np.float64(268.42),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(268.42),\n",
       "     'end': np.float64(268.7),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'related',\n",
       "     'start': np.float64(268.7),\n",
       "     'end': np.float64(268.82),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(268.82),\n",
       "     'end': np.float64(269.12),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(269.12),\n",
       "     'end': np.float64(269.3),\n",
       "     'confidence': 0.969},\n",
       "    {'text': 'field.',\n",
       "     'start': np.float64(269.3),\n",
       "     'end': np.float64(269.62),\n",
       "     'confidence': 0.981},\n",
       "    {'text': 'Right.',\n",
       "     'start': np.float64(269.92),\n",
       "     'end': np.float64(269.94),\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(270.36),\n",
       "     'end': np.float64(270.48),\n",
       "     'confidence': 0.767},\n",
       "    {'text': 'there',\n",
       "     'start': np.float64(270.48),\n",
       "     'end': np.float64(270.6),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(270.6),\n",
       "     'end': np.float64(270.74),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'multiple',\n",
       "     'start': np.float64(270.74),\n",
       "     'end': np.float64(271.02),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'types',\n",
       "     'start': np.float64(271.02),\n",
       "     'end': np.float64(271.34),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(271.34),\n",
       "     'end': np.float64(271.56),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(271.56),\n",
       "     'end': np.float64(271.78),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'cross-sectional',\n",
       "     'start': np.float64(272.0),\n",
       "     'end': np.float64(272.54),\n",
       "     'confidence': 0.836},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(272.54),\n",
       "     'end': np.float64(272.78),\n",
       "     'confidence': 0.705}]},\n",
       "  {'id': 38,\n",
       "   'seek': 25400,\n",
       "   'start': np.float64(272.84),\n",
       "   'end': np.float64(278.96),\n",
       "   'text': ' and panel data. So it highly depends on what type of data you are working with, which model are we',\n",
       "   'tokens': [51308,\n",
       "    293,\n",
       "    4831,\n",
       "    1412,\n",
       "    13,\n",
       "    407,\n",
       "    309,\n",
       "    5405,\n",
       "    5946,\n",
       "    322,\n",
       "    437,\n",
       "    2010,\n",
       "    295,\n",
       "    1412,\n",
       "    291,\n",
       "    366,\n",
       "    1364,\n",
       "    365,\n",
       "    11,\n",
       "    597,\n",
       "    2316,\n",
       "    366,\n",
       "    321,\n",
       "    51608],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10166075794967179,\n",
       "   'compression_ratio': 1.880952380952381,\n",
       "   'no_speech_prob': 0.042016398161649704,\n",
       "   'confidence': 0.902,\n",
       "   'words': [{'text': 'and',\n",
       "     'start': np.float64(272.84),\n",
       "     'end': np.float64(273.12),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(273.12),\n",
       "     'end': np.float64(273.8),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'panel',\n",
       "     'start': np.float64(273.8),\n",
       "     'end': np.float64(273.94),\n",
       "     'confidence': 0.742},\n",
       "    {'text': 'data.',\n",
       "     'start': np.float64(273.94),\n",
       "     'end': np.float64(274.36),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(274.62),\n",
       "     'end': np.float64(274.86),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(274.86),\n",
       "     'end': np.float64(275.0),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'highly',\n",
       "     'start': np.float64(275.0),\n",
       "     'end': np.float64(275.36),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'depends',\n",
       "     'start': np.float64(275.36),\n",
       "     'end': np.float64(275.82),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(275.82),\n",
       "     'end': np.float64(276.24),\n",
       "     'confidence': 0.53},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(276.24),\n",
       "     'end': np.float64(276.4),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(276.4),\n",
       "     'end': np.float64(276.62),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(276.62),\n",
       "     'end': np.float64(276.78),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(276.78),\n",
       "     'end': np.float64(277.02),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(277.02),\n",
       "     'end': np.float64(277.18),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(277.18),\n",
       "     'end': np.float64(277.26),\n",
       "     'confidence': 0.753},\n",
       "    {'text': 'working',\n",
       "     'start': np.float64(277.26),\n",
       "     'end': np.float64(277.5),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'with,',\n",
       "     'start': np.float64(277.5),\n",
       "     'end': np.float64(277.78),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(277.9),\n",
       "     'end': np.float64(278.22),\n",
       "     'confidence': 0.796},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(278.22),\n",
       "     'end': np.float64(278.54),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(278.54),\n",
       "     'end': np.float64(278.84),\n",
       "     'confidence': 0.67},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(278.84),\n",
       "     'end': np.float64(278.96),\n",
       "     'confidence': 0.847}]},\n",
       "  {'id': 39,\n",
       "   'seek': 27888,\n",
       "   'start': np.float64(278.98),\n",
       "   'end': np.float64(284.44),\n",
       "   'text': \" trying to use. And accordingly, I'll try to like clean the data. Yeah.\",\n",
       "   'tokens': [50368,\n",
       "    1382,\n",
       "    281,\n",
       "    764,\n",
       "    13,\n",
       "    400,\n",
       "    19717,\n",
       "    11,\n",
       "    286,\n",
       "    603,\n",
       "    853,\n",
       "    281,\n",
       "    411,\n",
       "    2541,\n",
       "    264,\n",
       "    1412,\n",
       "    13,\n",
       "    865,\n",
       "    13,\n",
       "    50644],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0666964848836263,\n",
       "   'compression_ratio': 1.6501766784452296,\n",
       "   'no_speech_prob': 0.0022879273165017366,\n",
       "   'confidence': 0.95,\n",
       "   'words': [{'text': 'trying',\n",
       "     'start': np.float64(278.98),\n",
       "     'end': np.float64(279.18),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(279.18),\n",
       "     'end': np.float64(279.38),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'use.',\n",
       "     'start': np.float64(279.38),\n",
       "     'end': np.float64(279.62),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(279.92),\n",
       "     'end': np.float64(280.14),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'accordingly,',\n",
       "     'start': np.float64(280.14),\n",
       "     'end': np.float64(280.72),\n",
       "     'confidence': 0.99},\n",
       "    {'text': \"I'll\",\n",
       "     'start': np.float64(280.92),\n",
       "     'end': np.float64(281.1),\n",
       "     'confidence': 0.945},\n",
       "    {'text': 'try',\n",
       "     'start': np.float64(281.1),\n",
       "     'end': np.float64(281.3),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(281.3),\n",
       "     'end': np.float64(281.56),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(281.56),\n",
       "     'end': np.float64(281.86),\n",
       "     'confidence': 0.812},\n",
       "    {'text': 'clean',\n",
       "     'start': np.float64(281.86),\n",
       "     'end': np.float64(282.18),\n",
       "     'confidence': 0.776},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(282.18),\n",
       "     'end': np.float64(282.36),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'data.',\n",
       "     'start': np.float64(282.36),\n",
       "     'end': np.float64(282.6),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(282.86),\n",
       "     'end': np.float64(283.6),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'Yeah.',\n",
       "     'start': np.float64(283.6),\n",
       "     'end': np.float64(284.44),\n",
       "     'confidence': 0.888}]},\n",
       "  {'id': 40,\n",
       "   'seek': 27888,\n",
       "   'start': np.float64(288.06),\n",
       "   'end': np.float64(292.98),\n",
       "   'text': \" Absolutely. That makes a lot of sense. And I think you nailed it. It's all about the context of the\",\n",
       "   'tokens': [50816,\n",
       "    7021,\n",
       "    13,\n",
       "    663,\n",
       "    1669,\n",
       "    257,\n",
       "    688,\n",
       "    295,\n",
       "    2020,\n",
       "    13,\n",
       "    400,\n",
       "    286,\n",
       "    519,\n",
       "    291,\n",
       "    30790,\n",
       "    309,\n",
       "    13,\n",
       "    467,\n",
       "    311,\n",
       "    439,\n",
       "    466,\n",
       "    264,\n",
       "    4319,\n",
       "    295,\n",
       "    264,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0666964848836263,\n",
       "   'compression_ratio': 1.6501766784452296,\n",
       "   'no_speech_prob': 0.0022879273165017366,\n",
       "   'confidence': 0.969,\n",
       "   'words': [{'text': 'Absolutely.',\n",
       "     'start': np.float64(288.06),\n",
       "     'end': np.float64(288.44),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'That',\n",
       "     'start': np.float64(288.64),\n",
       "     'end': np.float64(288.9),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'makes',\n",
       "     'start': np.float64(288.9),\n",
       "     'end': np.float64(289.12),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(289.12),\n",
       "     'end': np.float64(289.28),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'lot',\n",
       "     'start': np.float64(289.28),\n",
       "     'end': np.float64(289.42),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(289.42),\n",
       "     'end': np.float64(289.54),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'sense.',\n",
       "     'start': np.float64(289.54),\n",
       "     'end': np.float64(289.78),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(290.16),\n",
       "     'end': np.float64(290.38),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(290.38),\n",
       "     'end': np.float64(290.5),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'think',\n",
       "     'start': np.float64(290.5),\n",
       "     'end': np.float64(290.64),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(290.64),\n",
       "     'end': np.float64(290.78),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'nailed',\n",
       "     'start': np.float64(290.78),\n",
       "     'end': np.float64(290.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'it.',\n",
       "     'start': np.float64(290.98),\n",
       "     'end': np.float64(291.22),\n",
       "     'confidence': 0.997},\n",
       "    {'text': \"It's\",\n",
       "     'start': np.float64(291.56),\n",
       "     'end': np.float64(291.84),\n",
       "     'confidence': 0.951},\n",
       "    {'text': 'all',\n",
       "     'start': np.float64(291.84),\n",
       "     'end': np.float64(291.98),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(291.98),\n",
       "     'end': np.float64(292.14),\n",
       "     'confidence': 0.973},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(292.14),\n",
       "     'end': np.float64(292.3),\n",
       "     'confidence': 0.956},\n",
       "    {'text': 'context',\n",
       "     'start': np.float64(292.3),\n",
       "     'end': np.float64(292.62),\n",
       "     'confidence': 0.885},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(292.62),\n",
       "     'end': np.float64(292.86),\n",
       "     'confidence': 0.843},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(292.86),\n",
       "     'end': np.float64(292.98),\n",
       "     'confidence': 0.855}]},\n",
       "  {'id': 41,\n",
       "   'seek': 27888,\n",
       "   'start': np.float64(292.98),\n",
       "   'end': np.float64(297.75),\n",
       "   'text': \" data and the model you're using. There's definitely no one size fits all solution. So your approach\",\n",
       "   'tokens': [51064,\n",
       "    1412,\n",
       "    293,\n",
       "    264,\n",
       "    2316,\n",
       "    291,\n",
       "    434,\n",
       "    1228,\n",
       "    13,\n",
       "    821,\n",
       "    311,\n",
       "    2138,\n",
       "    572,\n",
       "    472,\n",
       "    2744,\n",
       "    9001,\n",
       "    439,\n",
       "    3827,\n",
       "    13,\n",
       "    407,\n",
       "    428,\n",
       "    3109,\n",
       "    51312],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0666964848836263,\n",
       "   'compression_ratio': 1.6501766784452296,\n",
       "   'no_speech_prob': 0.0022879273165017366,\n",
       "   'confidence': 0.961,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(292.98),\n",
       "     'end': np.float64(293.06),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(293.06),\n",
       "     'end': np.float64(293.22),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(293.22),\n",
       "     'end': np.float64(293.5),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(293.5),\n",
       "     'end': np.float64(293.6),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(293.6),\n",
       "     'end': np.float64(293.78),\n",
       "     'confidence': 0.994},\n",
       "    {'text': \"you're\",\n",
       "     'start': np.float64(293.78),\n",
       "     'end': np.float64(294.02),\n",
       "     'confidence': 0.983},\n",
       "    {'text': 'using.',\n",
       "     'start': np.float64(294.02),\n",
       "     'end': np.float64(294.28),\n",
       "     'confidence': 1.0},\n",
       "    {'text': \"There's\",\n",
       "     'start': np.float64(294.62),\n",
       "     'end': np.float64(294.98),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'definitely',\n",
       "     'start': np.float64(294.98),\n",
       "     'end': np.float64(295.24),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'no',\n",
       "     'start': np.float64(295.24),\n",
       "     'end': np.float64(295.48),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'one',\n",
       "     'start': np.float64(295.48),\n",
       "     'end': np.float64(295.66),\n",
       "     'confidence': 0.969},\n",
       "    {'text': 'size',\n",
       "     'start': np.float64(295.66),\n",
       "     'end': np.float64(295.88),\n",
       "     'confidence': 0.707},\n",
       "    {'text': 'fits',\n",
       "     'start': np.float64(295.88),\n",
       "     'end': np.float64(296.1),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'all',\n",
       "     'start': np.float64(296.1),\n",
       "     'end': np.float64(296.32),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'solution.',\n",
       "     'start': np.float64(296.32),\n",
       "     'end': np.float64(296.74),\n",
       "     'confidence': 0.86},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(297.14),\n",
       "     'end': np.float64(297.18),\n",
       "     'confidence': 0.948},\n",
       "    {'text': 'your',\n",
       "     'start': np.float64(297.18),\n",
       "     'end': np.float64(297.56),\n",
       "     'confidence': 0.919},\n",
       "    {'text': 'approach',\n",
       "     'start': np.float64(297.56),\n",
       "     'end': np.float64(297.75),\n",
       "     'confidence': 0.996}]},\n",
       "  {'id': 42,\n",
       "   'seek': 27888,\n",
       "   'start': np.float64(297.75),\n",
       "   'end': np.float64(302.18),\n",
       "   'text': \" of considering the type of data and the algorithm is spot on. All right. Let's move on to another\",\n",
       "   'tokens': [51312,\n",
       "    295,\n",
       "    8079,\n",
       "    264,\n",
       "    2010,\n",
       "    295,\n",
       "    1412,\n",
       "    293,\n",
       "    264,\n",
       "    9284,\n",
       "    307,\n",
       "    4008,\n",
       "    322,\n",
       "    13,\n",
       "    1057,\n",
       "    558,\n",
       "    13,\n",
       "    961,\n",
       "    311,\n",
       "    1286,\n",
       "    322,\n",
       "    281,\n",
       "    1071,\n",
       "    51536],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0666964848836263,\n",
       "   'compression_ratio': 1.6501766784452296,\n",
       "   'no_speech_prob': 0.0022879273165017366,\n",
       "   'confidence': 0.97,\n",
       "   'words': [{'text': 'of',\n",
       "     'start': np.float64(297.75),\n",
       "     'end': np.float64(298.02),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'considering',\n",
       "     'start': np.float64(298.02),\n",
       "     'end': np.float64(298.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(298.38),\n",
       "     'end': np.float64(298.6),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(298.6),\n",
       "     'end': np.float64(298.76),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(298.76),\n",
       "     'end': np.float64(298.86),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(298.86),\n",
       "     'end': np.float64(299.04),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(299.04),\n",
       "     'end': np.float64(299.2),\n",
       "     'confidence': 0.862},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(299.2),\n",
       "     'end': np.float64(299.28),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'algorithm',\n",
       "     'start': np.float64(299.28),\n",
       "     'end': np.float64(299.7),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(299.7),\n",
       "     'end': np.float64(300.0),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'spot',\n",
       "     'start': np.float64(300.0),\n",
       "     'end': np.float64(300.26),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'on.',\n",
       "     'start': np.float64(300.26),\n",
       "     'end': np.float64(300.52),\n",
       "     'confidence': 0.925},\n",
       "    {'text': 'All',\n",
       "     'start': np.float64(300.82),\n",
       "     'end': np.float64(301.4),\n",
       "     'confidence': 0.734},\n",
       "    {'text': 'right.',\n",
       "     'start': np.float64(301.4),\n",
       "     'end': np.float64(301.5),\n",
       "     'confidence': 0.999},\n",
       "    {'text': \"Let's\",\n",
       "     'start': np.float64(301.56),\n",
       "     'end': np.float64(301.72),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'move',\n",
       "     'start': np.float64(301.72),\n",
       "     'end': np.float64(301.84),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(301.84),\n",
       "     'end': np.float64(302.0),\n",
       "     'confidence': 0.949},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(302.0),\n",
       "     'end': np.float64(302.06),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'another',\n",
       "     'start': np.float64(302.06),\n",
       "     'end': np.float64(302.18),\n",
       "     'confidence': 0.999}]},\n",
       "  {'id': 43,\n",
       "   'seek': 27888,\n",
       "   'start': np.float64(302.18),\n",
       "   'end': np.float64(307.4),\n",
       "   'text': \" question. Suppose you're working on a project where you need to evaluate how well your ML model is\",\n",
       "   'tokens': [51536,\n",
       "    1168,\n",
       "    13,\n",
       "    21360,\n",
       "    291,\n",
       "    434,\n",
       "    1364,\n",
       "    322,\n",
       "    257,\n",
       "    1716,\n",
       "    689,\n",
       "    291,\n",
       "    643,\n",
       "    281,\n",
       "    13059,\n",
       "    577,\n",
       "    731,\n",
       "    428,\n",
       "    21601,\n",
       "    2316,\n",
       "    307,\n",
       "    51788],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0666964848836263,\n",
       "   'compression_ratio': 1.6501766784452296,\n",
       "   'no_speech_prob': 0.0022879273165017366,\n",
       "   'confidence': 0.94,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(302.18),\n",
       "     'end': np.float64(302.58),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'question.',\n",
       "     'start': np.float64(302.58),\n",
       "     'end': np.float64(302.74),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'Suppose',\n",
       "     'start': np.float64(302.98),\n",
       "     'end': np.float64(303.38),\n",
       "     'confidence': 0.979},\n",
       "    {'text': \"you're\",\n",
       "     'start': np.float64(303.38),\n",
       "     'end': np.float64(303.72),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'working',\n",
       "     'start': np.float64(303.72),\n",
       "     'end': np.float64(303.88),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(303.88),\n",
       "     'end': np.float64(304.02),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(304.02),\n",
       "     'end': np.float64(304.12),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'project',\n",
       "     'start': np.float64(304.12),\n",
       "     'end': np.float64(304.52),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'where',\n",
       "     'start': np.float64(304.52),\n",
       "     'end': np.float64(304.88),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(304.88),\n",
       "     'end': np.float64(305.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'need',\n",
       "     'start': np.float64(305.1),\n",
       "     'end': np.float64(305.26),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(305.26),\n",
       "     'end': np.float64(305.4),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'evaluate',\n",
       "     'start': np.float64(305.4),\n",
       "     'end': np.float64(305.82),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(305.82),\n",
       "     'end': np.float64(306.28),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'well',\n",
       "     'start': np.float64(306.28),\n",
       "     'end': np.float64(306.48),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'your',\n",
       "     'start': np.float64(306.48),\n",
       "     'end': np.float64(306.66),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'ML',\n",
       "     'start': np.float64(306.66),\n",
       "     'end': np.float64(306.86),\n",
       "     'confidence': 0.874},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(306.86),\n",
       "     'end': np.float64(307.16),\n",
       "     'confidence': 0.538},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(307.16),\n",
       "     'end': np.float64(307.4),\n",
       "     'confidence': 0.699}]},\n",
       "  {'id': 44,\n",
       "   'seek': 30736,\n",
       "   'start': np.float64(307.46),\n",
       "   'end': np.float64(312.92),\n",
       "   'text': ' performing. Could you walk me through how you would choose evaluation metrics and what metrics you',\n",
       "   'tokens': [50364,\n",
       "    10205,\n",
       "    13,\n",
       "    7497,\n",
       "    291,\n",
       "    1792,\n",
       "    385,\n",
       "    807,\n",
       "    577,\n",
       "    291,\n",
       "    576,\n",
       "    2826,\n",
       "    13344,\n",
       "    16367,\n",
       "    293,\n",
       "    437,\n",
       "    16367,\n",
       "    291,\n",
       "    50644],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11628957974013462,\n",
       "   'compression_ratio': 1.7324561403508771,\n",
       "   'no_speech_prob': 0.0031141566578298807,\n",
       "   'confidence': 0.917,\n",
       "   'words': [{'text': 'performing.',\n",
       "     'start': np.float64(307.46),\n",
       "     'end': np.float64(307.78),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(308.24),\n",
       "     'end': np.float64(308.46),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'Could',\n",
       "     'start': np.float64(308.46),\n",
       "     'end': np.float64(308.56),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(308.56),\n",
       "     'end': np.float64(308.7),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'walk',\n",
       "     'start': np.float64(308.7),\n",
       "     'end': np.float64(308.86),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'me',\n",
       "     'start': np.float64(308.86),\n",
       "     'end': np.float64(309.04),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'through',\n",
       "     'start': np.float64(309.04),\n",
       "     'end': np.float64(309.22),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(309.22),\n",
       "     'end': np.float64(309.5),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(309.5),\n",
       "     'end': np.float64(309.78),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'would',\n",
       "     'start': np.float64(309.78),\n",
       "     'end': np.float64(309.94),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'choose',\n",
       "     'start': np.float64(309.94),\n",
       "     'end': np.float64(310.22),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'evaluation',\n",
       "     'start': np.float64(310.22),\n",
       "     'end': np.float64(310.78),\n",
       "     'confidence': 0.782},\n",
       "    {'text': 'metrics',\n",
       "     'start': np.float64(310.78),\n",
       "     'end': np.float64(311.4),\n",
       "     'confidence': 0.886},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(311.4),\n",
       "     'end': np.float64(311.78),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(311.78),\n",
       "     'end': np.float64(312.14),\n",
       "     'confidence': 0.836},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(312.14),\n",
       "     'end': np.float64(312.42),\n",
       "     'confidence': 0.907},\n",
       "    {'text': 'metrics',\n",
       "     'start': np.float64(312.42),\n",
       "     'end': np.float64(312.78),\n",
       "     'confidence': 0.911},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(312.78),\n",
       "     'end': np.float64(312.92),\n",
       "     'confidence': 0.541}]},\n",
       "  {'id': 45,\n",
       "   'seek': 30736,\n",
       "   'start': np.float64(312.92),\n",
       "   'end': np.float64(322.68),\n",
       "   'text': ' might consider depending on the type of problem? Yeah. So this also depends on what, like, on what',\n",
       "   'tokens': [50644,\n",
       "    1062,\n",
       "    1949,\n",
       "    5413,\n",
       "    322,\n",
       "    264,\n",
       "    2010,\n",
       "    295,\n",
       "    1154,\n",
       "    30,\n",
       "    865,\n",
       "    13,\n",
       "    407,\n",
       "    341,\n",
       "    611,\n",
       "    5946,\n",
       "    322,\n",
       "    437,\n",
       "    11,\n",
       "    411,\n",
       "    11,\n",
       "    322,\n",
       "    437,\n",
       "    51140],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11628957974013462,\n",
       "   'compression_ratio': 1.7324561403508771,\n",
       "   'no_speech_prob': 0.0031141566578298807,\n",
       "   'confidence': 0.943,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(312.92),\n",
       "     'end': np.float64(313.08),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'might',\n",
       "     'start': np.float64(313.08),\n",
       "     'end': np.float64(313.2),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'consider',\n",
       "     'start': np.float64(313.2),\n",
       "     'end': np.float64(313.62),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(313.62),\n",
       "     'end': np.float64(313.66),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'depending',\n",
       "     'start': np.float64(313.66),\n",
       "     'end': np.float64(314.24),\n",
       "     'confidence': 0.699},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(314.24),\n",
       "     'end': np.float64(314.46),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(314.46),\n",
       "     'end': np.float64(314.58),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(314.58),\n",
       "     'end': np.float64(314.7),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(314.7),\n",
       "     'end': np.float64(314.82),\n",
       "     'confidence': 0.945},\n",
       "    {'text': 'problem?',\n",
       "     'start': np.float64(314.82),\n",
       "     'end': np.float64(315.12),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(316.62),\n",
       "     'end': np.float64(317.66),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'Yeah.',\n",
       "     'start': np.float64(317.66),\n",
       "     'end': np.float64(317.8),\n",
       "     'confidence': 0.915},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(317.88),\n",
       "     'end': np.float64(318.12),\n",
       "     'confidence': 0.979},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(318.12),\n",
       "     'end': np.float64(319.1),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(319.1),\n",
       "     'end': np.float64(319.4),\n",
       "     'confidence': 0.961},\n",
       "    {'text': 'also',\n",
       "     'start': np.float64(319.4),\n",
       "     'end': np.float64(319.64),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'depends',\n",
       "     'start': np.float64(319.64),\n",
       "     'end': np.float64(320.04),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(320.04),\n",
       "     'end': np.float64(320.52),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'what,',\n",
       "     'start': np.float64(320.52),\n",
       "     'end': np.float64(321.12),\n",
       "     'confidence': 0.954},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(321.32),\n",
       "     'end': np.float64(321.84),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like,',\n",
       "     'start': np.float64(321.84),\n",
       "     'end': np.float64(322.02),\n",
       "     'confidence': 0.919},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(322.26),\n",
       "     'end': np.float64(322.6),\n",
       "     'confidence': 0.843},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(322.6),\n",
       "     'end': np.float64(322.68),\n",
       "     'confidence': 0.841}]},\n",
       "  {'id': 46,\n",
       "   'seek': 30736,\n",
       "   'start': np.float64(322.68),\n",
       "   'end': np.float64(329.52),\n",
       "   'text': \" type of data or what type of application I'm working with. So for example, the most common one. So\",\n",
       "   'tokens': [51140,\n",
       "    2010,\n",
       "    295,\n",
       "    1412,\n",
       "    420,\n",
       "    437,\n",
       "    2010,\n",
       "    295,\n",
       "    3861,\n",
       "    286,\n",
       "    478,\n",
       "    1364,\n",
       "    365,\n",
       "    13,\n",
       "    407,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    264,\n",
       "    881,\n",
       "    2689,\n",
       "    472,\n",
       "    13,\n",
       "    407,\n",
       "    51476],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11628957974013462,\n",
       "   'compression_ratio': 1.7324561403508771,\n",
       "   'no_speech_prob': 0.0031141566578298807,\n",
       "   'confidence': 0.939,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(322.68),\n",
       "     'end': np.float64(323.06),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(323.06),\n",
       "     'end': np.float64(323.18),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(323.18),\n",
       "     'end': np.float64(323.46),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(323.46),\n",
       "     'end': np.float64(324.02),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(324.02),\n",
       "     'end': np.float64(324.26),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(324.26),\n",
       "     'end': np.float64(324.54),\n",
       "     'confidence': 0.963},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(324.54),\n",
       "     'end': np.float64(324.74),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(324.74),\n",
       "     'end': np.float64(324.98),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(324.98),\n",
       "     'end': np.float64(325.2),\n",
       "     'confidence': 0.99},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(325.2),\n",
       "     'end': np.float64(325.62),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'application',\n",
       "     'start': np.float64(325.62),\n",
       "     'end': np.float64(326.0),\n",
       "     'confidence': 0.864},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(326.0),\n",
       "     'end': np.float64(326.4),\n",
       "     'confidence': 0.971},\n",
       "    {'text': 'working',\n",
       "     'start': np.float64(326.4),\n",
       "     'end': np.float64(326.62),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'with.',\n",
       "     'start': np.float64(326.62),\n",
       "     'end': np.float64(326.9),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(327.08),\n",
       "     'end': np.float64(327.46),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(327.46),\n",
       "     'end': np.float64(327.64),\n",
       "     'confidence': 0.718},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(327.64),\n",
       "     'end': np.float64(328.0),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(328.2),\n",
       "     'end': np.float64(328.26),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'most',\n",
       "     'start': np.float64(328.26),\n",
       "     'end': np.float64(328.48),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'common',\n",
       "     'start': np.float64(328.48),\n",
       "     'end': np.float64(328.82),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'one.',\n",
       "     'start': np.float64(328.82),\n",
       "     'end': np.float64(329.08),\n",
       "     'confidence': 0.948},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(329.26),\n",
       "     'end': np.float64(329.44),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(329.44),\n",
       "     'end': np.float64(329.52),\n",
       "     'confidence': 0.554}]},\n",
       "  {'id': 47,\n",
       "   'seek': 30736,\n",
       "   'start': np.float64(329.52),\n",
       "   'end': np.float64(336.16),\n",
       "   'text': ' most common one, you can say, for example, like some regression tasks. So you are actually predict',\n",
       "   'tokens': [51476,\n",
       "    881,\n",
       "    2689,\n",
       "    472,\n",
       "    11,\n",
       "    291,\n",
       "    393,\n",
       "    584,\n",
       "    11,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    411,\n",
       "    512,\n",
       "    24590,\n",
       "    9608,\n",
       "    13,\n",
       "    407,\n",
       "    291,\n",
       "    366,\n",
       "    767,\n",
       "    6069,\n",
       "    51828],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11628957974013462,\n",
       "   'compression_ratio': 1.7324561403508771,\n",
       "   'no_speech_prob': 0.0031141566578298807,\n",
       "   'confidence': 0.949,\n",
       "   'words': [{'text': 'most',\n",
       "     'start': np.float64(329.52),\n",
       "     'end': np.float64(329.92),\n",
       "     'confidence': 0.897},\n",
       "    {'text': 'common',\n",
       "     'start': np.float64(329.92),\n",
       "     'end': np.float64(330.24),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'one,',\n",
       "     'start': np.float64(330.24),\n",
       "     'end': np.float64(330.44),\n",
       "     'confidence': 0.915},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(330.5),\n",
       "     'end': np.float64(330.58),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'can',\n",
       "     'start': np.float64(330.58),\n",
       "     'end': np.float64(330.74),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'say,',\n",
       "     'start': np.float64(330.74),\n",
       "     'end': np.float64(331.04),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(331.34),\n",
       "     'end': np.float64(331.38),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(331.38),\n",
       "     'end': np.float64(331.86),\n",
       "     'confidence': 1.0},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(331.86),\n",
       "     'end': np.float64(333.42),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(333.42),\n",
       "     'end': np.float64(333.58),\n",
       "     'confidence': 0.925},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(333.58),\n",
       "     'end': np.float64(333.8),\n",
       "     'confidence': 0.968},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(333.8),\n",
       "     'end': np.float64(333.82),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'regression',\n",
       "     'start': np.float64(333.82),\n",
       "     'end': np.float64(334.14),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'tasks.',\n",
       "     'start': np.float64(334.14),\n",
       "     'end': np.float64(334.64),\n",
       "     'confidence': 0.961},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(334.82),\n",
       "     'end': np.float64(335.04),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(335.04),\n",
       "     'end': np.float64(335.32),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(335.32),\n",
       "     'end': np.float64(335.46),\n",
       "     'confidence': 0.849},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(335.46),\n",
       "     'end': np.float64(335.84),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'predict',\n",
       "     'start': np.float64(335.84),\n",
       "     'end': np.float64(336.16),\n",
       "     'confidence': 0.729}]},\n",
       "  {'id': 48,\n",
       "   'seek': 33664,\n",
       "   'start': np.float64(336.68),\n",
       "   'end': np.float64(344.1),\n",
       "   'text': ' predicting some actual value about what actual value that variable could be. So for example,',\n",
       "   'tokens': [50364,\n",
       "    32884,\n",
       "    512,\n",
       "    3539,\n",
       "    2158,\n",
       "    466,\n",
       "    437,\n",
       "    3539,\n",
       "    2158,\n",
       "    300,\n",
       "    7006,\n",
       "    727,\n",
       "    312,\n",
       "    13,\n",
       "    407,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    50740],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12064015676104833,\n",
       "   'compression_ratio': 1.6829268292682926,\n",
       "   'no_speech_prob': 0.007757219020277262,\n",
       "   'confidence': 0.965,\n",
       "   'words': [{'text': 'predicting',\n",
       "     'start': np.float64(336.68),\n",
       "     'end': np.float64(337.1),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(337.1),\n",
       "     'end': np.float64(337.44),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(337.44),\n",
       "     'end': np.float64(337.78),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'actual',\n",
       "     'start': np.float64(337.78),\n",
       "     'end': np.float64(337.94),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'value',\n",
       "     'start': np.float64(337.94),\n",
       "     'end': np.float64(338.42),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(338.42),\n",
       "     'end': np.float64(338.82),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(338.82),\n",
       "     'end': np.float64(339.02),\n",
       "     'confidence': 0.96},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(339.02),\n",
       "     'end': np.float64(339.38),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'actual',\n",
       "     'start': np.float64(339.38),\n",
       "     'end': np.float64(339.7),\n",
       "     'confidence': 0.962},\n",
       "    {'text': 'value',\n",
       "     'start': np.float64(339.7),\n",
       "     'end': np.float64(340.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(340.1),\n",
       "     'end': np.float64(341.42),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(341.42),\n",
       "     'end': np.float64(341.64),\n",
       "     'confidence': 0.904},\n",
       "    {'text': 'variable',\n",
       "     'start': np.float64(341.64),\n",
       "     'end': np.float64(342.18),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'could',\n",
       "     'start': np.float64(342.18),\n",
       "     'end': np.float64(342.52),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'be.',\n",
       "     'start': np.float64(342.52),\n",
       "     'end': np.float64(342.8),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(343.02),\n",
       "     'end': np.float64(343.36),\n",
       "     'confidence': 0.947},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(343.36),\n",
       "     'end': np.float64(343.74),\n",
       "     'confidence': 0.783},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(343.74),\n",
       "     'end': np.float64(344.1),\n",
       "     'confidence': 0.968}]},\n",
       "  {'id': 49,\n",
       "   'seek': 33664,\n",
       "   'start': np.float64(344.16),\n",
       "   'end': np.float64(350.42),\n",
       "   'text': ' for housing crisis, for example, you are making a model that predicts the housing crisis given',\n",
       "   'tokens': [50740,\n",
       "    337,\n",
       "    6849,\n",
       "    5869,\n",
       "    11,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    291,\n",
       "    366,\n",
       "    1455,\n",
       "    257,\n",
       "    2316,\n",
       "    300,\n",
       "    6069,\n",
       "    82,\n",
       "    264,\n",
       "    6849,\n",
       "    5869,\n",
       "    2212,\n",
       "    51080],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12064015676104833,\n",
       "   'compression_ratio': 1.6829268292682926,\n",
       "   'no_speech_prob': 0.007757219020277262,\n",
       "   'confidence': 0.926,\n",
       "   'words': [{'text': 'for',\n",
       "     'start': np.float64(344.16),\n",
       "     'end': np.float64(344.38),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'housing',\n",
       "     'start': np.float64(344.38),\n",
       "     'end': np.float64(344.66),\n",
       "     'confidence': 0.957},\n",
       "    {'text': 'crisis,',\n",
       "     'start': np.float64(344.66),\n",
       "     'end': np.float64(345.0),\n",
       "     'confidence': 0.777},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(345.1),\n",
       "     'end': np.float64(345.22),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(345.22),\n",
       "     'end': np.float64(345.5),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(345.6),\n",
       "     'end': np.float64(345.74),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(345.74),\n",
       "     'end': np.float64(345.82),\n",
       "     'confidence': 0.914},\n",
       "    {'text': 'making',\n",
       "     'start': np.float64(345.82),\n",
       "     'end': np.float64(346.04),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(346.04),\n",
       "     'end': np.float64(346.34),\n",
       "     'confidence': 0.987},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(346.34),\n",
       "     'end': np.float64(346.7),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(346.7),\n",
       "     'end': np.float64(347.44),\n",
       "     'confidence': 0.994},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(347.44),\n",
       "     'end': np.float64(348.76),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(348.76),\n",
       "     'end': np.float64(348.92),\n",
       "     'confidence': 0.922},\n",
       "    {'text': 'predicts',\n",
       "     'start': np.float64(348.92),\n",
       "     'end': np.float64(349.46),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(349.46),\n",
       "     'end': np.float64(349.58),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'housing',\n",
       "     'start': np.float64(349.58),\n",
       "     'end': np.float64(349.82),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'crisis',\n",
       "     'start': np.float64(349.82),\n",
       "     'end': np.float64(350.16),\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'given',\n",
       "     'start': np.float64(350.16),\n",
       "     'end': np.float64(350.42),\n",
       "     'confidence': 0.469}]},\n",
       "  {'id': 50,\n",
       "   'seek': 33664,\n",
       "   'start': np.float64(350.46),\n",
       "   'end': np.float64(358.2),\n",
       "   'text': ' some features, right? So what you do to like evaluate how well your model is performing,',\n",
       "   'tokens': [51080,\n",
       "    512,\n",
       "    4122,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    407,\n",
       "    437,\n",
       "    291,\n",
       "    360,\n",
       "    281,\n",
       "    411,\n",
       "    13059,\n",
       "    577,\n",
       "    731,\n",
       "    428,\n",
       "    2316,\n",
       "    307,\n",
       "    10205,\n",
       "    11,\n",
       "    51460],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12064015676104833,\n",
       "   'compression_ratio': 1.6829268292682926,\n",
       "   'no_speech_prob': 0.007757219020277262,\n",
       "   'confidence': 0.93,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(350.46),\n",
       "     'end': np.float64(350.78),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(350.78),\n",
       "     'end': np.float64(351.16),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'features,',\n",
       "     'start': np.float64(351.16),\n",
       "     'end': np.float64(351.46),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(351.64),\n",
       "     'end': np.float64(351.78),\n",
       "     'confidence': 0.972},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(352.0),\n",
       "     'end': np.float64(352.36),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(352.36),\n",
       "     'end': np.float64(352.86),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(352.86),\n",
       "     'end': np.float64(353.08),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(353.08),\n",
       "     'end': np.float64(353.24),\n",
       "     'confidence': 0.741},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(353.24),\n",
       "     'end': np.float64(353.48),\n",
       "     'confidence': 0.957},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(353.48),\n",
       "     'end': np.float64(354.64),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(354.64),\n",
       "     'end': np.float64(354.96),\n",
       "     'confidence': 0.908},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(354.96),\n",
       "     'end': np.float64(355.14),\n",
       "     'confidence': 0.662},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(355.14),\n",
       "     'end': np.float64(355.36),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'evaluate',\n",
       "     'start': np.float64(355.36),\n",
       "     'end': np.float64(355.64),\n",
       "     'confidence': 0.963},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(355.64),\n",
       "     'end': np.float64(356.16),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(356.16),\n",
       "     'end': np.float64(356.58),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'well',\n",
       "     'start': np.float64(356.58),\n",
       "     'end': np.float64(356.84),\n",
       "     'confidence': 0.862},\n",
       "    {'text': 'your',\n",
       "     'start': np.float64(356.84),\n",
       "     'end': np.float64(357.04),\n",
       "     'confidence': 0.976},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(357.04),\n",
       "     'end': np.float64(357.46),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(357.46),\n",
       "     'end': np.float64(357.7),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'performing,',\n",
       "     'start': np.float64(357.7),\n",
       "     'end': np.float64(358.2),\n",
       "     'confidence': 0.995}]},\n",
       "  {'id': 51,\n",
       "   'seek': 35856,\n",
       "   'start': np.float64(358.64),\n",
       "   'end': np.float64(366.94),\n",
       "   'text': ' a simple metric is that like a simple matrix is that that we do is like we could like we',\n",
       "   'tokens': [50364,\n",
       "    257,\n",
       "    2199,\n",
       "    20678,\n",
       "    307,\n",
       "    300,\n",
       "    411,\n",
       "    257,\n",
       "    2199,\n",
       "    8141,\n",
       "    307,\n",
       "    300,\n",
       "    300,\n",
       "    321,\n",
       "    360,\n",
       "    307,\n",
       "    411,\n",
       "    321,\n",
       "    727,\n",
       "    411,\n",
       "    321,\n",
       "    50780],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1474018814743206,\n",
       "   'compression_ratio': 1.8686868686868687,\n",
       "   'no_speech_prob': 0.10813136398792267,\n",
       "   'confidence': 0.791,\n",
       "   'words': [{'text': 'a',\n",
       "     'start': np.float64(358.64),\n",
       "     'end': np.float64(358.78),\n",
       "     'confidence': 0.981},\n",
       "    {'text': 'simple',\n",
       "     'start': np.float64(358.78),\n",
       "     'end': np.float64(359.1),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'metric',\n",
       "     'start': np.float64(359.1),\n",
       "     'end': np.float64(359.48),\n",
       "     'confidence': 0.801},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(359.48),\n",
       "     'end': np.float64(359.78),\n",
       "     'confidence': 0.957},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(359.78),\n",
       "     'end': np.float64(360.06),\n",
       "     'confidence': 0.973},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(360.06),\n",
       "     'end': np.float64(360.64),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(360.64),\n",
       "     'end': np.float64(360.86),\n",
       "     'confidence': 0.457},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(360.86),\n",
       "     'end': np.float64(361.4),\n",
       "     'confidence': 0.849},\n",
       "    {'text': 'simple',\n",
       "     'start': np.float64(361.4),\n",
       "     'end': np.float64(361.64),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'matrix',\n",
       "     'start': np.float64(361.64),\n",
       "     'end': np.float64(362.02),\n",
       "     'confidence': 0.441},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(362.02),\n",
       "     'end': np.float64(362.32),\n",
       "     'confidence': 0.972},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(362.32),\n",
       "     'end': np.float64(362.74),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(362.74),\n",
       "     'end': np.float64(362.96),\n",
       "     'confidence': 0.786},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(362.96),\n",
       "     'end': np.float64(364.4),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(364.4),\n",
       "     'end': np.float64(364.58),\n",
       "     'confidence': 0.626},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(364.58),\n",
       "     'end': np.float64(364.8),\n",
       "     'confidence': 0.963},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(364.8),\n",
       "     'end': np.float64(365.04),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(365.04),\n",
       "     'end': np.float64(365.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(365.32),\n",
       "     'end': np.float64(365.56),\n",
       "     'confidence': 0.947},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(365.56),\n",
       "     'end': np.float64(365.76),\n",
       "     'confidence': 0.948},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(365.76),\n",
       "     'end': np.float64(365.94),\n",
       "     'confidence': 0.721},\n",
       "    {'text': 'could',\n",
       "     'start': np.float64(365.94),\n",
       "     'end': np.float64(366.08),\n",
       "     'confidence': 0.621},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(366.08),\n",
       "     'end': np.float64(366.38),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(366.38),\n",
       "     'end': np.float64(366.64),\n",
       "     'confidence': 0.566},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(366.64),\n",
       "     'end': np.float64(366.78),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(366.78),\n",
       "     'end': np.float64(366.94),\n",
       "     'confidence': 0.715}]},\n",
       "  {'id': 52,\n",
       "   'seek': 35856,\n",
       "   'start': np.float64(366.94),\n",
       "   'end': np.float64(372.55),\n",
       "   'text': ' calculate the cost and cost is nothing but cumulated errors, right? But that is not a very',\n",
       "   'tokens': [50780,\n",
       "    8873,\n",
       "    264,\n",
       "    2063,\n",
       "    293,\n",
       "    2063,\n",
       "    307,\n",
       "    1825,\n",
       "    457,\n",
       "    12713,\n",
       "    6987,\n",
       "    13603,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    583,\n",
       "    300,\n",
       "    307,\n",
       "    406,\n",
       "    257,\n",
       "    588,\n",
       "    51076],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1474018814743206,\n",
       "   'compression_ratio': 1.8686868686868687,\n",
       "   'no_speech_prob': 0.10813136398792267,\n",
       "   'confidence': 0.913,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(366.94),\n",
       "     'end': np.float64(367.08),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'calculate',\n",
       "     'start': np.float64(367.08),\n",
       "     'end': np.float64(367.34),\n",
       "     'confidence': 0.965},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(367.34),\n",
       "     'end': np.float64(367.62),\n",
       "     'confidence': 0.938},\n",
       "    {'text': 'cost',\n",
       "     'start': np.float64(367.62),\n",
       "     'end': np.float64(368.02),\n",
       "     'confidence': 0.972},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(368.02),\n",
       "     'end': np.float64(368.32),\n",
       "     'confidence': 0.931},\n",
       "    {'text': 'cost',\n",
       "     'start': np.float64(368.32),\n",
       "     'end': np.float64(368.6),\n",
       "     'confidence': 0.981},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(368.6),\n",
       "     'end': np.float64(368.84),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'nothing',\n",
       "     'start': np.float64(368.84),\n",
       "     'end': np.float64(369.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'but',\n",
       "     'start': np.float64(369.1),\n",
       "     'end': np.float64(369.38),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'cumulated',\n",
       "     'start': np.float64(369.38),\n",
       "     'end': np.float64(369.86),\n",
       "     'confidence': 0.608},\n",
       "    {'text': 'errors,',\n",
       "     'start': np.float64(369.86),\n",
       "     'end': np.float64(370.26),\n",
       "     'confidence': 0.832},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(370.44),\n",
       "     'end': np.float64(370.68),\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'But',\n",
       "     'start': np.float64(371.06),\n",
       "     'end': np.float64(371.32),\n",
       "     'confidence': 0.988},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(371.32),\n",
       "     'end': np.float64(371.76),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(371.76),\n",
       "     'end': np.float64(371.98),\n",
       "     'confidence': 0.983},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(371.98),\n",
       "     'end': np.float64(372.14),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'not',\n",
       "     'start': np.float64(372.14),\n",
       "     'end': np.float64(372.3),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(372.3),\n",
       "     'end': np.float64(372.46),\n",
       "     'confidence': 0.95},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(372.46),\n",
       "     'end': np.float64(372.55),\n",
       "     'confidence': 0.888}]},\n",
       "  {'id': 53,\n",
       "   'seek': 35856,\n",
       "   'start': np.float64(372.55),\n",
       "   'end': np.float64(379.76),\n",
       "   'text': ' like good metric because initially, when we got the data, we like split the data into two parts.',\n",
       "   'tokens': [51076,\n",
       "    411,\n",
       "    665,\n",
       "    20678,\n",
       "    570,\n",
       "    9105,\n",
       "    11,\n",
       "    562,\n",
       "    321,\n",
       "    658,\n",
       "    264,\n",
       "    1412,\n",
       "    11,\n",
       "    321,\n",
       "    411,\n",
       "    7472,\n",
       "    264,\n",
       "    1412,\n",
       "    666,\n",
       "    732,\n",
       "    3166,\n",
       "    13,\n",
       "    51444],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1474018814743206,\n",
       "   'compression_ratio': 1.8686868686868687,\n",
       "   'no_speech_prob': 0.10813136398792267,\n",
       "   'confidence': 0.947,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(372.55),\n",
       "     'end': np.float64(372.96),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(372.96),\n",
       "     'end': np.float64(373.1),\n",
       "     'confidence': 0.975},\n",
       "    {'text': 'good',\n",
       "     'start': np.float64(373.1),\n",
       "     'end': np.float64(373.92),\n",
       "     'confidence': 0.787},\n",
       "    {'text': 'metric',\n",
       "     'start': np.float64(373.92),\n",
       "     'end': np.float64(374.5),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'because',\n",
       "     'start': np.float64(374.5),\n",
       "     'end': np.float64(374.88),\n",
       "     'confidence': 0.662},\n",
       "    {'text': 'initially,',\n",
       "     'start': np.float64(374.88),\n",
       "     'end': np.float64(375.72),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'when',\n",
       "     'start': np.float64(375.94),\n",
       "     'end': np.float64(376.22),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(376.22),\n",
       "     'end': np.float64(376.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(376.38),\n",
       "     'end': np.float64(376.58),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(376.58),\n",
       "     'end': np.float64(376.8),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(376.8),\n",
       "     'end': np.float64(377.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(377.24),\n",
       "     'end': np.float64(377.54),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(377.54),\n",
       "     'end': np.float64(377.74),\n",
       "     'confidence': 0.891},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(377.74),\n",
       "     'end': np.float64(378.2),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'split',\n",
       "     'start': np.float64(378.2),\n",
       "     'end': np.float64(378.36),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(378.36),\n",
       "     'end': np.float64(378.6),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(378.6),\n",
       "     'end': np.float64(378.88),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'into',\n",
       "     'start': np.float64(378.88),\n",
       "     'end': np.float64(379.22),\n",
       "     'confidence': 0.969},\n",
       "    {'text': 'two',\n",
       "     'start': np.float64(379.22),\n",
       "     'end': np.float64(379.46),\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'parts.',\n",
       "     'start': np.float64(379.46),\n",
       "     'end': np.float64(379.76),\n",
       "     'confidence': 0.935}]},\n",
       "  {'id': 54,\n",
       "   'seek': 35856,\n",
       "   'start': np.float64(380.22),\n",
       "   'end': np.float64(386.44),\n",
       "   'text': ' We got the training data, not two parts, it actually it is three parts. So the training data,',\n",
       "   'tokens': [51444,\n",
       "    492,\n",
       "    658,\n",
       "    264,\n",
       "    3097,\n",
       "    1412,\n",
       "    11,\n",
       "    406,\n",
       "    732,\n",
       "    3166,\n",
       "    11,\n",
       "    309,\n",
       "    767,\n",
       "    309,\n",
       "    307,\n",
       "    1045,\n",
       "    3166,\n",
       "    13,\n",
       "    407,\n",
       "    264,\n",
       "    3097,\n",
       "    1412,\n",
       "    11,\n",
       "    51760],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1474018814743206,\n",
       "   'compression_ratio': 1.8686868686868687,\n",
       "   'no_speech_prob': 0.10813136398792267,\n",
       "   'confidence': 0.923,\n",
       "   'words': [{'text': 'We',\n",
       "     'start': np.float64(380.22),\n",
       "     'end': np.float64(380.42),\n",
       "     'confidence': 0.932},\n",
       "    {'text': 'got',\n",
       "     'start': np.float64(380.42),\n",
       "     'end': np.float64(380.66),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(380.66),\n",
       "     'end': np.float64(380.96),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'training',\n",
       "     'start': np.float64(380.96),\n",
       "     'end': np.float64(381.28),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(381.28),\n",
       "     'end': np.float64(381.66),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'not',\n",
       "     'start': np.float64(381.82),\n",
       "     'end': np.float64(382.04),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'two',\n",
       "     'start': np.float64(382.04),\n",
       "     'end': np.float64(382.3),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'parts,',\n",
       "     'start': np.float64(382.3),\n",
       "     'end': np.float64(382.54),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(382.62),\n",
       "     'end': np.float64(382.82),\n",
       "     'confidence': 0.691},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(382.82),\n",
       "     'end': np.float64(383.08),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(383.08),\n",
       "     'end': np.float64(383.22),\n",
       "     'confidence': 0.96},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(383.22),\n",
       "     'end': np.float64(383.46),\n",
       "     'confidence': 0.692},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(383.46),\n",
       "     'end': np.float64(383.62),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'three',\n",
       "     'start': np.float64(383.62),\n",
       "     'end': np.float64(384.0),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'parts.',\n",
       "     'start': np.float64(384.0),\n",
       "     'end': np.float64(384.3),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(384.46),\n",
       "     'end': np.float64(385.02),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(385.02),\n",
       "     'end': np.float64(385.46),\n",
       "     'confidence': 0.91},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(385.46),\n",
       "     'end': np.float64(385.62),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(385.62),\n",
       "     'end': np.float64(385.82),\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'training',\n",
       "     'start': np.float64(385.82),\n",
       "     'end': np.float64(386.12),\n",
       "     'confidence': 0.972},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(386.12),\n",
       "     'end': np.float64(386.44),\n",
       "     'confidence': 0.685}]},\n",
       "  {'id': 55,\n",
       "   'seek': 38648,\n",
       "   'start': np.float64(386.6),\n",
       "   'end': np.float64(392.64),\n",
       "   'text': ' the dev data and then the test data, right? So the best way to like evaluate it, evaluate the model',\n",
       "   'tokens': [50364,\n",
       "    264,\n",
       "    1905,\n",
       "    1412,\n",
       "    293,\n",
       "    550,\n",
       "    264,\n",
       "    1500,\n",
       "    1412,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    407,\n",
       "    264,\n",
       "    1151,\n",
       "    636,\n",
       "    281,\n",
       "    411,\n",
       "    13059,\n",
       "    309,\n",
       "    11,\n",
       "    13059,\n",
       "    264,\n",
       "    2316,\n",
       "    50696],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10567146969824723,\n",
       "   'compression_ratio': 1.740909090909091,\n",
       "   'no_speech_prob': 0.006311345379799604,\n",
       "   'confidence': 0.902,\n",
       "   'words': [{'text': 'the',\n",
       "     'start': np.float64(386.6),\n",
       "     'end': np.float64(386.72),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'dev',\n",
       "     'start': np.float64(386.72),\n",
       "     'end': np.float64(386.92),\n",
       "     'confidence': 0.548},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(386.92),\n",
       "     'end': np.float64(387.18),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(387.18),\n",
       "     'end': np.float64(387.36),\n",
       "     'confidence': 0.635},\n",
       "    {'text': 'then',\n",
       "     'start': np.float64(387.36),\n",
       "     'end': np.float64(387.46),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(387.46),\n",
       "     'end': np.float64(387.58),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'test',\n",
       "     'start': np.float64(387.58),\n",
       "     'end': np.float64(387.8),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(387.8),\n",
       "     'end': np.float64(388.06),\n",
       "     'confidence': 0.974},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(388.16),\n",
       "     'end': np.float64(388.36),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(388.7),\n",
       "     'end': np.float64(388.9),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(388.9),\n",
       "     'end': np.float64(389.22),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'best',\n",
       "     'start': np.float64(389.22),\n",
       "     'end': np.float64(389.48),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'way',\n",
       "     'start': np.float64(389.48),\n",
       "     'end': np.float64(389.74),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(389.74),\n",
       "     'end': np.float64(389.94),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(389.94),\n",
       "     'end': np.float64(390.48),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(390.48),\n",
       "     'end': np.float64(390.7),\n",
       "     'confidence': 0.843},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(390.7),\n",
       "     'end': np.float64(390.96),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'evaluate',\n",
       "     'start': np.float64(390.96),\n",
       "     'end': np.float64(391.2),\n",
       "     'confidence': 0.964},\n",
       "    {'text': 'it,',\n",
       "     'start': np.float64(391.2),\n",
       "     'end': np.float64(391.56),\n",
       "     'confidence': 0.934},\n",
       "    {'text': 'evaluate',\n",
       "     'start': np.float64(391.64),\n",
       "     'end': np.float64(392.02),\n",
       "     'confidence': 0.827},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(392.02),\n",
       "     'end': np.float64(392.34),\n",
       "     'confidence': 0.785},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(392.34),\n",
       "     'end': np.float64(392.64),\n",
       "     'confidence': 0.803}]},\n",
       "  {'id': 56,\n",
       "   'seek': 38648,\n",
       "   'start': np.float64(393.1),\n",
       "   'end': np.float64(399.06),\n",
       "   'text': ' you are working with is to like first define these like metrics, these cost. So for example,',\n",
       "   'tokens': [50696,\n",
       "    291,\n",
       "    366,\n",
       "    1364,\n",
       "    365,\n",
       "    307,\n",
       "    281,\n",
       "    411,\n",
       "    700,\n",
       "    6964,\n",
       "    613,\n",
       "    411,\n",
       "    16367,\n",
       "    11,\n",
       "    613,\n",
       "    2063,\n",
       "    13,\n",
       "    407,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    51004],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10567146969824723,\n",
       "   'compression_ratio': 1.740909090909091,\n",
       "   'no_speech_prob': 0.006311345379799604,\n",
       "   'confidence': 0.908,\n",
       "   'words': [{'text': 'you',\n",
       "     'start': np.float64(393.1),\n",
       "     'end': np.float64(393.32),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(393.32),\n",
       "     'end': np.float64(393.42),\n",
       "     'confidence': 0.866},\n",
       "    {'text': 'working',\n",
       "     'start': np.float64(393.42),\n",
       "     'end': np.float64(393.66),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'with',\n",
       "     'start': np.float64(393.66),\n",
       "     'end': np.float64(393.96),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(393.96),\n",
       "     'end': np.float64(394.22),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(394.22),\n",
       "     'end': np.float64(394.46),\n",
       "     'confidence': 0.834},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(394.46),\n",
       "     'end': np.float64(394.6),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(394.6),\n",
       "     'end': np.float64(394.76),\n",
       "     'confidence': 0.969},\n",
       "    {'text': 'first',\n",
       "     'start': np.float64(394.76),\n",
       "     'end': np.float64(394.98),\n",
       "     'confidence': 0.906},\n",
       "    {'text': 'define',\n",
       "     'start': np.float64(394.98),\n",
       "     'end': np.float64(395.3),\n",
       "     'confidence': 0.957},\n",
       "    {'text': 'these',\n",
       "     'start': np.float64(395.3),\n",
       "     'end': np.float64(395.64),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(395.64),\n",
       "     'end': np.float64(395.94),\n",
       "     'confidence': 0.932},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(395.94),\n",
       "     'end': np.float64(396.18),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'metrics,',\n",
       "     'start': np.float64(396.18),\n",
       "     'end': np.float64(396.42),\n",
       "     'confidence': 0.904},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(396.68),\n",
       "     'end': np.float64(397.02),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'these',\n",
       "     'start': np.float64(397.02),\n",
       "     'end': np.float64(397.38),\n",
       "     'confidence': 0.807},\n",
       "    {'text': 'cost.',\n",
       "     'start': np.float64(397.38),\n",
       "     'end': np.float64(397.96),\n",
       "     'confidence': 0.539},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(398.18),\n",
       "     'end': np.float64(398.42),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(398.42),\n",
       "     'end': np.float64(398.66),\n",
       "     'confidence': 0.968},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(398.66),\n",
       "     'end': np.float64(398.82),\n",
       "     'confidence': 0.928},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(398.82),\n",
       "     'end': np.float64(399.06),\n",
       "     'confidence': 0.999}]},\n",
       "  {'id': 57,\n",
       "   'seek': 38648,\n",
       "   'start': np.float64(399.06),\n",
       "   'end': np.float64(404.89),\n",
       "   'text': \" root mean square cost, right? So it measures the overall error. I'm talking about the regression\",\n",
       "   'tokens': [51004,\n",
       "    5593,\n",
       "    914,\n",
       "    3732,\n",
       "    2063,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    407,\n",
       "    309,\n",
       "    8000,\n",
       "    264,\n",
       "    4787,\n",
       "    6713,\n",
       "    13,\n",
       "    286,\n",
       "    478,\n",
       "    1417,\n",
       "    466,\n",
       "    264,\n",
       "    24590,\n",
       "    51300],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10567146969824723,\n",
       "   'compression_ratio': 1.740909090909091,\n",
       "   'no_speech_prob': 0.006311345379799604,\n",
       "   'confidence': 0.893,\n",
       "   'words': [{'text': 'root',\n",
       "     'start': np.float64(399.06),\n",
       "     'end': np.float64(399.48),\n",
       "     'confidence': 0.894},\n",
       "    {'text': 'mean',\n",
       "     'start': np.float64(399.48),\n",
       "     'end': np.float64(399.72),\n",
       "     'confidence': 0.736},\n",
       "    {'text': 'square',\n",
       "     'start': np.float64(399.72),\n",
       "     'end': np.float64(400.04),\n",
       "     'confidence': 0.863},\n",
       "    {'text': 'cost,',\n",
       "     'start': np.float64(400.04),\n",
       "     'end': np.float64(400.42),\n",
       "     'confidence': 0.722},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(400.68),\n",
       "     'end': np.float64(400.78),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(401.22),\n",
       "     'end': np.float64(401.46),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(401.46),\n",
       "     'end': np.float64(401.66),\n",
       "     'confidence': 0.989},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(401.66),\n",
       "     'end': np.float64(401.96),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'measures',\n",
       "     'start': np.float64(401.96),\n",
       "     'end': np.float64(402.34),\n",
       "     'confidence': 0.446},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(402.34),\n",
       "     'end': np.float64(402.6),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'overall',\n",
       "     'start': np.float64(402.6),\n",
       "     'end': np.float64(402.86),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'error.',\n",
       "     'start': np.float64(402.86),\n",
       "     'end': np.float64(403.2),\n",
       "     'confidence': 0.993},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(403.4),\n",
       "     'end': np.float64(404.08),\n",
       "     'confidence': 0.969},\n",
       "    {'text': 'talking',\n",
       "     'start': np.float64(404.08),\n",
       "     'end': np.float64(404.3),\n",
       "     'confidence': 0.935},\n",
       "    {'text': 'about',\n",
       "     'start': np.float64(404.3),\n",
       "     'end': np.float64(404.6),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(404.6),\n",
       "     'end': np.float64(404.8),\n",
       "     'confidence': 0.976},\n",
       "    {'text': 'regression',\n",
       "     'start': np.float64(404.8),\n",
       "     'end': np.float64(404.89),\n",
       "     'confidence': 0.969}]},\n",
       "  {'id': 58,\n",
       "   'seek': 38648,\n",
       "   'start': np.float64(404.89),\n",
       "   'end': np.float64(412.38),\n",
       "   'text': ' task. So in this case, what you do is that what we do while we are choosing the model, we try',\n",
       "   'tokens': [51300,\n",
       "    5633,\n",
       "    13,\n",
       "    407,\n",
       "    294,\n",
       "    341,\n",
       "    1389,\n",
       "    11,\n",
       "    437,\n",
       "    291,\n",
       "    360,\n",
       "    307,\n",
       "    300,\n",
       "    437,\n",
       "    321,\n",
       "    360,\n",
       "    1339,\n",
       "    321,\n",
       "    366,\n",
       "    10875,\n",
       "    264,\n",
       "    2316,\n",
       "    11,\n",
       "    321,\n",
       "    853,\n",
       "    51660],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10567146969824723,\n",
       "   'compression_ratio': 1.740909090909091,\n",
       "   'no_speech_prob': 0.006311345379799604,\n",
       "   'confidence': 0.947,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(404.89),\n",
       "     'end': np.float64(405.34),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'task.',\n",
       "     'start': np.float64(405.34),\n",
       "     'end': np.float64(405.48),\n",
       "     'confidence': 0.713},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(405.78),\n",
       "     'end': np.float64(406.34),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(406.34),\n",
       "     'end': np.float64(406.5),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(406.5),\n",
       "     'end': np.float64(406.72),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'case,',\n",
       "     'start': np.float64(406.72),\n",
       "     'end': np.float64(407.0),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(407.6),\n",
       "     'end': np.float64(407.78),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(407.78),\n",
       "     'end': np.float64(407.92),\n",
       "     'confidence': 0.919},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(407.92),\n",
       "     'end': np.float64(408.14),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(408.14),\n",
       "     'end': np.float64(408.7),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(408.7),\n",
       "     'end': np.float64(408.86),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(408.86),\n",
       "     'end': np.float64(409.06),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(409.06),\n",
       "     'end': np.float64(409.64),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(409.64),\n",
       "     'end': np.float64(409.84),\n",
       "     'confidence': 0.956},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(409.84),\n",
       "     'end': np.float64(410.02),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(410.02),\n",
       "     'end': np.float64(410.2),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'while',\n",
       "     'start': np.float64(410.2),\n",
       "     'end': np.float64(410.5),\n",
       "     'confidence': 0.846},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(410.5),\n",
       "     'end': np.float64(410.82),\n",
       "     'confidence': 0.98},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(410.82),\n",
       "     'end': np.float64(411.06),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(411.06),\n",
       "     'end': np.float64(411.18),\n",
       "     'confidence': 0.937},\n",
       "    {'text': 'choosing',\n",
       "     'start': np.float64(411.18),\n",
       "     'end': np.float64(411.46),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(411.46),\n",
       "     'end': np.float64(411.7),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'model,',\n",
       "     'start': np.float64(411.7),\n",
       "     'end': np.float64(411.96),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(412.14),\n",
       "     'end': np.float64(412.16),\n",
       "     'confidence': 0.712},\n",
       "    {'text': 'try',\n",
       "     'start': np.float64(412.16),\n",
       "     'end': np.float64(412.38),\n",
       "     'confidence': 0.98}]},\n",
       "  {'id': 59,\n",
       "   'seek': 41240,\n",
       "   'start': np.float64(412.52),\n",
       "   'end': np.float64(418.32),\n",
       "   'text': ' different models and we train the model. And on the training set, we try to minimize the cost as',\n",
       "   'tokens': [50364,\n",
       "    819,\n",
       "    5245,\n",
       "    293,\n",
       "    321,\n",
       "    3847,\n",
       "    264,\n",
       "    2316,\n",
       "    13,\n",
       "    400,\n",
       "    322,\n",
       "    264,\n",
       "    3097,\n",
       "    992,\n",
       "    11,\n",
       "    321,\n",
       "    853,\n",
       "    281,\n",
       "    17522,\n",
       "    264,\n",
       "    2063,\n",
       "    382,\n",
       "    50660],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08859089309094,\n",
       "   'compression_ratio': 1.8970588235294117,\n",
       "   'no_speech_prob': 0.023925356566905975,\n",
       "   'confidence': 0.968,\n",
       "   'words': [{'text': 'different',\n",
       "     'start': np.float64(412.52),\n",
       "     'end': np.float64(412.72),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'models',\n",
       "     'start': np.float64(412.72),\n",
       "     'end': np.float64(413.14),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(413.14),\n",
       "     'end': np.float64(413.52),\n",
       "     'confidence': 0.903},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(413.52),\n",
       "     'end': np.float64(413.7),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'train',\n",
       "     'start': np.float64(413.7),\n",
       "     'end': np.float64(414.2),\n",
       "     'confidence': 0.977},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(414.2),\n",
       "     'end': np.float64(414.38),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'model.',\n",
       "     'start': np.float64(414.38),\n",
       "     'end': np.float64(414.62),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(415.16),\n",
       "     'end': np.float64(415.22),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(415.22),\n",
       "     'end': np.float64(415.34),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(415.34),\n",
       "     'end': np.float64(415.46),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'training',\n",
       "     'start': np.float64(415.46),\n",
       "     'end': np.float64(415.76),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'set,',\n",
       "     'start': np.float64(415.76),\n",
       "     'end': np.float64(416.08),\n",
       "     'confidence': 0.933},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(416.26),\n",
       "     'end': np.float64(416.58),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'try',\n",
       "     'start': np.float64(416.58),\n",
       "     'end': np.float64(417.0),\n",
       "     'confidence': 0.95},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(417.0),\n",
       "     'end': np.float64(417.2),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'minimize',\n",
       "     'start': np.float64(417.2),\n",
       "     'end': np.float64(417.54),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(417.54),\n",
       "     'end': np.float64(417.82),\n",
       "     'confidence': 0.981},\n",
       "    {'text': 'cost',\n",
       "     'start': np.float64(417.82),\n",
       "     'end': np.float64(418.04),\n",
       "     'confidence': 0.924},\n",
       "    {'text': 'as',\n",
       "     'start': np.float64(418.04),\n",
       "     'end': np.float64(418.32),\n",
       "     'confidence': 0.798}]},\n",
       "  {'id': 60,\n",
       "   'seek': 41240,\n",
       "   'start': np.float64(418.32),\n",
       "   'end': np.float64(424.58),\n",
       "   'text': ' much as we can, right? But the problem here is the training cost error, if it is minimized,',\n",
       "   'tokens': [50660,\n",
       "    709,\n",
       "    382,\n",
       "    321,\n",
       "    393,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    583,\n",
       "    264,\n",
       "    1154,\n",
       "    510,\n",
       "    307,\n",
       "    264,\n",
       "    3097,\n",
       "    2063,\n",
       "    6713,\n",
       "    11,\n",
       "    498,\n",
       "    309,\n",
       "    307,\n",
       "    4464,\n",
       "    1602,\n",
       "    11,\n",
       "    50972],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08859089309094,\n",
       "   'compression_ratio': 1.8970588235294117,\n",
       "   'no_speech_prob': 0.023925356566905975,\n",
       "   'confidence': 0.965,\n",
       "   'words': [{'text': 'much',\n",
       "     'start': np.float64(418.32),\n",
       "     'end': np.float64(418.52),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'as',\n",
       "     'start': np.float64(418.52),\n",
       "     'end': np.float64(418.72),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(418.72),\n",
       "     'end': np.float64(418.86),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(418.86),\n",
       "     'end': np.float64(419.58),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'can,',\n",
       "     'start': np.float64(419.58),\n",
       "     'end': np.float64(419.78),\n",
       "     'confidence': 0.856},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(419.92),\n",
       "     'end': np.float64(420.08),\n",
       "     'confidence': 0.971},\n",
       "    {'text': 'But',\n",
       "     'start': np.float64(420.4),\n",
       "     'end': np.float64(420.6),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(420.6),\n",
       "     'end': np.float64(420.74),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'problem',\n",
       "     'start': np.float64(420.74),\n",
       "     'end': np.float64(421.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'here',\n",
       "     'start': np.float64(421.1),\n",
       "     'end': np.float64(421.34),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(421.34),\n",
       "     'end': np.float64(421.48),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(421.48),\n",
       "     'end': np.float64(422.4),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(422.4),\n",
       "     'end': np.float64(422.56),\n",
       "     'confidence': 0.832},\n",
       "    {'text': 'training',\n",
       "     'start': np.float64(422.56),\n",
       "     'end': np.float64(422.9),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'cost',\n",
       "     'start': np.float64(422.9),\n",
       "     'end': np.float64(423.2),\n",
       "     'confidence': 0.95},\n",
       "    {'text': 'error,',\n",
       "     'start': np.float64(423.2),\n",
       "     'end': np.float64(423.5),\n",
       "     'confidence': 0.887},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(423.6),\n",
       "     'end': np.float64(423.74),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(423.74),\n",
       "     'end': np.float64(423.9),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(423.9),\n",
       "     'end': np.float64(424.02),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'minimized,',\n",
       "     'start': np.float64(424.02),\n",
       "     'end': np.float64(424.58),\n",
       "     'confidence': 0.955}]},\n",
       "  {'id': 61,\n",
       "   'seek': 41240,\n",
       "   'start': np.float64(424.6),\n",
       "   'end': np.float64(430.31),\n",
       "   'text': ' if it is too much minimized, then there is chances of overfitting. Then we test it in from the test',\n",
       "   'tokens': [50972,\n",
       "    498,\n",
       "    309,\n",
       "    307,\n",
       "    886,\n",
       "    709,\n",
       "    4464,\n",
       "    1602,\n",
       "    11,\n",
       "    550,\n",
       "    456,\n",
       "    307,\n",
       "    10486,\n",
       "    295,\n",
       "    670,\n",
       "    69,\n",
       "    2414,\n",
       "    13,\n",
       "    1396,\n",
       "    321,\n",
       "    1500,\n",
       "    309,\n",
       "    294,\n",
       "    490,\n",
       "    264,\n",
       "    1500,\n",
       "    51268],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08859089309094,\n",
       "   'compression_ratio': 1.8970588235294117,\n",
       "   'no_speech_prob': 0.023925356566905975,\n",
       "   'confidence': 0.923,\n",
       "   'words': [{'text': 'if',\n",
       "     'start': np.float64(424.6),\n",
       "     'end': np.float64(424.76),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(424.76),\n",
       "     'end': np.float64(424.88),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(424.88),\n",
       "     'end': np.float64(425.02),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'too',\n",
       "     'start': np.float64(425.02),\n",
       "     'end': np.float64(425.24),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'much',\n",
       "     'start': np.float64(425.24),\n",
       "     'end': np.float64(425.42),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'minimized,',\n",
       "     'start': np.float64(425.42),\n",
       "     'end': np.float64(425.92),\n",
       "     'confidence': 0.909},\n",
       "    {'text': 'then',\n",
       "     'start': np.float64(426.16),\n",
       "     'end': np.float64(426.24),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'there',\n",
       "     'start': np.float64(426.24),\n",
       "     'end': np.float64(426.46),\n",
       "     'confidence': 0.929},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(426.46),\n",
       "     'end': np.float64(426.64),\n",
       "     'confidence': 0.96},\n",
       "    {'text': 'chances',\n",
       "     'start': np.float64(426.64),\n",
       "     'end': np.float64(426.92),\n",
       "     'confidence': 0.942},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(426.92),\n",
       "     'end': np.float64(427.16),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'overfitting.',\n",
       "     'start': np.float64(427.16),\n",
       "     'end': np.float64(427.68),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'Then',\n",
       "     'start': np.float64(427.92),\n",
       "     'end': np.float64(428.4),\n",
       "     'confidence': 0.964},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(428.4),\n",
       "     'end': np.float64(428.6),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'test',\n",
       "     'start': np.float64(428.6),\n",
       "     'end': np.float64(428.9),\n",
       "     'confidence': 0.886},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(428.9),\n",
       "     'end': np.float64(429.12),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(429.12),\n",
       "     'end': np.float64(429.5),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(429.5),\n",
       "     'end': np.float64(429.7),\n",
       "     'confidence': 0.523},\n",
       "    {'text': 'from',\n",
       "     'start': np.float64(429.7),\n",
       "     'end': np.float64(430.06),\n",
       "     'confidence': 0.663},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(430.06),\n",
       "     'end': np.float64(430.26),\n",
       "     'confidence': 0.921},\n",
       "    {'text': 'test',\n",
       "     'start': np.float64(430.26),\n",
       "     'end': np.float64(430.31),\n",
       "     'confidence': 0.978}]},\n",
       "  {'id': 62,\n",
       "   'seek': 41240,\n",
       "   'start': np.float64(430.31),\n",
       "   'end': np.float64(436.46),\n",
       "   'text': ' data. And here is the thing in the test data, you want the data in the test should be a production',\n",
       "   'tokens': [51268,\n",
       "    1412,\n",
       "    13,\n",
       "    400,\n",
       "    510,\n",
       "    307,\n",
       "    264,\n",
       "    551,\n",
       "    294,\n",
       "    264,\n",
       "    1500,\n",
       "    1412,\n",
       "    11,\n",
       "    291,\n",
       "    528,\n",
       "    264,\n",
       "    1412,\n",
       "    294,\n",
       "    264,\n",
       "    1500,\n",
       "    820,\n",
       "    312,\n",
       "    257,\n",
       "    4265,\n",
       "    51572],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.08859089309094,\n",
       "   'compression_ratio': 1.8970588235294117,\n",
       "   'no_speech_prob': 0.023925356566905975,\n",
       "   'confidence': 0.927,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(430.31),\n",
       "     'end': np.float64(430.64),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'data.',\n",
       "     'start': np.float64(430.64),\n",
       "     'end': np.float64(430.84),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(431.06),\n",
       "     'end': np.float64(431.08),\n",
       "     'confidence': 0.992},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(431.08),\n",
       "     'end': np.float64(431.52),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'here',\n",
       "     'start': np.float64(431.52),\n",
       "     'end': np.float64(431.76),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(431.76),\n",
       "     'end': np.float64(431.92),\n",
       "     'confidence': 0.752},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(431.92),\n",
       "     'end': np.float64(432.06),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'thing',\n",
       "     'start': np.float64(432.06),\n",
       "     'end': np.float64(432.26),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(432.26),\n",
       "     'end': np.float64(432.46),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(432.46),\n",
       "     'end': np.float64(432.66),\n",
       "     'confidence': 0.491},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(432.66),\n",
       "     'end': np.float64(432.78),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'test',\n",
       "     'start': np.float64(432.78),\n",
       "     'end': np.float64(433.06),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'data,',\n",
       "     'start': np.float64(433.06),\n",
       "     'end': np.float64(433.38),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(433.66),\n",
       "     'end': np.float64(433.88),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'want',\n",
       "     'start': np.float64(433.88),\n",
       "     'end': np.float64(434.16),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(434.16),\n",
       "     'end': np.float64(434.36),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(434.36),\n",
       "     'end': np.float64(434.66),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(434.66),\n",
       "     'end': np.float64(434.86),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(434.86),\n",
       "     'end': np.float64(435.0),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'test',\n",
       "     'start': np.float64(435.0),\n",
       "     'end': np.float64(435.28),\n",
       "     'confidence': 0.916},\n",
       "    {'text': 'should',\n",
       "     'start': np.float64(435.28),\n",
       "     'end': np.float64(435.74),\n",
       "     'confidence': 0.705},\n",
       "    {'text': 'be',\n",
       "     'start': np.float64(435.74),\n",
       "     'end': np.float64(435.94),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(435.94),\n",
       "     'end': np.float64(436.14),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'production',\n",
       "     'start': np.float64(436.14),\n",
       "     'end': np.float64(436.46),\n",
       "     'confidence': 0.925}]},\n",
       "  {'id': 63,\n",
       "   'seek': 43656,\n",
       "   'start': np.float64(436.56),\n",
       "   'end': np.float64(446.78),\n",
       "   'text': ' quality data. I mean, the data on which the model is going to be on which the model is going to work',\n",
       "   'tokens': [50364,\n",
       "    3125,\n",
       "    1412,\n",
       "    13,\n",
       "    286,\n",
       "    914,\n",
       "    11,\n",
       "    264,\n",
       "    1412,\n",
       "    322,\n",
       "    597,\n",
       "    264,\n",
       "    2316,\n",
       "    307,\n",
       "    516,\n",
       "    281,\n",
       "    312,\n",
       "    322,\n",
       "    597,\n",
       "    264,\n",
       "    2316,\n",
       "    307,\n",
       "    516,\n",
       "    281,\n",
       "    589,\n",
       "    50876],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12453098786182892,\n",
       "   'compression_ratio': 1.7926829268292683,\n",
       "   'no_speech_prob': 0.038893166929483414,\n",
       "   'confidence': 0.85,\n",
       "   'words': [{'text': 'quality',\n",
       "     'start': np.float64(436.56),\n",
       "     'end': np.float64(436.92),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'data.',\n",
       "     'start': np.float64(436.92),\n",
       "     'end': np.float64(437.26),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(437.62),\n",
       "     'end': np.float64(438.0),\n",
       "     'confidence': 0.764},\n",
       "    {'text': 'mean,',\n",
       "     'start': np.float64(438.0),\n",
       "     'end': np.float64(438.16),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(438.46),\n",
       "     'end': np.float64(438.86),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(438.86),\n",
       "     'end': np.float64(439.18),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(439.18),\n",
       "     'end': np.float64(440.02),\n",
       "     'confidence': 0.513},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(440.02),\n",
       "     'end': np.float64(440.28),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(440.28),\n",
       "     'end': np.float64(440.56),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(440.56),\n",
       "     'end': np.float64(440.82),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(440.82),\n",
       "     'end': np.float64(441.02),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'going',\n",
       "     'start': np.float64(441.02),\n",
       "     'end': np.float64(441.2),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(441.2),\n",
       "     'end': np.float64(441.5),\n",
       "     'confidence': 0.986},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(441.5),\n",
       "     'end': np.float64(441.92),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'be',\n",
       "     'start': np.float64(441.92),\n",
       "     'end': np.float64(442.5),\n",
       "     'confidence': 0.589},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(442.5),\n",
       "     'end': np.float64(443.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(443.32),\n",
       "     'end': np.float64(443.6),\n",
       "     'confidence': 0.399},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(443.6),\n",
       "     'end': np.float64(445.26),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(445.26),\n",
       "     'end': np.float64(445.42),\n",
       "     'confidence': 0.866},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(445.42),\n",
       "     'end': np.float64(445.78),\n",
       "     'confidence': 0.906},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(445.78),\n",
       "     'end': np.float64(446.02),\n",
       "     'confidence': 0.962},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(446.02),\n",
       "     'end': np.float64(446.22),\n",
       "     'confidence': 0.965},\n",
       "    {'text': 'going',\n",
       "     'start': np.float64(446.22),\n",
       "     'end': np.float64(446.4),\n",
       "     'confidence': 0.863},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(446.4),\n",
       "     'end': np.float64(446.58),\n",
       "     'confidence': 0.874},\n",
       "    {'text': 'work',\n",
       "     'start': np.float64(446.58),\n",
       "     'end': np.float64(446.78),\n",
       "     'confidence': 0.602}]},\n",
       "  {'id': 64,\n",
       "   'seek': 43656,\n",
       "   'start': np.float64(446.82),\n",
       "   'end': np.float64(451.9),\n",
       "   'text': ' on. So in the actual production, what kind of data you will get and what kind of data you are',\n",
       "   'tokens': [50876,\n",
       "    322,\n",
       "    13,\n",
       "    407,\n",
       "    294,\n",
       "    264,\n",
       "    3539,\n",
       "    4265,\n",
       "    11,\n",
       "    437,\n",
       "    733,\n",
       "    295,\n",
       "    1412,\n",
       "    291,\n",
       "    486,\n",
       "    483,\n",
       "    293,\n",
       "    437,\n",
       "    733,\n",
       "    295,\n",
       "    1412,\n",
       "    291,\n",
       "    366,\n",
       "    51132],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12453098786182892,\n",
       "   'compression_ratio': 1.7926829268292683,\n",
       "   'no_speech_prob': 0.038893166929483414,\n",
       "   'confidence': 0.956,\n",
       "   'words': [{'text': 'on.',\n",
       "     'start': np.float64(446.82),\n",
       "     'end': np.float64(447.0),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(447.36),\n",
       "     'end': np.float64(447.56),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(447.56),\n",
       "     'end': np.float64(447.68),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(447.68),\n",
       "     'end': np.float64(447.76),\n",
       "     'confidence': 0.855},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(447.76),\n",
       "     'end': np.float64(447.78),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'actual',\n",
       "     'start': np.float64(447.78),\n",
       "     'end': np.float64(448.04),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'production,',\n",
       "     'start': np.float64(448.04),\n",
       "     'end': np.float64(448.52),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(449.02),\n",
       "     'end': np.float64(449.2),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'kind',\n",
       "     'start': np.float64(449.2),\n",
       "     'end': np.float64(449.42),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(449.42),\n",
       "     'end': np.float64(449.58),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(449.58),\n",
       "     'end': np.float64(449.8),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(449.8),\n",
       "     'end': np.float64(450.0),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'will',\n",
       "     'start': np.float64(450.0),\n",
       "     'end': np.float64(450.12),\n",
       "     'confidence': 0.905},\n",
       "    {'text': 'get',\n",
       "     'start': np.float64(450.12),\n",
       "     'end': np.float64(450.36),\n",
       "     'confidence': 1.0},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(450.36),\n",
       "     'end': np.float64(450.64),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(450.64),\n",
       "     'end': np.float64(450.8),\n",
       "     'confidence': 0.696},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(450.8),\n",
       "     'end': np.float64(450.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'kind',\n",
       "     'start': np.float64(450.98),\n",
       "     'end': np.float64(451.22),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(451.22),\n",
       "     'end': np.float64(451.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(451.38),\n",
       "     'end': np.float64(451.62),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(451.62),\n",
       "     'end': np.float64(451.78),\n",
       "     'confidence': 0.93},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(451.78),\n",
       "     'end': np.float64(451.9),\n",
       "     'confidence': 0.86}]},\n",
       "  {'id': 65,\n",
       "   'seek': 43656,\n",
       "   'start': np.float64(451.9),\n",
       "   'end': np.float64(459.34),\n",
       "   'text': ' expecting the model to do well on, right? You will put that data into the test data. So test it and',\n",
       "   'tokens': [51132,\n",
       "    9650,\n",
       "    264,\n",
       "    2316,\n",
       "    281,\n",
       "    360,\n",
       "    731,\n",
       "    322,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    509,\n",
       "    486,\n",
       "    829,\n",
       "    300,\n",
       "    1412,\n",
       "    666,\n",
       "    264,\n",
       "    1500,\n",
       "    1412,\n",
       "    13,\n",
       "    407,\n",
       "    1500,\n",
       "    309,\n",
       "    293,\n",
       "    51504],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12453098786182892,\n",
       "   'compression_ratio': 1.7926829268292683,\n",
       "   'no_speech_prob': 0.038893166929483414,\n",
       "   'confidence': 0.886,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(451.9),\n",
       "     'end': np.float64(451.94),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'expecting',\n",
       "     'start': np.float64(451.94),\n",
       "     'end': np.float64(452.38),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(452.38),\n",
       "     'end': np.float64(452.84),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(452.84),\n",
       "     'end': np.float64(453.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(453.1),\n",
       "     'end': np.float64(453.4),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(453.4),\n",
       "     'end': np.float64(453.7),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(453.7),\n",
       "     'end': np.float64(454.06),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'well',\n",
       "     'start': np.float64(454.06),\n",
       "     'end': np.float64(454.28),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'on,',\n",
       "     'start': np.float64(454.28),\n",
       "     'end': np.float64(454.44),\n",
       "     'confidence': 0.922},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(454.46),\n",
       "     'end': np.float64(454.62),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'You',\n",
       "     'start': np.float64(454.86),\n",
       "     'end': np.float64(455.18),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'will',\n",
       "     'start': np.float64(455.18),\n",
       "     'end': np.float64(455.3),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'put',\n",
       "     'start': np.float64(455.3),\n",
       "     'end': np.float64(455.54),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(455.54),\n",
       "     'end': np.float64(455.8),\n",
       "     'confidence': 0.976},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(455.8),\n",
       "     'end': np.float64(456.12),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(456.12),\n",
       "     'end': np.float64(456.14),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'into',\n",
       "     'start': np.float64(456.14),\n",
       "     'end': np.float64(456.4),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(456.4),\n",
       "     'end': np.float64(456.6),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'test',\n",
       "     'start': np.float64(456.6),\n",
       "     'end': np.float64(456.84),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'data.',\n",
       "     'start': np.float64(456.84),\n",
       "     'end': np.float64(457.14),\n",
       "     'confidence': 0.972},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(457.14),\n",
       "     'end': np.float64(457.74),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(457.74),\n",
       "     'end': np.float64(458.32),\n",
       "     'confidence': 0.519},\n",
       "    {'text': 'test',\n",
       "     'start': np.float64(458.32),\n",
       "     'end': np.float64(458.6),\n",
       "     'confidence': 0.935},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(458.6),\n",
       "     'end': np.float64(458.82),\n",
       "     'confidence': 0.65},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(458.82),\n",
       "     'end': np.float64(459.34),\n",
       "     'confidence': 0.305}]},\n",
       "  {'id': 66,\n",
       "   'seek': 45936,\n",
       "   'start': np.float64(459.36),\n",
       "   'end': np.float64(467.16),\n",
       "   'text': ' you will check the errors or root mean square error, how much error is the model giving on that set.',\n",
       "   'tokens': [50364,\n",
       "    291,\n",
       "    486,\n",
       "    1520,\n",
       "    264,\n",
       "    13603,\n",
       "    420,\n",
       "    5593,\n",
       "    914,\n",
       "    3732,\n",
       "    6713,\n",
       "    11,\n",
       "    577,\n",
       "    709,\n",
       "    6713,\n",
       "    307,\n",
       "    264,\n",
       "    2316,\n",
       "    2902,\n",
       "    322,\n",
       "    300,\n",
       "    992,\n",
       "    13,\n",
       "    50756],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12404599140599831,\n",
       "   'compression_ratio': 1.7636363636363637,\n",
       "   'no_speech_prob': 0.12055857479572296,\n",
       "   'confidence': 0.934,\n",
       "   'words': [{'text': 'you',\n",
       "     'start': np.float64(459.36),\n",
       "     'end': np.float64(459.62),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'will',\n",
       "     'start': np.float64(459.62),\n",
       "     'end': np.float64(459.78),\n",
       "     'confidence': 0.994},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(459.78),\n",
       "     'end': np.float64(460.12),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'check',\n",
       "     'start': np.float64(460.12),\n",
       "     'end': np.float64(460.3),\n",
       "     'confidence': 0.996},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(460.3),\n",
       "     'end': np.float64(460.88),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(460.88),\n",
       "     'end': np.float64(461.12),\n",
       "     'confidence': 0.981},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(461.12),\n",
       "     'end': np.float64(461.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'errors',\n",
       "     'start': np.float64(461.56),\n",
       "     'end': np.float64(462.0),\n",
       "     'confidence': 0.878},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(462.0),\n",
       "     'end': np.float64(462.34),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(462.34),\n",
       "     'end': np.float64(462.54),\n",
       "     'confidence': 0.61},\n",
       "    {'text': 'root',\n",
       "     'start': np.float64(462.54),\n",
       "     'end': np.float64(462.84),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'mean',\n",
       "     'start': np.float64(462.84),\n",
       "     'end': np.float64(463.04),\n",
       "     'confidence': 0.962},\n",
       "    {'text': 'square',\n",
       "     'start': np.float64(463.04),\n",
       "     'end': np.float64(463.3),\n",
       "     'confidence': 0.965},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(463.3),\n",
       "     'end': np.float64(463.52),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'error,',\n",
       "     'start': np.float64(463.52),\n",
       "     'end': np.float64(463.64),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(464.06),\n",
       "     'end': np.float64(464.24),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'much',\n",
       "     'start': np.float64(464.24),\n",
       "     'end': np.float64(464.42),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'error',\n",
       "     'start': np.float64(464.42),\n",
       "     'end': np.float64(464.72),\n",
       "     'confidence': 0.997},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(464.72),\n",
       "     'end': np.float64(465.06),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(465.06),\n",
       "     'end': np.float64(465.26),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(465.26),\n",
       "     'end': np.float64(465.44),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(465.44),\n",
       "     'end': np.float64(465.76),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'giving',\n",
       "     'start': np.float64(465.76),\n",
       "     'end': np.float64(466.28),\n",
       "     'confidence': 0.885},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(466.28),\n",
       "     'end': np.float64(466.62),\n",
       "     'confidence': 0.974},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(466.62),\n",
       "     'end': np.float64(466.88),\n",
       "     'confidence': 0.791},\n",
       "    {'text': 'set.',\n",
       "     'start': np.float64(466.88),\n",
       "     'end': np.float64(467.16),\n",
       "     'confidence': 0.828}]},\n",
       "  {'id': 67,\n",
       "   'seek': 45936,\n",
       "   'start': np.float64(467.9),\n",
       "   'end': np.float64(474.58),\n",
       "   'text': \" So that is how you'll know that how well the model is generalized, right? So this is the in the case\",\n",
       "   'tokens': [50788,\n",
       "    407,\n",
       "    300,\n",
       "    307,\n",
       "    577,\n",
       "    291,\n",
       "    603,\n",
       "    458,\n",
       "    300,\n",
       "    577,\n",
       "    731,\n",
       "    264,\n",
       "    2316,\n",
       "    307,\n",
       "    44498,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    407,\n",
       "    341,\n",
       "    307,\n",
       "    264,\n",
       "    294,\n",
       "    264,\n",
       "    1389,\n",
       "    51128],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12404599140599831,\n",
       "   'compression_ratio': 1.7636363636363637,\n",
       "   'no_speech_prob': 0.12055857479572296,\n",
       "   'confidence': 0.841,\n",
       "   'words': [{'text': 'So',\n",
       "     'start': np.float64(467.9),\n",
       "     'end': np.float64(468.12),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(468.12),\n",
       "     'end': np.float64(468.64),\n",
       "     'confidence': 0.965},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(468.64),\n",
       "     'end': np.float64(468.86),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(468.86),\n",
       "     'end': np.float64(469.08),\n",
       "     'confidence': 0.999},\n",
       "    {'text': \"you'll\",\n",
       "     'start': np.float64(469.08),\n",
       "     'end': np.float64(469.38),\n",
       "     'confidence': 0.831},\n",
       "    {'text': 'know',\n",
       "     'start': np.float64(469.38),\n",
       "     'end': np.float64(469.6),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(469.6),\n",
       "     'end': np.float64(469.98),\n",
       "     'confidence': 0.978},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(469.98),\n",
       "     'end': np.float64(470.3),\n",
       "     'confidence': 0.953},\n",
       "    {'text': 'well',\n",
       "     'start': np.float64(470.3),\n",
       "     'end': np.float64(470.54),\n",
       "     'confidence': 0.953},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(470.54),\n",
       "     'end': np.float64(470.76),\n",
       "     'confidence': 0.977},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(470.76),\n",
       "     'end': np.float64(471.36),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(471.36),\n",
       "     'end': np.float64(471.48),\n",
       "     'confidence': 0.974},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(471.48),\n",
       "     'end': np.float64(471.74),\n",
       "     'confidence': 0.527},\n",
       "    {'text': 'generalized,',\n",
       "     'start': np.float64(471.74),\n",
       "     'end': np.float64(472.32),\n",
       "     'confidence': 0.737},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(472.64),\n",
       "     'end': np.float64(472.9),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(473.3),\n",
       "     'end': np.float64(473.5),\n",
       "     'confidence': 0.903},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(473.5),\n",
       "     'end': np.float64(473.7),\n",
       "     'confidence': 0.943},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(473.7),\n",
       "     'end': np.float64(473.86),\n",
       "     'confidence': 0.935},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(473.86),\n",
       "     'end': np.float64(474.02),\n",
       "     'confidence': 0.543},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(474.02),\n",
       "     'end': np.float64(474.3),\n",
       "     'confidence': 0.341},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(474.3),\n",
       "     'end': np.float64(474.44),\n",
       "     'confidence': 0.803},\n",
       "    {'text': 'case',\n",
       "     'start': np.float64(474.44),\n",
       "     'end': np.float64(474.58),\n",
       "     'confidence': 0.877}]},\n",
       "  {'id': 68,\n",
       "   'seek': 45936,\n",
       "   'start': np.float64(474.58),\n",
       "   'end': np.float64(479.4),\n",
       "   'text': ' of regression task. For example, you get classification task. In the case of classification',\n",
       "   'tokens': [51128,\n",
       "    295,\n",
       "    24590,\n",
       "    5633,\n",
       "    13,\n",
       "    1171,\n",
       "    1365,\n",
       "    11,\n",
       "    291,\n",
       "    483,\n",
       "    21538,\n",
       "    5633,\n",
       "    13,\n",
       "    682,\n",
       "    264,\n",
       "    1389,\n",
       "    295,\n",
       "    21538,\n",
       "    51380],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12404599140599831,\n",
       "   'compression_ratio': 1.7636363636363637,\n",
       "   'no_speech_prob': 0.12055857479572296,\n",
       "   'confidence': 0.893,\n",
       "   'words': [{'text': 'of',\n",
       "     'start': np.float64(474.58),\n",
       "     'end': np.float64(474.84),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'regression',\n",
       "     'start': np.float64(474.84),\n",
       "     'end': np.float64(475.24),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'task.',\n",
       "     'start': np.float64(475.24),\n",
       "     'end': np.float64(475.64),\n",
       "     'confidence': 0.51},\n",
       "    {'text': 'For',\n",
       "     'start': np.float64(475.82),\n",
       "     'end': np.float64(476.02),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(476.02),\n",
       "     'end': np.float64(476.28),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(476.42),\n",
       "     'end': np.float64(476.52),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'get',\n",
       "     'start': np.float64(476.52),\n",
       "     'end': np.float64(476.72),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'classification',\n",
       "     'start': np.float64(476.72),\n",
       "     'end': np.float64(477.42),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'task.',\n",
       "     'start': np.float64(477.42),\n",
       "     'end': np.float64(477.98),\n",
       "     'confidence': 0.638},\n",
       "    {'text': 'In',\n",
       "     'start': np.float64(478.14),\n",
       "     'end': np.float64(478.48),\n",
       "     'confidence': 0.645},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(478.48),\n",
       "     'end': np.float64(478.58),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'case',\n",
       "     'start': np.float64(478.58),\n",
       "     'end': np.float64(478.78),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(478.78),\n",
       "     'end': np.float64(478.92),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'classification',\n",
       "     'start': np.float64(478.92),\n",
       "     'end': np.float64(479.4),\n",
       "     'confidence': 0.998}]},\n",
       "  {'id': 69,\n",
       "   'seek': 45936,\n",
       "   'start': np.float64(479.5),\n",
       "   'end': np.float64(485.5),\n",
       "   'text': \" task, it is very tough, not very tough, but the thing is you can't just check if it is correct\",\n",
       "   'tokens': [51380,\n",
       "    5633,\n",
       "    11,\n",
       "    309,\n",
       "    307,\n",
       "    588,\n",
       "    4930,\n",
       "    11,\n",
       "    406,\n",
       "    588,\n",
       "    4930,\n",
       "    11,\n",
       "    457,\n",
       "    264,\n",
       "    551,\n",
       "    307,\n",
       "    291,\n",
       "    393,\n",
       "    380,\n",
       "    445,\n",
       "    1520,\n",
       "    498,\n",
       "    309,\n",
       "    307,\n",
       "    3006,\n",
       "    51680],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12404599140599831,\n",
       "   'compression_ratio': 1.7636363636363637,\n",
       "   'no_speech_prob': 0.12055857479572296,\n",
       "   'confidence': 0.972,\n",
       "   'words': [{'text': 'task,',\n",
       "     'start': np.float64(479.5),\n",
       "     'end': np.float64(479.92),\n",
       "     'confidence': 0.942},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(480.06),\n",
       "     'end': np.float64(480.2),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(480.2),\n",
       "     'end': np.float64(480.32),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(480.32),\n",
       "     'end': np.float64(480.54),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'tough,',\n",
       "     'start': np.float64(480.54),\n",
       "     'end': np.float64(480.86),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'not',\n",
       "     'start': np.float64(481.0),\n",
       "     'end': np.float64(481.48),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(481.48),\n",
       "     'end': np.float64(481.74),\n",
       "     'confidence': 0.958},\n",
       "    {'text': 'tough,',\n",
       "     'start': np.float64(481.74),\n",
       "     'end': np.float64(481.96),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'but',\n",
       "     'start': np.float64(482.14),\n",
       "     'end': np.float64(482.18),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(482.18),\n",
       "     'end': np.float64(482.5),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'thing',\n",
       "     'start': np.float64(482.5),\n",
       "     'end': np.float64(482.7),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(482.7),\n",
       "     'end': np.float64(482.86),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(482.86),\n",
       "     'end': np.float64(482.98),\n",
       "     'confidence': 0.85},\n",
       "    {'text': \"can't\",\n",
       "     'start': np.float64(482.98),\n",
       "     'end': np.float64(483.26),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'just',\n",
       "     'start': np.float64(483.26),\n",
       "     'end': np.float64(483.5),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(483.5),\n",
       "     'end': np.float64(484.4),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'check',\n",
       "     'start': np.float64(484.4),\n",
       "     'end': np.float64(484.56),\n",
       "     'confidence': 0.885},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(484.56),\n",
       "     'end': np.float64(484.78),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(484.78),\n",
       "     'end': np.float64(484.94),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(484.94),\n",
       "     'end': np.float64(485.1),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'correct',\n",
       "     'start': np.float64(485.1),\n",
       "     'end': np.float64(485.5),\n",
       "     'confidence': 0.873}]},\n",
       "  {'id': 70,\n",
       "   'seek': 48568,\n",
       "   'start': np.float64(485.76),\n",
       "   'end': np.float64(493.72),\n",
       "   'text': ' or non-correct, right? Because if the data set is skewed, so you know the 70% of the data is like',\n",
       "   'tokens': [50364,\n",
       "    420,\n",
       "    2107,\n",
       "    12,\n",
       "    19558,\n",
       "    2554,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    1436,\n",
       "    498,\n",
       "    264,\n",
       "    1412,\n",
       "    992,\n",
       "    307,\n",
       "    8756,\n",
       "    26896,\n",
       "    11,\n",
       "    370,\n",
       "    291,\n",
       "    458,\n",
       "    264,\n",
       "    5285,\n",
       "    4,\n",
       "    295,\n",
       "    264,\n",
       "    1412,\n",
       "    307,\n",
       "    411,\n",
       "    50764],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14173248970862662,\n",
       "   'compression_ratio': 1.820754716981132,\n",
       "   'no_speech_prob': 0.0149857671931386,\n",
       "   'confidence': 0.848,\n",
       "   'words': [{'text': 'or',\n",
       "     'start': np.float64(485.76),\n",
       "     'end': np.float64(485.9),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'non-correct,',\n",
       "     'start': np.float64(485.9),\n",
       "     'end': np.float64(487.04),\n",
       "     'confidence': 0.755},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(487.28),\n",
       "     'end': np.float64(487.5),\n",
       "     'confidence': 0.957},\n",
       "    {'text': 'Because',\n",
       "     'start': np.float64(487.98),\n",
       "     'end': np.float64(488.1),\n",
       "     'confidence': 0.979},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(488.1),\n",
       "     'end': np.float64(488.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(488.56),\n",
       "     'end': np.float64(488.78),\n",
       "     'confidence': 0.974},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(488.78),\n",
       "     'end': np.float64(489.5),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(489.5),\n",
       "     'end': np.float64(489.78),\n",
       "     'confidence': 0.656},\n",
       "    {'text': 'set',\n",
       "     'start': np.float64(489.78),\n",
       "     'end': np.float64(490.04),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(490.04),\n",
       "     'end': np.float64(490.22),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'skewed,',\n",
       "     'start': np.float64(490.22),\n",
       "     'end': np.float64(490.7),\n",
       "     'confidence': 0.946},\n",
       "    {'text': 'so',\n",
       "     'start': np.float64(490.78),\n",
       "     'end': np.float64(491.02),\n",
       "     'confidence': 0.924},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(491.02),\n",
       "     'end': np.float64(491.32),\n",
       "     'confidence': 0.88},\n",
       "    {'text': 'know',\n",
       "     'start': np.float64(491.32),\n",
       "     'end': np.float64(491.5),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(491.5),\n",
       "     'end': np.float64(491.68),\n",
       "     'confidence': 0.45},\n",
       "    {'text': '70%',\n",
       "     'start': np.float64(491.68),\n",
       "     'end': np.float64(492.02),\n",
       "     'confidence': 0.971},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(492.38),\n",
       "     'end': np.float64(492.6),\n",
       "     'confidence': 0.9},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(492.6),\n",
       "     'end': np.float64(492.76),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(492.76),\n",
       "     'end': np.float64(493.0),\n",
       "     'confidence': 0.958},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(493.0),\n",
       "     'end': np.float64(493.34),\n",
       "     'confidence': 0.861},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(493.34),\n",
       "     'end': np.float64(493.72),\n",
       "     'confidence': 0.436}]},\n",
       "  {'id': 71,\n",
       "   'seek': 48568,\n",
       "   'start': np.float64(494.58),\n",
       "   'end': np.float64(499.88),\n",
       "   'text': ' it is a classification task. So for example, you are testing if the patient has a heart disease',\n",
       "   'tokens': [50804,\n",
       "    309,\n",
       "    307,\n",
       "    257,\n",
       "    21538,\n",
       "    5633,\n",
       "    13,\n",
       "    407,\n",
       "    337,\n",
       "    1365,\n",
       "    11,\n",
       "    291,\n",
       "    366,\n",
       "    4997,\n",
       "    498,\n",
       "    264,\n",
       "    4537,\n",
       "    575,\n",
       "    257,\n",
       "    1917,\n",
       "    4752,\n",
       "    51092],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14173248970862662,\n",
       "   'compression_ratio': 1.820754716981132,\n",
       "   'no_speech_prob': 0.0149857671931386,\n",
       "   'confidence': 0.946,\n",
       "   'words': [{'text': 'it',\n",
       "     'start': np.float64(494.58),\n",
       "     'end': np.float64(494.7),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(494.7),\n",
       "     'end': np.float64(494.84),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(494.84),\n",
       "     'end': np.float64(495.0),\n",
       "     'confidence': 0.927},\n",
       "    {'text': 'classification',\n",
       "     'start': np.float64(495.0),\n",
       "     'end': np.float64(495.46),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'task.',\n",
       "     'start': np.float64(495.46),\n",
       "     'end': np.float64(495.94),\n",
       "     'confidence': 0.972},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(496.22),\n",
       "     'end': np.float64(496.24),\n",
       "     'confidence': 0.849},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(496.24),\n",
       "     'end': np.float64(496.8),\n",
       "     'confidence': 0.735},\n",
       "    {'text': 'example,',\n",
       "     'start': np.float64(496.8),\n",
       "     'end': np.float64(497.14),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(497.3),\n",
       "     'end': np.float64(497.4),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(497.4),\n",
       "     'end': np.float64(497.5),\n",
       "     'confidence': 0.964},\n",
       "    {'text': 'testing',\n",
       "     'start': np.float64(497.5),\n",
       "     'end': np.float64(497.78),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(497.78),\n",
       "     'end': np.float64(498.06),\n",
       "     'confidence': 0.923},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(498.06),\n",
       "     'end': np.float64(498.6),\n",
       "     'confidence': 0.854},\n",
       "    {'text': 'patient',\n",
       "     'start': np.float64(498.6),\n",
       "     'end': np.float64(498.94),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'has',\n",
       "     'start': np.float64(498.94),\n",
       "     'end': np.float64(499.28),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(499.28),\n",
       "     'end': np.float64(499.46),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'heart',\n",
       "     'start': np.float64(499.46),\n",
       "     'end': np.float64(499.6),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'disease',\n",
       "     'start': np.float64(499.6),\n",
       "     'end': np.float64(499.88),\n",
       "     'confidence': 0.934}]},\n",
       "  {'id': 72,\n",
       "   'seek': 48568,\n",
       "   'start': np.float64(500.3),\n",
       "   'end': np.float64(507.98),\n",
       "   'text': ' or not. And the data set actually has 70% patients which have like diseases and they have a heart',\n",
       "   'tokens': [51092,\n",
       "    420,\n",
       "    406,\n",
       "    13,\n",
       "    400,\n",
       "    264,\n",
       "    1412,\n",
       "    992,\n",
       "    767,\n",
       "    575,\n",
       "    5285,\n",
       "    4,\n",
       "    4209,\n",
       "    597,\n",
       "    362,\n",
       "    411,\n",
       "    11044,\n",
       "    293,\n",
       "    436,\n",
       "    362,\n",
       "    257,\n",
       "    1917,\n",
       "    51488],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14173248970862662,\n",
       "   'compression_ratio': 1.820754716981132,\n",
       "   'no_speech_prob': 0.0149857671931386,\n",
       "   'confidence': 0.831,\n",
       "   'words': [{'text': 'or',\n",
       "     'start': np.float64(500.3),\n",
       "     'end': np.float64(500.46),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'not.',\n",
       "     'start': np.float64(500.46),\n",
       "     'end': np.float64(500.66),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(500.66),\n",
       "     'end': np.float64(501.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(501.32),\n",
       "     'end': np.float64(501.46),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(501.46),\n",
       "     'end': np.float64(501.6),\n",
       "     'confidence': 0.981},\n",
       "    {'text': 'data',\n",
       "     'start': np.float64(501.6),\n",
       "     'end': np.float64(501.82),\n",
       "     'confidence': 0.846},\n",
       "    {'text': 'set',\n",
       "     'start': np.float64(501.82),\n",
       "     'end': np.float64(502.02),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(502.02),\n",
       "     'end': np.float64(502.36),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'has',\n",
       "     'start': np.float64(502.36),\n",
       "     'end': np.float64(502.6),\n",
       "     'confidence': 0.99},\n",
       "    {'text': '70%',\n",
       "     'start': np.float64(502.6),\n",
       "     'end': np.float64(502.92),\n",
       "     'confidence': 0.988},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(503.22),\n",
       "     'end': np.float64(503.46),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'patients',\n",
       "     'start': np.float64(503.46),\n",
       "     'end': np.float64(503.56),\n",
       "     'confidence': 0.935},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(503.56),\n",
       "     'end': np.float64(503.9),\n",
       "     'confidence': 0.85},\n",
       "    {'text': 'have',\n",
       "     'start': np.float64(503.9),\n",
       "     'end': np.float64(504.2),\n",
       "     'confidence': 0.982},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(504.2),\n",
       "     'end': np.float64(505.26),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(505.26),\n",
       "     'end': np.float64(505.4),\n",
       "     'confidence': 0.396},\n",
       "    {'text': 'diseases',\n",
       "     'start': np.float64(505.4),\n",
       "     'end': np.float64(505.88),\n",
       "     'confidence': 0.868},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(505.88),\n",
       "     'end': np.float64(506.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(506.32),\n",
       "     'end': np.float64(506.66),\n",
       "     'confidence': 0.474},\n",
       "    {'text': 'they',\n",
       "     'start': np.float64(506.66),\n",
       "     'end': np.float64(507.12),\n",
       "     'confidence': 0.883},\n",
       "    {'text': 'have',\n",
       "     'start': np.float64(507.12),\n",
       "     'end': np.float64(507.32),\n",
       "     'confidence': 0.89},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(507.32),\n",
       "     'end': np.float64(507.74),\n",
       "     'confidence': 0.402},\n",
       "    {'text': 'heart',\n",
       "     'start': np.float64(507.74),\n",
       "     'end': np.float64(507.98),\n",
       "     'confidence': 0.934}]},\n",
       "  {'id': 73,\n",
       "   'seek': 48568,\n",
       "   'start': np.float64(507.98),\n",
       "   'end': np.float64(514.36),\n",
       "   'text': ' disease. So if the model just predicts all two, if the model just predicts that all have heart',\n",
       "   'tokens': [51488,\n",
       "    4752,\n",
       "    13,\n",
       "    407,\n",
       "    498,\n",
       "    264,\n",
       "    2316,\n",
       "    445,\n",
       "    6069,\n",
       "    82,\n",
       "    439,\n",
       "    732,\n",
       "    11,\n",
       "    498,\n",
       "    264,\n",
       "    2316,\n",
       "    445,\n",
       "    6069,\n",
       "    82,\n",
       "    300,\n",
       "    439,\n",
       "    362,\n",
       "    1917,\n",
       "    51796],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14173248970862662,\n",
       "   'compression_ratio': 1.820754716981132,\n",
       "   'no_speech_prob': 0.0149857671931386,\n",
       "   'confidence': 0.913,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(507.98),\n",
       "     'end': np.float64(508.24),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'disease.',\n",
       "     'start': np.float64(508.24),\n",
       "     'end': np.float64(508.44),\n",
       "     'confidence': 0.807},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(508.86),\n",
       "     'end': np.float64(509.1),\n",
       "     'confidence': 0.993},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(509.1),\n",
       "     'end': np.float64(509.44),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(509.44),\n",
       "     'end': np.float64(509.64),\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(509.64),\n",
       "     'end': np.float64(509.76),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(509.76),\n",
       "     'end': np.float64(510.04),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'just',\n",
       "     'start': np.float64(510.04),\n",
       "     'end': np.float64(510.28),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'predicts',\n",
       "     'start': np.float64(510.28),\n",
       "     'end': np.float64(511.16),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'all',\n",
       "     'start': np.float64(511.16),\n",
       "     'end': np.float64(511.38),\n",
       "     'confidence': 0.706},\n",
       "    {'text': 'two,',\n",
       "     'start': np.float64(511.38),\n",
       "     'end': np.float64(511.7),\n",
       "     'confidence': 0.578},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(512.0),\n",
       "     'end': np.float64(512.22),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(512.22),\n",
       "     'end': np.float64(512.36),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(512.36),\n",
       "     'end': np.float64(512.6),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'just',\n",
       "     'start': np.float64(512.6),\n",
       "     'end': np.float64(512.94),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'predicts',\n",
       "     'start': np.float64(512.94),\n",
       "     'end': np.float64(513.38),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(513.38),\n",
       "     'end': np.float64(513.52),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'all',\n",
       "     'start': np.float64(513.52),\n",
       "     'end': np.float64(513.78),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'have',\n",
       "     'start': np.float64(513.78),\n",
       "     'end': np.float64(513.98),\n",
       "     'confidence': 0.716},\n",
       "    {'text': 'heart',\n",
       "     'start': np.float64(513.98),\n",
       "     'end': np.float64(514.36),\n",
       "     'confidence': 0.823}]},\n",
       "  {'id': 74,\n",
       "   'seek': 51432,\n",
       "   'start': np.float64(514.36),\n",
       "   'end': np.float64(523.14),\n",
       "   'text': \" disease, still it gets 70% accuracy, right? So we don't want that. So here what we do is that we\",\n",
       "   'tokens': [50364,\n",
       "    4752,\n",
       "    11,\n",
       "    920,\n",
       "    309,\n",
       "    2170,\n",
       "    5285,\n",
       "    4,\n",
       "    14170,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    407,\n",
       "    321,\n",
       "    500,\n",
       "    380,\n",
       "    528,\n",
       "    300,\n",
       "    13,\n",
       "    407,\n",
       "    510,\n",
       "    437,\n",
       "    321,\n",
       "    360,\n",
       "    307,\n",
       "    300,\n",
       "    321,\n",
       "    50804],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1563135545645187,\n",
       "   'compression_ratio': 1.8355263157894737,\n",
       "   'no_speech_prob': 0.01193438470363617,\n",
       "   'confidence': 0.912,\n",
       "   'words': [{'text': 'disease,',\n",
       "     'start': np.float64(514.36),\n",
       "     'end': np.float64(514.68),\n",
       "     'confidence': 0.846},\n",
       "    {'text': 'still',\n",
       "     'start': np.float64(514.8),\n",
       "     'end': np.float64(515.02),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(515.02),\n",
       "     'end': np.float64(515.2),\n",
       "     'confidence': 0.97},\n",
       "    {'text': 'gets',\n",
       "     'start': np.float64(515.2),\n",
       "     'end': np.float64(515.52),\n",
       "     'confidence': 0.936},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(515.52),\n",
       "     'end': np.float64(516.1),\n",
       "     'confidence': 0.0},\n",
       "    {'text': '70%',\n",
       "     'start': np.float64(516.1),\n",
       "     'end': np.float64(516.56),\n",
       "     'confidence': 0.95},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(516.96),\n",
       "     'end': np.float64(517.86),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'accuracy,',\n",
       "     'start': np.float64(517.86),\n",
       "     'end': np.float64(518.0),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(518.2),\n",
       "     'end': np.float64(518.36),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(518.64),\n",
       "     'end': np.float64(518.8),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(518.8),\n",
       "     'end': np.float64(518.92),\n",
       "     'confidence': 0.984},\n",
       "    {'text': \"don't\",\n",
       "     'start': np.float64(518.92),\n",
       "     'end': np.float64(519.2),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'want',\n",
       "     'start': np.float64(519.2),\n",
       "     'end': np.float64(519.48),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'that.',\n",
       "     'start': np.float64(519.48),\n",
       "     'end': np.float64(519.76),\n",
       "     'confidence': 0.997},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(519.76),\n",
       "     'end': np.float64(520.36),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(520.36),\n",
       "     'end': np.float64(520.86),\n",
       "     'confidence': 0.89},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(520.86),\n",
       "     'end': np.float64(521.26),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'here',\n",
       "     'start': np.float64(521.26),\n",
       "     'end': np.float64(521.56),\n",
       "     'confidence': 0.876},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(521.56),\n",
       "     'end': np.float64(522.04),\n",
       "     'confidence': 0.467},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(522.04),\n",
       "     'end': np.float64(522.26),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(522.26),\n",
       "     'end': np.float64(522.48),\n",
       "     'confidence': 0.975},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(522.48),\n",
       "     'end': np.float64(522.74),\n",
       "     'confidence': 0.882},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(522.74),\n",
       "     'end': np.float64(522.92),\n",
       "     'confidence': 0.924},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(522.92),\n",
       "     'end': np.float64(523.14),\n",
       "     'confidence': 0.737}]},\n",
       "  {'id': 75,\n",
       "   'seek': 51432,\n",
       "   'start': np.float64(524.34),\n",
       "   'end': np.float64(530.8),\n",
       "   'text': ' calculate this confusion matrix and what this confusion matrix gives us is that we',\n",
       "   'tokens': [50872,\n",
       "    8873,\n",
       "    341,\n",
       "    15075,\n",
       "    8141,\n",
       "    293,\n",
       "    437,\n",
       "    341,\n",
       "    15075,\n",
       "    8141,\n",
       "    2709,\n",
       "    505,\n",
       "    307,\n",
       "    300,\n",
       "    321,\n",
       "    51184],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1563135545645187,\n",
       "   'compression_ratio': 1.8355263157894737,\n",
       "   'no_speech_prob': 0.01193438470363617,\n",
       "   'confidence': 0.845,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(524.34),\n",
       "     'end': np.float64(524.68),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'calculate',\n",
       "     'start': np.float64(524.68),\n",
       "     'end': np.float64(524.98),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(524.98),\n",
       "     'end': np.float64(525.34),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'confusion',\n",
       "     'start': np.float64(525.34),\n",
       "     'end': np.float64(525.78),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'matrix',\n",
       "     'start': np.float64(525.78),\n",
       "     'end': np.float64(526.2),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(526.2),\n",
       "     'end': np.float64(526.54),\n",
       "     'confidence': 0.484},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(526.54),\n",
       "     'end': np.float64(526.68),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'this',\n",
       "     'start': np.float64(526.68),\n",
       "     'end': np.float64(526.88),\n",
       "     'confidence': 0.547},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(526.88),\n",
       "     'end': np.float64(527.16),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'confusion',\n",
       "     'start': np.float64(527.16),\n",
       "     'end': np.float64(527.56),\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'matrix',\n",
       "     'start': np.float64(527.56),\n",
       "     'end': np.float64(528.02),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(528.02),\n",
       "     'end': np.float64(528.38),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'gives',\n",
       "     'start': np.float64(528.38),\n",
       "     'end': np.float64(528.74),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'us',\n",
       "     'start': np.float64(528.74),\n",
       "     'end': np.float64(529.02),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(529.02),\n",
       "     'end': np.float64(529.56),\n",
       "     'confidence': 0.921},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(529.56),\n",
       "     'end': np.float64(529.76),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(529.76),\n",
       "     'end': np.float64(530.8),\n",
       "     'confidence': 0.421}]},\n",
       "  {'id': 76,\n",
       "   'seek': 51432,\n",
       "   'start': np.float64(531.8),\n",
       "   'end': np.float64(538.3),\n",
       "   'text': ' what we do is that we calculate false positive, like false negatives, true positive, true negatives',\n",
       "   'tokens': [51240,\n",
       "    437,\n",
       "    321,\n",
       "    360,\n",
       "    307,\n",
       "    300,\n",
       "    321,\n",
       "    8873,\n",
       "    7908,\n",
       "    3353,\n",
       "    11,\n",
       "    411,\n",
       "    7908,\n",
       "    40019,\n",
       "    11,\n",
       "    2074,\n",
       "    3353,\n",
       "    11,\n",
       "    2074,\n",
       "    40019,\n",
       "    51580],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1563135545645187,\n",
       "   'compression_ratio': 1.8355263157894737,\n",
       "   'no_speech_prob': 0.01193438470363617,\n",
       "   'confidence': 0.887,\n",
       "   'words': [{'text': 'what',\n",
       "     'start': np.float64(531.8),\n",
       "     'end': np.float64(532.08),\n",
       "     'confidence': 0.961},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(532.08),\n",
       "     'end': np.float64(532.26),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'do',\n",
       "     'start': np.float64(532.26),\n",
       "     'end': np.float64(532.44),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'is',\n",
       "     'start': np.float64(532.44),\n",
       "     'end': np.float64(532.6),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(532.6),\n",
       "     'end': np.float64(532.76),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(532.76),\n",
       "     'end': np.float64(533.0),\n",
       "     'confidence': 0.994},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(533.0),\n",
       "     'end': np.float64(533.28),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'calculate',\n",
       "     'start': np.float64(533.28),\n",
       "     'end': np.float64(533.5),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'false',\n",
       "     'start': np.float64(533.5),\n",
       "     'end': np.float64(533.88),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'positive,',\n",
       "     'start': np.float64(533.88),\n",
       "     'end': np.float64(534.32),\n",
       "     'confidence': 0.5},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(534.82),\n",
       "     'end': np.float64(535.06),\n",
       "     'confidence': 0.668},\n",
       "    {'text': 'false',\n",
       "     'start': np.float64(535.06),\n",
       "     'end': np.float64(535.62),\n",
       "     'confidence': 0.965},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(535.62),\n",
       "     'end': np.float64(535.86),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'negatives,',\n",
       "     'start': np.float64(535.86),\n",
       "     'end': np.float64(536.12),\n",
       "     'confidence': 0.969},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(536.38),\n",
       "     'end': np.float64(537.14),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'true',\n",
       "     'start': np.float64(537.14),\n",
       "     'end': np.float64(537.24),\n",
       "     'confidence': 0.838},\n",
       "    {'text': 'positive,',\n",
       "     'start': np.float64(537.24),\n",
       "     'end': np.float64(537.62),\n",
       "     'confidence': 0.959},\n",
       "    {'text': 'true',\n",
       "     'start': np.float64(537.8),\n",
       "     'end': np.float64(537.94),\n",
       "     'confidence': 0.727},\n",
       "    {'text': 'negatives',\n",
       "     'start': np.float64(537.94),\n",
       "     'end': np.float64(538.3),\n",
       "     'confidence': 0.855}]},\n",
       "  {'id': 77,\n",
       "   'seek': 53864,\n",
       "   'start': np.float64(538.64),\n",
       "   'end': np.float64(546.84),\n",
       "   'text': ' and then we calculate recall, precision and F1 score. So recall, precision, these are very like',\n",
       "   'tokens': [50364,\n",
       "    293,\n",
       "    550,\n",
       "    321,\n",
       "    8873,\n",
       "    9901,\n",
       "    11,\n",
       "    18356,\n",
       "    293,\n",
       "    479,\n",
       "    16,\n",
       "    6175,\n",
       "    13,\n",
       "    407,\n",
       "    9901,\n",
       "    11,\n",
       "    18356,\n",
       "    11,\n",
       "    613,\n",
       "    366,\n",
       "    588,\n",
       "    411,\n",
       "    50788],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.150959683560777,\n",
       "   'compression_ratio': 1.8224299065420562,\n",
       "   'no_speech_prob': 0.02100338414311409,\n",
       "   'confidence': 0.891,\n",
       "   'words': [{'text': 'and',\n",
       "     'start': np.float64(538.64),\n",
       "     'end': np.float64(538.9),\n",
       "     'confidence': 0.983},\n",
       "    {'text': 'then',\n",
       "     'start': np.float64(538.9),\n",
       "     'end': np.float64(539.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'we',\n",
       "     'start': np.float64(539.38),\n",
       "     'end': np.float64(539.58),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'calculate',\n",
       "     'start': np.float64(539.58),\n",
       "     'end': np.float64(540.02),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'recall,',\n",
       "     'start': np.float64(540.02),\n",
       "     'end': np.float64(540.52),\n",
       "     'confidence': 0.98},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(540.52),\n",
       "     'end': np.float64(540.98),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'precision',\n",
       "     'start': np.float64(540.98),\n",
       "     'end': np.float64(541.36),\n",
       "     'confidence': 0.945},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(541.36),\n",
       "     'end': np.float64(541.44),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(541.44),\n",
       "     'end': np.float64(542.16),\n",
       "     'confidence': 0.764},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(542.16),\n",
       "     'end': np.float64(542.56),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'F1',\n",
       "     'start': np.float64(542.56),\n",
       "     'end': np.float64(543.08),\n",
       "     'confidence': 0.736},\n",
       "    {'text': 'score.',\n",
       "     'start': np.float64(543.08),\n",
       "     'end': np.float64(543.46),\n",
       "     'confidence': 0.98},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(543.46),\n",
       "     'end': np.float64(544.1),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(544.1),\n",
       "     'end': np.float64(544.24),\n",
       "     'confidence': 0.95},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(544.24),\n",
       "     'end': np.float64(544.82),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'recall,',\n",
       "     'start': np.float64(544.82),\n",
       "     'end': np.float64(545.02),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'precision,',\n",
       "     'start': np.float64(545.12),\n",
       "     'end': np.float64(545.44),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'these',\n",
       "     'start': np.float64(545.6),\n",
       "     'end': np.float64(545.82),\n",
       "     'confidence': 0.923},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(545.82),\n",
       "     'end': np.float64(546.06),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'very',\n",
       "     'start': np.float64(546.06),\n",
       "     'end': np.float64(546.48),\n",
       "     'confidence': 0.852},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(546.48),\n",
       "     'end': np.float64(546.84),\n",
       "     'confidence': 0.527}]},\n",
       "  {'id': 78,\n",
       "   'seek': 53864,\n",
       "   'start': np.float64(547.04),\n",
       "   'end': np.float64(553.92),\n",
       "   'text': ' important metrics, especially for the classification tasks and they actually tell you, precision tells',\n",
       "   'tokens': [50788,\n",
       "    1021,\n",
       "    16367,\n",
       "    11,\n",
       "    2318,\n",
       "    337,\n",
       "    264,\n",
       "    21538,\n",
       "    9608,\n",
       "    293,\n",
       "    436,\n",
       "    767,\n",
       "    980,\n",
       "    291,\n",
       "    11,\n",
       "    18356,\n",
       "    5112,\n",
       "    51140],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.150959683560777,\n",
       "   'compression_ratio': 1.8224299065420562,\n",
       "   'no_speech_prob': 0.02100338414311409,\n",
       "   'confidence': 0.875,\n",
       "   'words': [{'text': 'important',\n",
       "     'start': np.float64(547.04),\n",
       "     'end': np.float64(547.52),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'metrics,',\n",
       "     'start': np.float64(547.52),\n",
       "     'end': np.float64(548.0),\n",
       "     'confidence': 0.658},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(548.6),\n",
       "     'end': np.float64(548.98),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'especially',\n",
       "     'start': np.float64(548.98),\n",
       "     'end': np.float64(549.12),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(549.12),\n",
       "     'end': np.float64(549.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(549.38),\n",
       "     'end': np.float64(549.52),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'classification',\n",
       "     'start': np.float64(549.52),\n",
       "     'end': np.float64(549.98),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'tasks',\n",
       "     'start': np.float64(549.98),\n",
       "     'end': np.float64(550.52),\n",
       "     'confidence': 0.845},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(550.52),\n",
       "     'end': np.float64(550.8),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(550.8),\n",
       "     'end': np.float64(551.18),\n",
       "     'confidence': 0.515},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(551.18),\n",
       "     'end': np.float64(551.66),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'they',\n",
       "     'start': np.float64(551.66),\n",
       "     'end': np.float64(552.0),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(552.0),\n",
       "     'end': np.float64(552.74),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'tell',\n",
       "     'start': np.float64(552.74),\n",
       "     'end': np.float64(553.04),\n",
       "     'confidence': 0.947},\n",
       "    {'text': 'you,',\n",
       "     'start': np.float64(553.04),\n",
       "     'end': np.float64(553.26),\n",
       "     'confidence': 0.95},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(553.34),\n",
       "     'end': np.float64(553.62),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'precision',\n",
       "     'start': np.float64(553.62),\n",
       "     'end': np.float64(553.8),\n",
       "     'confidence': 0.757},\n",
       "    {'text': 'tells',\n",
       "     'start': np.float64(553.8),\n",
       "     'end': np.float64(553.92),\n",
       "     'confidence': 0.83}]},\n",
       "  {'id': 79,\n",
       "   'seek': 53864,\n",
       "   'start': np.float64(553.92),\n",
       "   'end': np.float64(560.66),\n",
       "   'text': ' you how much like how much correct answer it gives for the answer which were actually correct,',\n",
       "   'tokens': [51140,\n",
       "    291,\n",
       "    577,\n",
       "    709,\n",
       "    411,\n",
       "    577,\n",
       "    709,\n",
       "    3006,\n",
       "    1867,\n",
       "    309,\n",
       "    2709,\n",
       "    337,\n",
       "    264,\n",
       "    1867,\n",
       "    597,\n",
       "    645,\n",
       "    767,\n",
       "    3006,\n",
       "    11,\n",
       "    51484],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.150959683560777,\n",
       "   'compression_ratio': 1.8224299065420562,\n",
       "   'no_speech_prob': 0.02100338414311409,\n",
       "   'confidence': 0.897,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(553.92),\n",
       "     'end': np.float64(554.1),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(554.1),\n",
       "     'end': np.float64(554.44),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(554.44),\n",
       "     'end': np.float64(554.78),\n",
       "     'confidence': 0.979},\n",
       "    {'text': 'much',\n",
       "     'start': np.float64(554.78),\n",
       "     'end': np.float64(555.04),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(555.04),\n",
       "     'end': np.float64(555.9),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(555.9),\n",
       "     'end': np.float64(556.06),\n",
       "     'confidence': 0.564},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(556.06),\n",
       "     'end': np.float64(556.76),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(556.76),\n",
       "     'end': np.float64(557.1),\n",
       "     'confidence': 0.724},\n",
       "    {'text': 'much',\n",
       "     'start': np.float64(557.1),\n",
       "     'end': np.float64(557.4),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(557.4),\n",
       "     'end': np.float64(557.76),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'correct',\n",
       "     'start': np.float64(557.76),\n",
       "     'end': np.float64(558.1),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'answer',\n",
       "     'start': np.float64(558.1),\n",
       "     'end': np.float64(558.44),\n",
       "     'confidence': 0.973},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(558.44),\n",
       "     'end': np.float64(558.66),\n",
       "     'confidence': 0.711},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(558.66),\n",
       "     'end': np.float64(558.96),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'gives',\n",
       "     'start': np.float64(558.96),\n",
       "     'end': np.float64(559.16),\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(559.16),\n",
       "     'end': np.float64(559.42),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(559.42),\n",
       "     'end': np.float64(559.56),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'answer',\n",
       "     'start': np.float64(559.56),\n",
       "     'end': np.float64(559.84),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(559.84),\n",
       "     'end': np.float64(560.04),\n",
       "     'confidence': 0.853},\n",
       "    {'text': 'were',\n",
       "     'start': np.float64(560.04),\n",
       "     'end': np.float64(560.2),\n",
       "     'confidence': 0.712},\n",
       "    {'text': 'actually',\n",
       "     'start': np.float64(560.2),\n",
       "     'end': np.float64(560.46),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'correct,',\n",
       "     'start': np.float64(560.46),\n",
       "     'end': np.float64(560.66),\n",
       "     'confidence': 0.986}]},\n",
       "  {'id': 80,\n",
       "   'seek': 53864,\n",
       "   'start': np.float64(560.66),\n",
       "   'end': np.float64(566.5),\n",
       "   'text': ' correct, right? So these are some of the matrix that I would use and they are all like there are',\n",
       "   'tokens': [51484,\n",
       "    3006,\n",
       "    11,\n",
       "    558,\n",
       "    30,\n",
       "    407,\n",
       "    613,\n",
       "    366,\n",
       "    512,\n",
       "    295,\n",
       "    264,\n",
       "    8141,\n",
       "    300,\n",
       "    286,\n",
       "    576,\n",
       "    764,\n",
       "    293,\n",
       "    436,\n",
       "    366,\n",
       "    439,\n",
       "    411,\n",
       "    456,\n",
       "    366,\n",
       "    51756],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.150959683560777,\n",
       "   'compression_ratio': 1.8224299065420562,\n",
       "   'no_speech_prob': 0.02100338414311409,\n",
       "   'confidence': 0.829,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(560.66),\n",
       "     'end': np.float64(561.2),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'correct,',\n",
       "     'start': np.float64(561.2),\n",
       "     'end': np.float64(561.38),\n",
       "     'confidence': 0.97},\n",
       "    {'text': 'right?',\n",
       "     'start': np.float64(561.54),\n",
       "     'end': np.float64(561.7),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(561.96),\n",
       "     'end': np.float64(562.14),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'these',\n",
       "     'start': np.float64(562.14),\n",
       "     'end': np.float64(562.32),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(562.32),\n",
       "     'end': np.float64(562.5),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(562.5),\n",
       "     'end': np.float64(562.76),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(562.76),\n",
       "     'end': np.float64(562.9),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(562.9),\n",
       "     'end': np.float64(563.0),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'matrix',\n",
       "     'start': np.float64(563.0),\n",
       "     'end': np.float64(563.3),\n",
       "     'confidence': 0.465},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(563.3),\n",
       "     'end': np.float64(563.56),\n",
       "     'confidence': 0.985},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(563.56),\n",
       "     'end': np.float64(564.12),\n",
       "     'confidence': 0.542},\n",
       "    {'text': 'would',\n",
       "     'start': np.float64(564.12),\n",
       "     'end': np.float64(564.32),\n",
       "     'confidence': 0.948},\n",
       "    {'text': 'use',\n",
       "     'start': np.float64(564.32),\n",
       "     'end': np.float64(564.64),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(564.64),\n",
       "     'end': np.float64(564.88),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(564.88),\n",
       "     'end': np.float64(565.08),\n",
       "     'confidence': 0.731},\n",
       "    {'text': 'they',\n",
       "     'start': np.float64(565.08),\n",
       "     'end': np.float64(565.2),\n",
       "     'confidence': 0.519},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(565.2),\n",
       "     'end': np.float64(565.34),\n",
       "     'confidence': 0.902},\n",
       "    {'text': 'all',\n",
       "     'start': np.float64(565.34),\n",
       "     'end': np.float64(565.66),\n",
       "     'confidence': 0.944},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(565.66),\n",
       "     'end': np.float64(566.08),\n",
       "     'confidence': 0.628},\n",
       "    {'text': 'there',\n",
       "     'start': np.float64(566.08),\n",
       "     'end': np.float64(566.32),\n",
       "     'confidence': 0.626},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(566.32),\n",
       "     'end': np.float64(566.5),\n",
       "     'confidence': 0.826}]},\n",
       "  {'id': 81,\n",
       "   'seek': 56648,\n",
       "   'start': np.float64(566.58),\n",
       "   'end': np.float64(573.78),\n",
       "   'text': \" also multiple matrix, new matrix for multiple applications. You can actually, if I if I'm like\",\n",
       "   'tokens': [50364,\n",
       "    611,\n",
       "    3866,\n",
       "    8141,\n",
       "    11,\n",
       "    777,\n",
       "    8141,\n",
       "    337,\n",
       "    3866,\n",
       "    5821,\n",
       "    13,\n",
       "    509,\n",
       "    393,\n",
       "    767,\n",
       "    11,\n",
       "    498,\n",
       "    286,\n",
       "    498,\n",
       "    286,\n",
       "    478,\n",
       "    411,\n",
       "    50728],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1824159052834582,\n",
       "   'compression_ratio': 1.7065868263473054,\n",
       "   'no_speech_prob': 0.014040485955774784,\n",
       "   'confidence': 0.869,\n",
       "   'words': [{'text': 'also',\n",
       "     'start': np.float64(566.58),\n",
       "     'end': np.float64(566.82),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'multiple',\n",
       "     'start': np.float64(566.82),\n",
       "     'end': np.float64(567.2),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'matrix,',\n",
       "     'start': np.float64(567.2),\n",
       "     'end': np.float64(567.66),\n",
       "     'confidence': 0.832},\n",
       "    {'text': 'new',\n",
       "     'start': np.float64(568.06),\n",
       "     'end': np.float64(568.28),\n",
       "     'confidence': 0.609},\n",
       "    {'text': 'matrix',\n",
       "     'start': np.float64(568.28),\n",
       "     'end': np.float64(568.64),\n",
       "     'confidence': 0.954},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(568.64),\n",
       "     'end': np.float64(568.96),\n",
       "     'confidence': 0.967},\n",
       "    {'text': 'multiple',\n",
       "     'start': np.float64(568.96),\n",
       "     'end': np.float64(569.5),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(569.5),\n",
       "     'end': np.float64(569.88),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'applications.',\n",
       "     'start': np.float64(569.88),\n",
       "     'end': np.float64(570.5),\n",
       "     'confidence': 0.995},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(570.5),\n",
       "     'end': np.float64(571.4),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'You',\n",
       "     'start': np.float64(571.4),\n",
       "     'end': np.float64(571.48),\n",
       "     'confidence': 0.881},\n",
       "    {'text': 'can',\n",
       "     'start': np.float64(571.48),\n",
       "     'end': np.float64(571.64),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'actually,',\n",
       "     'start': np.float64(571.64),\n",
       "     'end': np.float64(571.96),\n",
       "     'confidence': 0.997},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(571.96),\n",
       "     'end': np.float64(572.64),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(572.64),\n",
       "     'end': np.float64(572.9),\n",
       "     'confidence': 0.921},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(572.9),\n",
       "     'end': np.float64(573.08),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'if',\n",
       "     'start': np.float64(573.08),\n",
       "     'end': np.float64(573.3),\n",
       "     'confidence': 0.477},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(573.3),\n",
       "     'end': np.float64(573.54),\n",
       "     'confidence': 0.802},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(573.54),\n",
       "     'end': np.float64(573.78),\n",
       "     'confidence': 0.815}]},\n",
       "  {'id': 82,\n",
       "   'seek': 56648,\n",
       "   'start': np.float64(574.72),\n",
       "   'end': np.float64(583.09),\n",
       "   'text': \" for certain applications, I can also like go through or custom like I'll try to create some\",\n",
       "   'tokens': [50780,\n",
       "    337,\n",
       "    1629,\n",
       "    5821,\n",
       "    11,\n",
       "    286,\n",
       "    393,\n",
       "    611,\n",
       "    411,\n",
       "    352,\n",
       "    807,\n",
       "    420,\n",
       "    2375,\n",
       "    411,\n",
       "    286,\n",
       "    603,\n",
       "    853,\n",
       "    281,\n",
       "    1884,\n",
       "    512,\n",
       "    51192],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1824159052834582,\n",
       "   'compression_ratio': 1.7065868263473054,\n",
       "   'no_speech_prob': 0.014040485955774784,\n",
       "   'confidence': 0.908,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(574.72),\n",
       "     'end': np.float64(575.06),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'for',\n",
       "     'start': np.float64(575.06),\n",
       "     'end': np.float64(575.2),\n",
       "     'confidence': 0.92},\n",
       "    {'text': 'certain',\n",
       "     'start': np.float64(575.2),\n",
       "     'end': np.float64(575.74),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'applications,',\n",
       "     'start': np.float64(575.74),\n",
       "     'end': np.float64(576.34),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'I',\n",
       "     'start': np.float64(576.78),\n",
       "     'end': np.float64(576.96),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'can',\n",
       "     'start': np.float64(576.96),\n",
       "     'end': np.float64(577.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'also',\n",
       "     'start': np.float64(577.1),\n",
       "     'end': np.float64(577.4),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(577.4),\n",
       "     'end': np.float64(577.82),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(577.82),\n",
       "     'end': np.float64(578.3),\n",
       "     'confidence': 0.774},\n",
       "    {'text': 'go',\n",
       "     'start': np.float64(578.3),\n",
       "     'end': np.float64(578.86),\n",
       "     'confidence': 0.968},\n",
       "    {'text': 'through',\n",
       "     'start': np.float64(578.86),\n",
       "     'end': np.float64(579.14),\n",
       "     'confidence': 0.998},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(579.14),\n",
       "     'end': np.float64(580.0),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(580.0),\n",
       "     'end': np.float64(580.22),\n",
       "     'confidence': 0.836},\n",
       "    {'text': 'custom',\n",
       "     'start': np.float64(580.22),\n",
       "     'end': np.float64(580.78),\n",
       "     'confidence': 0.846},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(580.78),\n",
       "     'end': np.float64(581.08),\n",
       "     'confidence': 0.613},\n",
       "    {'text': \"I'll\",\n",
       "     'start': np.float64(581.08),\n",
       "     'end': np.float64(581.98),\n",
       "     'confidence': 0.888},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(581.98),\n",
       "     'end': np.float64(582.16),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'try',\n",
       "     'start': np.float64(582.16),\n",
       "     'end': np.float64(582.5),\n",
       "     'confidence': 0.907},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(582.5),\n",
       "     'end': np.float64(582.68),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'create',\n",
       "     'start': np.float64(582.68),\n",
       "     'end': np.float64(582.92),\n",
       "     'confidence': 0.96},\n",
       "    {'text': 'some',\n",
       "     'start': np.float64(582.92),\n",
       "     'end': np.float64(583.09),\n",
       "     'confidence': 0.871}]},\n",
       "  {'id': 83,\n",
       "   'seek': 56648,\n",
       "   'start': np.float64(583.09),\n",
       "   'end': np.float64(592.2),\n",
       "   'text': \" custom matrix like matrix not like matrix on which I'll test the system. So it also highly depends\",\n",
       "   'tokens': [51192,\n",
       "    2375,\n",
       "    8141,\n",
       "    411,\n",
       "    8141,\n",
       "    406,\n",
       "    411,\n",
       "    8141,\n",
       "    322,\n",
       "    597,\n",
       "    286,\n",
       "    603,\n",
       "    1500,\n",
       "    264,\n",
       "    1185,\n",
       "    13,\n",
       "    407,\n",
       "    309,\n",
       "    611,\n",
       "    5405,\n",
       "    5946,\n",
       "    51656],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1824159052834582,\n",
       "   'compression_ratio': 1.7065868263473054,\n",
       "   'no_speech_prob': 0.014040485955774784,\n",
       "   'confidence': 0.866,\n",
       "   'words': [{'text': '[*]',\n",
       "     'start': np.float64(583.09),\n",
       "     'end': np.float64(583.2),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'custom',\n",
       "     'start': np.float64(583.2),\n",
       "     'end': np.float64(583.54),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'matrix',\n",
       "     'start': np.float64(583.54),\n",
       "     'end': np.float64(583.98),\n",
       "     'confidence': 0.963},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(583.98),\n",
       "     'end': np.float64(584.46),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(584.46),\n",
       "     'end': np.float64(584.96),\n",
       "     'confidence': 0.539},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(584.96),\n",
       "     'end': np.float64(585.4),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'matrix',\n",
       "     'start': np.float64(585.4),\n",
       "     'end': np.float64(585.76),\n",
       "     'confidence': 0.634},\n",
       "    {'text': 'not',\n",
       "     'start': np.float64(585.76),\n",
       "     'end': np.float64(586.08),\n",
       "     'confidence': 0.622},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(586.08),\n",
       "     'end': np.float64(586.36),\n",
       "     'confidence': 0.982},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(586.36),\n",
       "     'end': np.float64(587.22),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'matrix',\n",
       "     'start': np.float64(587.22),\n",
       "     'end': np.float64(587.38),\n",
       "     'confidence': 0.735},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(587.38),\n",
       "     'end': np.float64(587.88),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(587.88),\n",
       "     'end': np.float64(588.4),\n",
       "     'confidence': 0.962},\n",
       "    {'text': 'which',\n",
       "     'start': np.float64(588.4),\n",
       "     'end': np.float64(588.62),\n",
       "     'confidence': 0.995},\n",
       "    {'text': \"I'll\",\n",
       "     'start': np.float64(588.62),\n",
       "     'end': np.float64(588.84),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'test',\n",
       "     'start': np.float64(588.84),\n",
       "     'end': np.float64(589.12),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(589.12),\n",
       "     'end': np.float64(589.62),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'system.',\n",
       "     'start': np.float64(589.62),\n",
       "     'end': np.float64(590.18),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(590.4),\n",
       "     'end': np.float64(590.78),\n",
       "     'confidence': 0.678},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(590.78),\n",
       "     'end': np.float64(591.12),\n",
       "     'confidence': 0.98},\n",
       "    {'text': 'also',\n",
       "     'start': np.float64(591.12),\n",
       "     'end': np.float64(591.52),\n",
       "     'confidence': 0.906},\n",
       "    {'text': 'highly',\n",
       "     'start': np.float64(591.52),\n",
       "     'end': np.float64(591.8),\n",
       "     'confidence': 0.956},\n",
       "    {'text': 'depends',\n",
       "     'start': np.float64(591.8),\n",
       "     'end': np.float64(592.2),\n",
       "     'confidence': 0.822}]},\n",
       "  {'id': 84,\n",
       "   'seek': 59232,\n",
       "   'start': np.float64(592.5),\n",
       "   'end': np.float64(597.2),\n",
       "   'text': \" on what type of application I'm working with here and what type of model I'm working with here.\",\n",
       "   'tokens': [50368,\n",
       "    322,\n",
       "    437,\n",
       "    2010,\n",
       "    295,\n",
       "    3861,\n",
       "    286,\n",
       "    478,\n",
       "    1364,\n",
       "    365,\n",
       "    510,\n",
       "    293,\n",
       "    437,\n",
       "    2010,\n",
       "    295,\n",
       "    2316,\n",
       "    286,\n",
       "    478,\n",
       "    1364,\n",
       "    365,\n",
       "    510,\n",
       "    13,\n",
       "    50608],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10487721948062673,\n",
       "   'compression_ratio': 1.7751937984496124,\n",
       "   'no_speech_prob': 0.006727556232362986,\n",
       "   'confidence': 0.956,\n",
       "   'words': [{'text': 'on',\n",
       "     'start': np.float64(592.5),\n",
       "     'end': np.float64(592.62),\n",
       "     'confidence': 0.99},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(592.62),\n",
       "     'end': np.float64(592.82),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(592.82),\n",
       "     'end': np.float64(593.06),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(593.06),\n",
       "     'end': np.float64(593.24),\n",
       "     'confidence': 0.999},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(593.24),\n",
       "     'end': np.float64(593.4),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'application',\n",
       "     'start': np.float64(593.4),\n",
       "     'end': np.float64(593.56),\n",
       "     'confidence': 0.826},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(593.56),\n",
       "     'end': np.float64(593.98),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'working',\n",
       "     'start': np.float64(593.98),\n",
       "     'end': np.float64(594.22),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'with',\n",
       "     'start': np.float64(594.22),\n",
       "     'end': np.float64(594.48),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'here',\n",
       "     'start': np.float64(594.48),\n",
       "     'end': np.float64(594.72),\n",
       "     'confidence': 0.725},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(594.72),\n",
       "     'end': np.float64(595.32),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(595.32),\n",
       "     'end': np.float64(595.44),\n",
       "     'confidence': 0.925},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(595.44),\n",
       "     'end': np.float64(595.64),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(595.64),\n",
       "     'end': np.float64(595.86),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(595.86),\n",
       "     'end': np.float64(596.06),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'model',\n",
       "     'start': np.float64(596.06),\n",
       "     'end': np.float64(596.28),\n",
       "     'confidence': 0.998},\n",
       "    {'text': \"I'm\",\n",
       "     'start': np.float64(596.28),\n",
       "     'end': np.float64(596.52),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'working',\n",
       "     'start': np.float64(596.52),\n",
       "     'end': np.float64(596.76),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'with',\n",
       "     'start': np.float64(596.76),\n",
       "     'end': np.float64(596.98),\n",
       "     'confidence': 0.991},\n",
       "    {'text': 'here.',\n",
       "     'start': np.float64(596.98),\n",
       "     'end': np.float64(597.2),\n",
       "     'confidence': 0.813}]},\n",
       "  {'id': 85,\n",
       "   'seek': 59232,\n",
       "   'start': np.float64(603.86),\n",
       "   'end': np.float64(608.6),\n",
       "   'text': \" Absolutely and that's a fantastic breakdown. You're spot on that the choice of evaluation\",\n",
       "   'tokens': [50936,\n",
       "    7021,\n",
       "    293,\n",
       "    300,\n",
       "    311,\n",
       "    257,\n",
       "    5456,\n",
       "    18188,\n",
       "    13,\n",
       "    509,\n",
       "    434,\n",
       "    4008,\n",
       "    322,\n",
       "    300,\n",
       "    264,\n",
       "    3922,\n",
       "    295,\n",
       "    13344,\n",
       "    51184],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10487721948062673,\n",
       "   'compression_ratio': 1.7751937984496124,\n",
       "   'no_speech_prob': 0.006727556232362986,\n",
       "   'confidence': 0.904,\n",
       "   'words': [{'text': 'Absolutely',\n",
       "     'start': np.float64(603.86),\n",
       "     'end': np.float64(604.24),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(604.24),\n",
       "     'end': np.float64(604.62),\n",
       "     'confidence': 0.554},\n",
       "    {'text': \"that's\",\n",
       "     'start': np.float64(604.62),\n",
       "     'end': np.float64(604.88),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(604.88),\n",
       "     'end': np.float64(604.98),\n",
       "     'confidence': 0.992},\n",
       "    {'text': 'fantastic',\n",
       "     'start': np.float64(604.98),\n",
       "     'end': np.float64(605.42),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'breakdown.',\n",
       "     'start': np.float64(605.42),\n",
       "     'end': np.float64(605.94),\n",
       "     'confidence': 0.958},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(606.32),\n",
       "     'end': np.float64(606.4),\n",
       "     'confidence': 0.0},\n",
       "    {'text': \"You're\",\n",
       "     'start': np.float64(606.4),\n",
       "     'end': np.float64(606.76),\n",
       "     'confidence': 0.731},\n",
       "    {'text': 'spot',\n",
       "     'start': np.float64(606.76),\n",
       "     'end': np.float64(607.04),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(607.04),\n",
       "     'end': np.float64(607.34),\n",
       "     'confidence': 0.872},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(607.34),\n",
       "     'end': np.float64(607.56),\n",
       "     'confidence': 0.965},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(607.56),\n",
       "     'end': np.float64(607.7),\n",
       "     'confidence': 0.953},\n",
       "    {'text': 'choice',\n",
       "     'start': np.float64(607.7),\n",
       "     'end': np.float64(607.94),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(607.94),\n",
       "     'end': np.float64(608.16),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'evaluation',\n",
       "     'start': np.float64(608.16),\n",
       "     'end': np.float64(608.6),\n",
       "     'confidence': 0.937}]},\n",
       "  {'id': 86,\n",
       "   'seek': 59232,\n",
       "   'start': np.float64(608.66),\n",
       "   'end': np.float64(612.64),\n",
       "   'text': \" metrics really depends on the type of problem you're tackling, whether it's regression,\",\n",
       "   'tokens': [51184,\n",
       "    16367,\n",
       "    534,\n",
       "    5946,\n",
       "    322,\n",
       "    264,\n",
       "    2010,\n",
       "    295,\n",
       "    1154,\n",
       "    291,\n",
       "    434,\n",
       "    34415,\n",
       "    11,\n",
       "    1968,\n",
       "    309,\n",
       "    311,\n",
       "    24590,\n",
       "    11,\n",
       "    51388],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10487721948062673,\n",
       "   'compression_ratio': 1.7751937984496124,\n",
       "   'no_speech_prob': 0.006727556232362986,\n",
       "   'confidence': 0.986,\n",
       "   'words': [{'text': 'metrics',\n",
       "     'start': np.float64(608.66),\n",
       "     'end': np.float64(609.14),\n",
       "     'confidence': 0.848},\n",
       "    {'text': 'really',\n",
       "     'start': np.float64(609.14),\n",
       "     'end': np.float64(609.46),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'depends',\n",
       "     'start': np.float64(609.46),\n",
       "     'end': np.float64(609.68),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(609.68),\n",
       "     'end': np.float64(609.94),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(609.94),\n",
       "     'end': np.float64(610.06),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'type',\n",
       "     'start': np.float64(610.06),\n",
       "     'end': np.float64(610.22),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'of',\n",
       "     'start': np.float64(610.22),\n",
       "     'end': np.float64(610.36),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'problem',\n",
       "     'start': np.float64(610.36),\n",
       "     'end': np.float64(610.6),\n",
       "     'confidence': 1.0},\n",
       "    {'text': \"you're\",\n",
       "     'start': np.float64(610.6),\n",
       "     'end': np.float64(610.82),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'tackling,',\n",
       "     'start': np.float64(610.82),\n",
       "     'end': np.float64(611.14),\n",
       "     'confidence': 1.0},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(611.4),\n",
       "     'end': np.float64(611.62),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'whether',\n",
       "     'start': np.float64(611.62),\n",
       "     'end': np.float64(611.9),\n",
       "     'confidence': 0.985},\n",
       "    {'text': \"it's\",\n",
       "     'start': np.float64(611.9),\n",
       "     'end': np.float64(612.2),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'regression,',\n",
       "     'start': np.float64(612.2),\n",
       "     'end': np.float64(612.64),\n",
       "     'confidence': 0.996}]},\n",
       "  {'id': 87,\n",
       "   'seek': 59232,\n",
       "   'start': np.float64(613.36),\n",
       "   'end': np.float64(616.9),\n",
       "   'text': \" classification or something else. And it's great that you brought up things like the confusion\",\n",
       "   'tokens': [51388,\n",
       "    21538,\n",
       "    420,\n",
       "    746,\n",
       "    1646,\n",
       "    13,\n",
       "    400,\n",
       "    309,\n",
       "    311,\n",
       "    869,\n",
       "    300,\n",
       "    291,\n",
       "    3038,\n",
       "    493,\n",
       "    721,\n",
       "    411,\n",
       "    264,\n",
       "    15075,\n",
       "    51596],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10487721948062673,\n",
       "   'compression_ratio': 1.7751937984496124,\n",
       "   'no_speech_prob': 0.006727556232362986,\n",
       "   'confidence': 0.956,\n",
       "   'words': [{'text': 'classification',\n",
       "     'start': np.float64(613.36),\n",
       "     'end': np.float64(613.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(613.38),\n",
       "     'end': np.float64(613.94),\n",
       "     'confidence': 0.887},\n",
       "    {'text': 'something',\n",
       "     'start': np.float64(613.94),\n",
       "     'end': np.float64(614.18),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'else.',\n",
       "     'start': np.float64(614.18),\n",
       "     'end': np.float64(614.52),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(615.1),\n",
       "     'end': np.float64(615.18),\n",
       "     'confidence': 0.976},\n",
       "    {'text': \"it's\",\n",
       "     'start': np.float64(615.18),\n",
       "     'end': np.float64(615.34),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'great',\n",
       "     'start': np.float64(615.34),\n",
       "     'end': np.float64(615.48),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'that',\n",
       "     'start': np.float64(615.48),\n",
       "     'end': np.float64(615.6),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(615.6),\n",
       "     'end': np.float64(615.7),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'brought',\n",
       "     'start': np.float64(615.7),\n",
       "     'end': np.float64(615.84),\n",
       "     'confidence': 0.986},\n",
       "    {'text': 'up',\n",
       "     'start': np.float64(615.84),\n",
       "     'end': np.float64(615.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'things',\n",
       "     'start': np.float64(615.98),\n",
       "     'end': np.float64(616.18),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(616.18),\n",
       "     'end': np.float64(616.44),\n",
       "     'confidence': 0.982},\n",
       "    {'text': 'the',\n",
       "     'start': np.float64(616.44),\n",
       "     'end': np.float64(616.62),\n",
       "     'confidence': 0.955},\n",
       "    {'text': 'confusion',\n",
       "     'start': np.float64(616.62),\n",
       "     'end': np.float64(616.9),\n",
       "     'confidence': 0.621}]},\n",
       "  {'id': 88,\n",
       "   'seek': 59232,\n",
       "   'start': np.float64(617.04),\n",
       "   'end': np.float64(621.56),\n",
       "   'text': ' matrix, precision, recall, those are super critical in classification. And like you said,',\n",
       "   'tokens': [51596,\n",
       "    8141,\n",
       "    11,\n",
       "    18356,\n",
       "    11,\n",
       "    9901,\n",
       "    11,\n",
       "    729,\n",
       "    366,\n",
       "    1687,\n",
       "    4924,\n",
       "    294,\n",
       "    21538,\n",
       "    13,\n",
       "    400,\n",
       "    411,\n",
       "    291,\n",
       "    848,\n",
       "    11,\n",
       "    51828],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10487721948062673,\n",
       "   'compression_ratio': 1.7751937984496124,\n",
       "   'no_speech_prob': 0.006727556232362986,\n",
       "   'confidence': 0.946,\n",
       "   'words': [{'text': 'matrix,',\n",
       "     'start': np.float64(617.04),\n",
       "     'end': np.float64(617.3),\n",
       "     'confidence': 0.658},\n",
       "    {'text': 'precision,',\n",
       "     'start': np.float64(617.56),\n",
       "     'end': np.float64(617.88),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'recall,',\n",
       "     'start': np.float64(618.1),\n",
       "     'end': np.float64(618.44),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'those',\n",
       "     'start': np.float64(618.62),\n",
       "     'end': np.float64(618.8),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'are',\n",
       "     'start': np.float64(618.8),\n",
       "     'end': np.float64(618.98),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'super',\n",
       "     'start': np.float64(618.98),\n",
       "     'end': np.float64(619.24),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'critical',\n",
       "     'start': np.float64(619.24),\n",
       "     'end': np.float64(619.6),\n",
       "     'confidence': 0.959},\n",
       "    {'text': 'in',\n",
       "     'start': np.float64(619.6),\n",
       "     'end': np.float64(619.8),\n",
       "     'confidence': 0.852},\n",
       "    {'text': 'classification.',\n",
       "     'start': np.float64(619.8),\n",
       "     'end': np.float64(620.36),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'And',\n",
       "     'start': np.float64(620.9),\n",
       "     'end': np.float64(621.14),\n",
       "     'confidence': 0.988},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(621.14),\n",
       "     'end': np.float64(621.26),\n",
       "     'confidence': 0.993},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(621.26),\n",
       "     'end': np.float64(621.4),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'said,',\n",
       "     'start': np.float64(621.4),\n",
       "     'end': np.float64(621.56),\n",
       "     'confidence': 0.951}]},\n",
       "  {'id': 89,\n",
       "   'seek': 62160,\n",
       "   'start': np.float64(621.6),\n",
       "   'end': np.float64(626.11),\n",
       "   'text': ' for regression, you might go with something like RMSE or MAE, but it all depends on what',\n",
       "   'tokens': [50364,\n",
       "    337,\n",
       "    24590,\n",
       "    11,\n",
       "    291,\n",
       "    1062,\n",
       "    352,\n",
       "    365,\n",
       "    746,\n",
       "    411,\n",
       "    23790,\n",
       "    5879,\n",
       "    420,\n",
       "    12191,\n",
       "    36,\n",
       "    11,\n",
       "    457,\n",
       "    309,\n",
       "    439,\n",
       "    5946,\n",
       "    322,\n",
       "    437,\n",
       "    50588],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11622653440995649,\n",
       "   'compression_ratio': 1.356687898089172,\n",
       "   'no_speech_prob': 0.0021377026569098234,\n",
       "   'confidence': 0.955,\n",
       "   'words': [{'text': 'for',\n",
       "     'start': np.float64(621.6),\n",
       "     'end': np.float64(621.82),\n",
       "     'confidence': 0.989},\n",
       "    {'text': 'regression,',\n",
       "     'start': np.float64(621.82),\n",
       "     'end': np.float64(622.2),\n",
       "     'confidence': 0.902},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(622.34),\n",
       "     'end': np.float64(622.46),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'might',\n",
       "     'start': np.float64(622.46),\n",
       "     'end': np.float64(622.6),\n",
       "     'confidence': 0.997},\n",
       "    {'text': 'go',\n",
       "     'start': np.float64(622.6),\n",
       "     'end': np.float64(622.78),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'with',\n",
       "     'start': np.float64(622.78),\n",
       "     'end': np.float64(622.92),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'something',\n",
       "     'start': np.float64(622.92),\n",
       "     'end': np.float64(623.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(623.1),\n",
       "     'end': np.float64(623.38),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'RMSE',\n",
       "     'start': np.float64(623.38),\n",
       "     'end': np.float64(623.94),\n",
       "     'confidence': 0.898},\n",
       "    {'text': 'or',\n",
       "     'start': np.float64(623.94),\n",
       "     'end': np.float64(624.22),\n",
       "     'confidence': 0.987},\n",
       "    {'text': 'MAE,',\n",
       "     'start': np.float64(624.22),\n",
       "     'end': np.float64(624.7),\n",
       "     'confidence': 0.803},\n",
       "    {'text': 'but',\n",
       "     'start': np.float64(624.8),\n",
       "     'end': np.float64(624.94),\n",
       "     'confidence': 0.994},\n",
       "    {'text': 'it',\n",
       "     'start': np.float64(624.94),\n",
       "     'end': np.float64(625.08),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'all',\n",
       "     'start': np.float64(625.08),\n",
       "     'end': np.float64(625.22),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'depends',\n",
       "     'start': np.float64(625.22),\n",
       "     'end': np.float64(625.5),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'on',\n",
       "     'start': np.float64(625.5),\n",
       "     'end': np.float64(625.84),\n",
       "     'confidence': 0.996},\n",
       "    {'text': 'what',\n",
       "     'start': np.float64(625.84),\n",
       "     'end': np.float64(626.11),\n",
       "     'confidence': 0.929}]},\n",
       "  {'id': 90,\n",
       "   'seek': 62160,\n",
       "   'start': np.float64(626.11),\n",
       "   'end': np.float64(630.5),\n",
       "   'text': \" you're trying to measure and how you want to balance things like bias and variance. So yeah,\",\n",
       "   'tokens': [50588,\n",
       "    291,\n",
       "    434,\n",
       "    1382,\n",
       "    281,\n",
       "    3481,\n",
       "    293,\n",
       "    577,\n",
       "    291,\n",
       "    528,\n",
       "    281,\n",
       "    4772,\n",
       "    721,\n",
       "    411,\n",
       "    12577,\n",
       "    293,\n",
       "    21977,\n",
       "    13,\n",
       "    407,\n",
       "    1338,\n",
       "    11,\n",
       "    50816],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11622653440995649,\n",
       "   'compression_ratio': 1.356687898089172,\n",
       "   'no_speech_prob': 0.0021377026569098234,\n",
       "   'confidence': 0.944,\n",
       "   'words': [{'text': \"you're\",\n",
       "     'start': np.float64(626.11),\n",
       "     'end': np.float64(626.34),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'trying',\n",
       "     'start': np.float64(626.34),\n",
       "     'end': np.float64(626.42),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(626.42),\n",
       "     'end': np.float64(626.52),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'measure',\n",
       "     'start': np.float64(626.52),\n",
       "     'end': np.float64(626.78),\n",
       "     'confidence': 1.0},\n",
       "    {'text': '[*]',\n",
       "     'start': np.float64(626.78),\n",
       "     'end': np.float64(627.12),\n",
       "     'confidence': 0.0},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(627.12),\n",
       "     'end': np.float64(627.34),\n",
       "     'confidence': 0.924},\n",
       "    {'text': 'how',\n",
       "     'start': np.float64(627.34),\n",
       "     'end': np.float64(627.5),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'you',\n",
       "     'start': np.float64(627.5),\n",
       "     'end': np.float64(627.64),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'want',\n",
       "     'start': np.float64(627.64),\n",
       "     'end': np.float64(627.78),\n",
       "     'confidence': 0.976},\n",
       "    {'text': 'to',\n",
       "     'start': np.float64(627.78),\n",
       "     'end': np.float64(627.88),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'balance',\n",
       "     'start': np.float64(627.88),\n",
       "     'end': np.float64(628.1),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'things',\n",
       "     'start': np.float64(628.1),\n",
       "     'end': np.float64(628.32),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'like',\n",
       "     'start': np.float64(628.32),\n",
       "     'end': np.float64(628.54),\n",
       "     'confidence': 0.995},\n",
       "    {'text': 'bias',\n",
       "     'start': np.float64(628.54),\n",
       "     'end': np.float64(628.78),\n",
       "     'confidence': 0.998},\n",
       "    {'text': 'and',\n",
       "     'start': np.float64(628.78),\n",
       "     'end': np.float64(628.98),\n",
       "     'confidence': 0.962},\n",
       "    {'text': 'variance.',\n",
       "     'start': np.float64(628.98),\n",
       "     'end': np.float64(629.3),\n",
       "     'confidence': 0.966},\n",
       "    {'text': 'So',\n",
       "     'start': np.float64(629.68),\n",
       "     'end': np.float64(630.18),\n",
       "     'confidence': 0.636},\n",
       "    {'text': 'yeah,',\n",
       "     'start': np.float64(630.18),\n",
       "     'end': np.float64(630.5),\n",
       "     'confidence': 0.67}]},\n",
       "  {'id': 91,\n",
       "   'seek': 62160,\n",
       "   'start': np.float64(630.5),\n",
       "   'end': np.float64(631.72),\n",
       "   'text': \" that's a really solid approach.\",\n",
       "   'tokens': [50816, 300, 311, 257, 534, 5100, 3109, 13, 50868],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.11622653440995649,\n",
       "   'compression_ratio': 1.356687898089172,\n",
       "   'no_speech_prob': 0.0021377026569098234,\n",
       "   'confidence': 0.994,\n",
       "   'words': [{'text': \"that's\",\n",
       "     'start': np.float64(630.5),\n",
       "     'end': np.float64(630.94),\n",
       "     'confidence': 0.984},\n",
       "    {'text': 'a',\n",
       "     'start': np.float64(630.94),\n",
       "     'end': np.float64(631.02),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'really',\n",
       "     'start': np.float64(631.02),\n",
       "     'end': np.float64(631.16),\n",
       "     'confidence': 1.0},\n",
       "    {'text': 'solid',\n",
       "     'start': np.float64(631.16),\n",
       "     'end': np.float64(631.4),\n",
       "     'confidence': 0.999},\n",
       "    {'text': 'approach.',\n",
       "     'start': np.float64(631.4),\n",
       "     'end': np.float64(631.72),\n",
       "     'confidence': 0.999}]}],\n",
       " 'language': 'en',\n",
       " 'language_probs': {'en': 0.9952878952026367,\n",
       "  'zh': 0.00039766242844052613,\n",
       "  'de': 1.70353250723565e-05,\n",
       "  'es': 0.00015895495016593486,\n",
       "  'ru': 7.513076707255095e-05,\n",
       "  'ko': 0.0001691869692876935,\n",
       "  'fr': 4.550336961983703e-05,\n",
       "  'ja': 0.0003405255847610533,\n",
       "  'pt': 4.10266948165372e-05,\n",
       "  'tr': 1.3717371075472329e-05,\n",
       "  'pl': 8.826156658869877e-07,\n",
       "  'ca': 1.6467054138047388e-06,\n",
       "  'nl': 9.666343430581037e-06,\n",
       "  'ar': 0.0001381406473228708,\n",
       "  'sv': 1.8829852024282445e-06,\n",
       "  'it': 8.749152584641706e-06,\n",
       "  'id': 0.00013671837223228067,\n",
       "  'hi': 0.0013449513353407383,\n",
       "  'fi': 1.2162783605162986e-05,\n",
       "  'vi': 1.3062794096185826e-05,\n",
       "  'he': 9.993423191190232e-07,\n",
       "  'uk': 2.651360773597844e-06,\n",
       "  'el': 6.490803116321331e-06,\n",
       "  'ms': 0.00011624291801126674,\n",
       "  'cs': 1.2054254057147773e-06,\n",
       "  'ro': 4.727869054477196e-06,\n",
       "  'da': 7.580716214761196e-07,\n",
       "  'hu': 1.7876233187053003e-06,\n",
       "  'ta': 0.00013547600246965885,\n",
       "  'no': 1.4011773146194173e-06,\n",
       "  'th': 3.250202280469239e-05,\n",
       "  'ur': 0.00011868016008520499,\n",
       "  'hr': 6.991249534848976e-08,\n",
       "  'bg': 6.17513933320879e-07,\n",
       "  'lt': 1.0922952498049199e-07,\n",
       "  'la': 0.0002017324004555121,\n",
       "  'mi': 9.15189320949139e-06,\n",
       "  'ml': 0.00018371308397036046,\n",
       "  'cy': 0.00036873426870442927,\n",
       "  'sk': 1.6358465870780492e-07,\n",
       "  'te': 0.00016030098777264357,\n",
       "  'fa': 3.5345053674973315e-06,\n",
       "  'lv': 8.204837342873361e-08,\n",
       "  'bn': 2.2138723579701036e-05,\n",
       "  'sr': 1.136792349143434e-07,\n",
       "  'az': 7.369738597162723e-08,\n",
       "  'sl': 1.2269586022739531e-06,\n",
       "  'kn': 3.836878022411838e-06,\n",
       "  'et': 1.8315999739115796e-07,\n",
       "  'mk': 2.563014511736128e-08,\n",
       "  'br': 3.5033426684094593e-06,\n",
       "  'eu': 1.8949531011003273e-07,\n",
       "  'is': 2.7962624926658464e-07,\n",
       "  'hy': 1.184635465278916e-07,\n",
       "  'ne': 3.957691660616547e-06,\n",
       "  'mn': 9.344532259092375e-07,\n",
       "  'bs': 6.843013977686496e-08,\n",
       "  'kk': 3.761531885970726e-08,\n",
       "  'sq': 6.03556458145249e-08,\n",
       "  'sw': 5.950589638814563e-06,\n",
       "  'gl': 9.88434521786985e-07,\n",
       "  'mr': 1.0985581866407301e-05,\n",
       "  'pa': 3.4710440104390727e-06,\n",
       "  'si': 9.380180017615203e-06,\n",
       "  'km': 2.110997593263164e-05,\n",
       "  'sn': 7.442409241775749e-06,\n",
       "  'yo': 3.0336054805957247e-06,\n",
       "  'so': 1.3499157347496293e-08,\n",
       "  'af': 7.830115578144614e-07,\n",
       "  'oc': 5.920768586520353e-08,\n",
       "  'ka': 4.226186067768367e-09,\n",
       "  'be': 2.787834887385543e-07,\n",
       "  'tg': 7.88012988195419e-10,\n",
       "  'sd': 1.3797961173622753e-06,\n",
       "  'gu': 2.084271670810267e-07,\n",
       "  'am': 1.5761568050720598e-08,\n",
       "  'yi': 1.6697755711447826e-07,\n",
       "  'lo': 2.2151182577090367e-07,\n",
       "  'uz': 3.234916154393197e-11,\n",
       "  'fo': 6.574840227813183e-08,\n",
       "  'ht': 7.784845479363867e-07,\n",
       "  'ps': 5.264145670480502e-07,\n",
       "  'tk': 1.197987542500556e-10,\n",
       "  'nn': 7.290860230568796e-05,\n",
       "  'mt': 5.17758920182132e-08,\n",
       "  'sa': 3.0370343665708788e-05,\n",
       "  'lb': 7.470008639431924e-11,\n",
       "  'my': 7.991544066499046e-07,\n",
       "  'bo': 4.840582278120564e-06,\n",
       "  'tl': 0.00010764644684968516,\n",
       "  'mg': 2.0715786724911922e-11,\n",
       "  'as': 1.0859557733056135e-06,\n",
       "  'tt': 2.3716920094507543e-10,\n",
       "  'haw': 8.1112259067595e-05,\n",
       "  'ln': 5.781394474269064e-09,\n",
       "  'ha': 6.445685096778675e-10,\n",
       "  'ba': 9.438725495636291e-11,\n",
       "  'jw': 3.171195930917747e-05,\n",
       "  'su': 4.586796775729596e-10}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e97a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wbyw = pd.DataFrame(result['segments'][0]['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a2c88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We're</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starting</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>now.</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[*]</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text  start   end  confidence\n",
       "0     We're   0.00  0.32       0.483\n",
       "1  starting   0.32  0.62       0.997\n",
       "2      now.   0.62  0.94       0.993\n",
       "3       [*]   0.94  1.72       0.000\n",
       "4        So   1.72  1.76       0.708"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbyw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5f4a812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wbyw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e749ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['segments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218264ef",
   "metadata": {},
   "source": [
    "#### Let's create this wordbyword dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "306a9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for sen in result['segments']:\n",
    "    df = pd.DataFrame(sen['words'])\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd57721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbyw = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c924da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We're</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starting</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>now.</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[*]</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text  start   end  confidence\n",
       "0     We're   0.00  0.32       0.483\n",
       "1  starting   0.32  0.62       0.997\n",
       "2      now.   0.62  0.94       0.993\n",
       "3       [*]   0.94  1.72       0.000\n",
       "4        So   1.72  1.76       0.708"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbyw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda9202a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1873"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wbyw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b041cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbyw.drop(columns=['confidence'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72adf1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We're</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starting</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>now.</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[*]</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text  start   end\n",
       "0     We're   0.00  0.32\n",
       "1  starting   0.32  0.62\n",
       "2      now.   0.62  0.94\n",
       "3       [*]   0.94  1.72\n",
       "4        So   1.72  1.76"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbyw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a774f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ad2366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = project_root / 'data' / 'processed' / 'whisper_data' / 'wbyw.csv'\n",
    "wbyw.to_csv(str(path), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1102e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = pd.DataFrame(result[\"segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd115b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seek</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>temperature</th>\n",
       "      <th>avg_logprob</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>no_speech_prob</th>\n",
       "      <th>confidence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.69</td>\n",
       "      <td>We're starting now. So welcome to the intervi...</td>\n",
       "      <td>[50364, 492, 434, 2891, 586, 13, 407, 2928, 28...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.149370</td>\n",
       "      <td>1.573222</td>\n",
       "      <td>0.105431</td>\n",
       "      <td>0.837</td>\n",
       "      <td>[{'text': 'We're', 'start': 0.0, 'end': 0.32, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>9.36</td>\n",
       "      <td>me a little bit about your background and wha...</td>\n",
       "      <td>[50648, 385, 257, 707, 857, 466, 428, 3678, 29...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.149370</td>\n",
       "      <td>1.573222</td>\n",
       "      <td>0.105431</td>\n",
       "      <td>0.973</td>\n",
       "      <td>[{'text': 'me', 'start': 5.69, 'end': 5.86, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.18</td>\n",
       "      <td>18.06</td>\n",
       "      <td>Yeah, so right now I'm in third year of my co...</td>\n",
       "      <td>[50916, 865, 11, 370, 558, 586, 286, 478, 294,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.149370</td>\n",
       "      <td>1.573222</td>\n",
       "      <td>0.105431</td>\n",
       "      <td>0.887</td>\n",
       "      <td>[{'text': 'Yeah,', 'start': 11.18, 'end': 11.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.76</td>\n",
       "      <td>25.44</td>\n",
       "      <td>but yeah, from the start of my college, I thi...</td>\n",
       "      <td>[51304, 457, 1338, 11, 490, 264, 722, 295, 452...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.149370</td>\n",
       "      <td>1.573222</td>\n",
       "      <td>0.105431</td>\n",
       "      <td>0.906</td>\n",
       "      <td>[{'text': 'but', 'start': 18.76, 'end': 19.12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2584</td>\n",
       "      <td>25.94</td>\n",
       "      <td>33.45</td>\n",
       "      <td>I got interested in like machine learning. I ...</td>\n",
       "      <td>[50364, 286, 658, 3102, 294, 411, 3479, 2539, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.120762</td>\n",
       "      <td>1.753488</td>\n",
       "      <td>0.026963</td>\n",
       "      <td>0.885</td>\n",
       "      <td>[{'text': 'I', 'start': 25.94, 'end': 26.2, 'c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  seek  start    end                                               text  \\\n",
       "0   0     0   0.00   5.69   We're starting now. So welcome to the intervi...   \n",
       "1   1     0   5.69   9.36   me a little bit about your background and wha...   \n",
       "2   2     0  11.18  18.06   Yeah, so right now I'm in third year of my co...   \n",
       "3   3     0  18.76  25.44   but yeah, from the start of my college, I thi...   \n",
       "4   4  2584  25.94  33.45   I got interested in like machine learning. I ...   \n",
       "\n",
       "                                              tokens  temperature  \\\n",
       "0  [50364, 492, 434, 2891, 586, 13, 407, 2928, 28...          0.0   \n",
       "1  [50648, 385, 257, 707, 857, 466, 428, 3678, 29...          0.0   \n",
       "2  [50916, 865, 11, 370, 558, 586, 286, 478, 294,...          0.0   \n",
       "3  [51304, 457, 1338, 11, 490, 264, 722, 295, 452...          0.0   \n",
       "4  [50364, 286, 658, 3102, 294, 411, 3479, 2539, ...          0.0   \n",
       "\n",
       "   avg_logprob  compression_ratio  no_speech_prob  confidence  \\\n",
       "0    -0.149370           1.573222        0.105431       0.837   \n",
       "1    -0.149370           1.573222        0.105431       0.973   \n",
       "2    -0.149370           1.573222        0.105431       0.887   \n",
       "3    -0.149370           1.573222        0.105431       0.906   \n",
       "4    -0.120762           1.753488        0.026963       0.885   \n",
       "\n",
       "                                               words  \n",
       "0  [{'text': 'We're', 'start': 0.0, 'end': 0.32, ...  \n",
       "1  [{'text': 'me', 'start': 5.69, 'end': 5.86, 'c...  \n",
       "2  [{'text': 'Yeah,', 'start': 11.18, 'end': 11.3...  \n",
       "3  [{'text': 'but', 'start': 18.76, 'end': 19.12,...  \n",
       "4  [{'text': 'I', 'start': 25.94, 'end': 26.2, 'c...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "407f4a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  2584,  5152,  7336,  9864, 12616, 15328, 18008, 20224,\n",
       "       23032, 25400, 27888, 30736, 33664, 35856, 38648, 41240, 43656,\n",
       "       45936, 48568, 51432, 53864, 56648, 59232, 62160])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df.seek.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e402707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'seek', 'start', 'end', 'text', 'tokens', 'temperature',\n",
       "       'avg_logprob', 'compression_ratio', 'no_speech_prob', 'confidence',\n",
       "       'words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b0f2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.drop(columns=['tokens', 'temperature', 'avg_logprob', 'compression_ratio', 'no_speech_prob', 'confidence', 'words'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0aed27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = project_root / 'data' / 'processed' / 'whisper_data' / 'Interview_2.csv'\n",
    "tr_df.to_csv(str(path), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923082c2",
   "metadata": {},
   "source": [
    "## Trying to get who is talking in the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f25f0ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading and transcribing...\n",
      "Transcription complete!\n",
      "Preview: Alright, we're starting now, so welcome to the interview. Let's begin with a simple question. Can yo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import requests\n",
    "from dotenv import load_dotenv\n",
    "import assemblyai as aai\n",
    "load_dotenv()\n",
    "api_key=os.getenv(\"ASSEMBLYAI_API_KEY\")\n",
    "\n",
    "audio_path = \"../data/raw/Interview_2.wav\"\n",
    "\n",
    "aai.settings.api_key = api_key\n",
    "\n",
    "print(\"Uploading and transcribing...\")\n",
    "transcriber = aai.Transcriber()\n",
    "\n",
    "# The SDK handles upload automatically\n",
    "transcript = transcriber.transcribe(\n",
    "    audio_path,  # Pass the file path directly\n",
    "    config=aai.TranscriptionConfig(speaker_labels=True)\n",
    ")\n",
    "\n",
    "if transcript.status == aai.TranscriptStatus.error:\n",
    "    print(f'Transcription failed: {transcript.error}')\n",
    "else:\n",
    "    print(\"Transcription complete!\")\n",
    "    \n",
    "    # Save transcript\n",
    "    with open(\"transcript_output.txt\", 'w') as f:\n",
    "        f.write(transcript.text)\n",
    "    \n",
    "    print(f\"Preview: {transcript.text[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "817b52f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Utterance(text=\"Alright, we're starting now, so welcome to the interview. Let's begin with a simple question. Can you tell me a little bit about your background and what got you interested in ML Engineering?\", start=80, end=9680, confidence=0.98873436, speaker='A', channel=None, words=[UtteranceWord(text='Alright,', start=80, end=280, confidence=0.82281494, speaker='A', channel=None), UtteranceWord(text=\"we're\", start=280, end=480, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='starting', start=480, end=800, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='now,', start=800, end=1120, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='so', start=1680, end=1960, confidence=0.9838867, speaker='A', channel=None), UtteranceWord(text='welcome', start=1960, end=2280, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='to', start=2280, end=2440, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='the', start=2440, end=2600, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='interview.', start=2600, end=3040, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text=\"Let's\", start=3360, end=3720, confidence=0.99886066, speaker='A', channel=None), UtteranceWord(text='begin', start=3720, end=3960, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='with', start=3960, end=4120, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='a', start=4120, end=4280, confidence=0.9863281, speaker='A', channel=None), UtteranceWord(text='simple', start=4280, end=4600, confidence=0.9992676, speaker='A', channel=None), UtteranceWord(text='question.', start=4600, end=4880, confidence=0.9819336, speaker='A', channel=None), UtteranceWord(text='Can', start=5200, end=5480, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='you', start=5480, end=5640, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='tell', start=5640, end=5800, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='me', start=5800, end=5920, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='a', start=5920, end=6040, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='little', start=6040, end=6200, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='bit', start=6200, end=6320, confidence=0.9970703, speaker='A', channel=None), UtteranceWord(text='about', start=6320, end=6480, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='your', start=6480, end=6680, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='background', start=6680, end=7160, confidence=0.88378906, speaker='A', channel=None), UtteranceWord(text='and', start=7160, end=7440, confidence=0.99560547, speaker='A', channel=None), UtteranceWord(text='what', start=7440, end=7640, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='got', start=7640, end=7800, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='you', start=7800, end=8040, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='interested', start=8040, end=8520, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='in', start=8520, end=8720, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='ML', start=8720, end=9120, confidence=0.9929199, speaker='A', channel=None), UtteranceWord(text='Engineering?', start=9120, end=9680, confidence=0.99886066, speaker='A', channel=None)], translated_texts=None),\n",
       " Utterance(text=\"Yeah, so like right now I'm in third year of my college, I mean like I'm going to be in the sixth semester but yeah, from start of my college, I think from my second semester towards end of it I got interested in like machine learning. I, I got to know about machine learning from some channels, from YouTube channels and all and I thought yeah, it is an interesting field. I got to know some things about it. I took a course, a very famous course from Andrew Ng which is ML specialization course which is on Coursera. So in the break, in the summer break which I've got in the college, I actually completed that course and actually I was very intrigued by how like we do all the stuff, what we do in the like machine learning field. Right. So it was very interesting and like after that I was just doing some courses, then I got into deep learning, I then got into some nlp. I like, I learned NLP or like Transformers about all these things from some YouTube channel from a famous, very famous guy called like Andrej Karpathy, his famous, famous playlist on neural networks. That was amazing. So I built, I tried like I did some projects, I got into some hackathons with my friends and all, we worked on some ideas and all. So yeah, that was pretty amazing and that got me into this journey on ML and then DL and Genai stuff and that's how I thought that yeah, this is the field for me. I'm very interested in this field. I like, I like it is amazing what we do and I saw the possibilities that what we can build from this ever growing field. Right. So that's why I chose this field and that's why I'm in front of you interviewing for this role here.\", start=11040, end=136520, confidence=0.9752746, speaker='B', channel=None, words=[UtteranceWord(text='Yeah,', start=11040, end=11600, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='so', start=11680, end=12080, confidence=0.9741211, speaker='B', channel=None), UtteranceWord(text='like', start=12640, end=12960, confidence=0.90722656, speaker='B', channel=None), UtteranceWord(text='right', start=12960, end=13200, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='now', start=13200, end=13400, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=13400, end=13640, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='in', start=13640, end=13880, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='third', start=13880, end=14200, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='year', start=14200, end=14440, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='of', start=14440, end=14640, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='my', start=14640, end=14840, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='college,', start=14840, end=15280, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='I', start=15680, end=15920, confidence=0.9873047, speaker='B', channel=None), UtteranceWord(text='mean', start=15920, end=16160, confidence=0.64746094, speaker='B', channel=None), UtteranceWord(text='like', start=16160, end=16440, confidence=0.96191406, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=16440, end=16680, confidence=0.9848633, speaker='B', channel=None), UtteranceWord(text='going', start=16680, end=16840, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='to', start=16840, end=17000, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='be', start=17000, end=17200, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='in', start=17200, end=17360, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='the', start=17360, end=17520, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='sixth', start=17520, end=17840, confidence=0.9453125, speaker='B', channel=None), UtteranceWord(text='semester', start=17840, end=18400, confidence=0.92626953, speaker='B', channel=None), UtteranceWord(text='but', start=18800, end=19200, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='yeah,', start=19680, end=20160, confidence=0.8655599, speaker='B', channel=None), UtteranceWord(text='from', start=20480, end=20880, confidence=0.99072266, speaker='B', channel=None), UtteranceWord(text='start', start=21040, end=21400, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='of', start=21400, end=21640, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='my', start=21640, end=21800, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='college,', start=21800, end=22120, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='I', start=22120, end=22280, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='think', start=22280, end=22520, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='from', start=22520, end=22840, confidence=0.9921875, speaker='B', channel=None), UtteranceWord(text='my', start=22840, end=23120, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='second', start=23120, end=23440, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='semester', start=23440, end=23960, confidence=0.9165039, speaker='B', channel=None), UtteranceWord(text='towards', start=23960, end=24480, confidence=0.998291, speaker='B', channel=None), UtteranceWord(text='end', start=24880, end=25160, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='of', start=25160, end=25280, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='it', start=25280, end=25520, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='I', start=26100, end=26340, confidence=0.9707031, speaker='B', channel=None), UtteranceWord(text='got', start=26340, end=26700, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='interested', start=26700, end=27260, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='in', start=27260, end=27540, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='like', start=28020, end=28420, confidence=0.9394531, speaker='B', channel=None), UtteranceWord(text='machine', start=28820, end=29300, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='learning.', start=29300, end=29660, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='I,', start=29660, end=29980, confidence=0.8925781, speaker='B', channel=None), UtteranceWord(text='I', start=29980, end=30220, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='got', start=30220, end=30420, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='to', start=30420, end=30660, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='know', start=30660, end=30860, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='about', start=30860, end=31140, confidence=0.9321289, speaker='B', channel=None), UtteranceWord(text='machine', start=31380, end=31860, confidence=0.9998372, speaker='B', channel=None), UtteranceWord(text='learning', start=31860, end=32260, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='from', start=32580, end=32900, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='some', start=32900, end=33140, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='channels,', start=33140, end=33620, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='from', start=33620, end=33900, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='YouTube', start=33900, end=34300, confidence=0.9794922, speaker='B', channel=None), UtteranceWord(text='channels', start=34300, end=34660, confidence=0.99934894, speaker='B', channel=None), UtteranceWord(text='and', start=34660, end=34860, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='all', start=34860, end=35140, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='and', start=35460, end=35820, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='I', start=35820, end=36060, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='thought', start=36060, end=36340, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='yeah,', start=36340, end=36700, confidence=0.99593097, speaker='B', channel=None), UtteranceWord(text='it', start=36700, end=36820, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=36820, end=36980, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='an', start=36980, end=37180, confidence=0.75634766, speaker='B', channel=None), UtteranceWord(text='interesting', start=37180, end=37660, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='field.', start=37660, end=37940, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='I', start=37940, end=38140, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='got', start=38140, end=38340, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='to', start=38340, end=38540, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='know', start=38540, end=38740, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='some', start=38740, end=38940, confidence=0.96435547, speaker='B', channel=None), UtteranceWord(text='things', start=38940, end=39140, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='about', start=39140, end=39460, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='it.', start=39700, end=40100, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='I', start=40660, end=41020, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='took', start=41020, end=41380, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='a', start=41699, end=41980, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='course,', start=41980, end=42260, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='a', start=42340, end=42620, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='very', start=42620, end=42820, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='famous', start=42820, end=43220, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='course', start=43220, end=43500, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='from', start=43500, end=43860, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='Andrew', start=43860, end=44340, confidence=0.79752606, speaker='B', channel=None), UtteranceWord(text='Ng', start=44340, end=44820, confidence=0.98291016, speaker='B', channel=None), UtteranceWord(text='which', start=45140, end=45420, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='is', start=45420, end=45660, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='ML', start=45660, end=46180, confidence=0.9902344, speaker='B', channel=None), UtteranceWord(text='specialization', start=46180, end=46900, confidence=0.81884766, speaker='B', channel=None), UtteranceWord(text='course', start=46980, end=47380, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='which', start=47700, end=47980, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=47980, end=48100, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='on', start=48100, end=48220, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='Coursera.', start=48220, end=48820, confidence=0.8688965, speaker='B', channel=None), UtteranceWord(text='So', start=49300, end=49620, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='in', start=49620, end=49820, confidence=0.99365234, speaker='B', channel=None), UtteranceWord(text='the', start=49820, end=50020, confidence=0.9873047, speaker='B', channel=None), UtteranceWord(text='break,', start=50020, end=50340, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='in', start=50340, end=50620, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='the', start=50620, end=50740, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='summer', start=50740, end=51020, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='break', start=51020, end=51220, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='which', start=51220, end=51420, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text=\"I've\", start=51420, end=51700, confidence=0.94401044, speaker='B', channel=None), UtteranceWord(text='got', start=51700, end=51860, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='in', start=51860, end=52060, confidence=0.93066406, speaker='B', channel=None), UtteranceWord(text='the', start=52060, end=52220, confidence=0.98535156, speaker='B', channel=None), UtteranceWord(text='college,', start=52220, end=52660, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='I', start=52660, end=53060, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='actually', start=53140, end=53540, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='completed', start=53540, end=54140, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='that', start=54140, end=54340, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='course', start=54340, end=54660, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='and', start=55270, end=55470, confidence=0.8989258, speaker='B', channel=None), UtteranceWord(text='actually', start=55470, end=55790, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='I', start=55790, end=56030, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='was', start=56030, end=56230, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='very', start=56230, end=56470, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='intrigued', start=56470, end=57110, confidence=0.94555664, speaker='B', channel=None), UtteranceWord(text='by', start=57590, end=57990, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='how', start=58710, end=59110, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='like', start=60070, end=60430, confidence=0.9042969, speaker='B', channel=None), UtteranceWord(text='we', start=60430, end=60670, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='do', start=60670, end=60830, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='all', start=60830, end=60990, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=60990, end=61190, confidence=0.7402344, speaker='B', channel=None), UtteranceWord(text='stuff,', start=61190, end=61470, confidence=0.9996745, speaker='B', channel=None), UtteranceWord(text='what', start=61470, end=61630, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='we', start=61630, end=61790, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='do', start=61790, end=61950, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='in', start=61950, end=62070, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='the', start=62070, end=62310, confidence=0.9902344, speaker='B', channel=None), UtteranceWord(text='like', start=62470, end=62870, confidence=0.87939453, speaker='B', channel=None), UtteranceWord(text='machine', start=63110, end=63550, confidence=0.9998372, speaker='B', channel=None), UtteranceWord(text='learning', start=63550, end=63870, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='field.', start=63870, end=64150, confidence=0.9916992, speaker='B', channel=None), UtteranceWord(text='Right.', start=64150, end=64470, confidence=0.98291016, speaker='B', channel=None), UtteranceWord(text='So', start=65030, end=65430, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='it', start=65510, end=65790, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='was', start=65790, end=65990, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='very', start=65990, end=66190, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='interesting', start=66190, end=66790, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='and', start=66790, end=67190, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='like', start=68150, end=68550, confidence=0.98095703, speaker='B', channel=None), UtteranceWord(text='after', start=68790, end=69190, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='that', start=69190, end=69550, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='I', start=69550, end=69790, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='was', start=69790, end=69990, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='just', start=69990, end=70310, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='doing', start=70550, end=70949, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='some', start=70949, end=71270, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='courses,', start=71270, end=71750, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='then', start=71750, end=72030, confidence=0.9902344, speaker='B', channel=None), UtteranceWord(text='I', start=72030, end=72190, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='got', start=72190, end=72390, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='into', start=72390, end=72710, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='deep', start=72790, end=73190, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='learning,', start=73190, end=73590, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='I', start=73990, end=74310, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='then', start=74310, end=74590, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='got', start=74590, end=74910, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='into', start=74910, end=75270, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='some', start=75350, end=75750, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='nlp.', start=76390, end=77190, confidence=0.98307294, speaker='B', channel=None), UtteranceWord(text='I', start=77350, end=77750, confidence=0.9658203, speaker='B', channel=None), UtteranceWord(text='like,', start=77910, end=78310, confidence=0.95751953, speaker='B', channel=None), UtteranceWord(text='I', start=78630, end=78950, confidence=0.95703125, speaker='B', channel=None), UtteranceWord(text='learned', start=78950, end=79310, confidence=0.9968262, speaker='B', channel=None), UtteranceWord(text='NLP', start=79310, end=79910, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='or', start=79910, end=80190, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='like', start=80190, end=80510, confidence=0.8911133, speaker='B', channel=None), UtteranceWord(text='Transformers', start=80510, end=81350, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='about', start=81350, end=81750, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='all', start=81910, end=82270, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='these', start=82270, end=82590, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='things', start=82590, end=82950, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='from', start=83190, end=83470, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='some', start=83470, end=83670, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='YouTube', start=83670, end=84110, confidence=0.95422363, speaker='B', channel=None), UtteranceWord(text='channel', start=84110, end=84550, confidence=0.99869794, speaker='B', channel=None), UtteranceWord(text='from', start=84850, end=84970, confidence=0.92529297, speaker='B', channel=None), UtteranceWord(text='a', start=84970, end=85130, confidence=0.53125, speaker='B', channel=None), UtteranceWord(text='famous,', start=85130, end=85530, confidence=0.81762695, speaker='B', channel=None), UtteranceWord(text='very', start=85530, end=85810, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='famous', start=85810, end=86210, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='guy', start=86210, end=86530, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='called', start=86530, end=86810, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='like', start=86810, end=87170, confidence=0.9394531, speaker='B', channel=None), UtteranceWord(text='Andrej', start=87410, end=88090, confidence=0.95182294, speaker='B', channel=None), UtteranceWord(text='Karpathy,', start=88090, end=88850, confidence=0.91494143, speaker='B', channel=None), UtteranceWord(text='his', start=89330, end=89650, confidence=0.97558594, speaker='B', channel=None), UtteranceWord(text='famous,', start=89650, end=90210, confidence=0.9367676, speaker='B', channel=None), UtteranceWord(text='famous', start=90290, end=90810, confidence=0.98779297, speaker='B', channel=None), UtteranceWord(text='playlist', start=90810, end=91330, confidence=0.9059245, speaker='B', channel=None), UtteranceWord(text='on', start=91330, end=91610, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='neural', start=91610, end=92010, confidence=0.9987793, speaker='B', channel=None), UtteranceWord(text='networks.', start=92010, end=92610, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='That', start=92770, end=93050, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='was', start=93050, end=93210, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='amazing.', start=93210, end=93810, confidence=0.9998372, speaker='B', channel=None), UtteranceWord(text='So', start=94210, end=94490, confidence=0.98876953, speaker='B', channel=None), UtteranceWord(text='I', start=94490, end=94650, confidence=0.96240234, speaker='B', channel=None), UtteranceWord(text='built,', start=94650, end=95090, confidence=0.97526044, speaker='B', channel=None), UtteranceWord(text='I', start=95090, end=95410, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='tried', start=95410, end=95850, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='like', start=95850, end=96130, confidence=0.90185547, speaker='B', channel=None), UtteranceWord(text='I', start=96130, end=96410, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='did', start=96410, end=96730, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='some', start=96730, end=97010, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='projects,', start=97010, end=97650, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='I', start=97650, end=97930, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='got', start=97930, end=98170, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='into', start=98170, end=98490, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='some', start=98490, end=98730, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='hackathons', start=98730, end=99370, confidence=0.9987305, speaker='B', channel=None), UtteranceWord(text='with', start=99370, end=99610, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='my', start=99610, end=99810, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='friends', start=99810, end=100090, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='and', start=100090, end=100330, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='all,', start=100330, end=100610, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='we', start=100769, end=101090, confidence=0.8911133, speaker='B', channel=None), UtteranceWord(text='worked', start=101090, end=101410, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='on', start=101410, end=101530, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='some', start=101530, end=101730, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='ideas', start=101730, end=102130, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='and', start=102130, end=102370, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='all.', start=102370, end=102690, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='So', start=103090, end=103410, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='yeah,', start=103410, end=103690, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='that', start=103690, end=103850, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='was', start=103850, end=104050, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='pretty', start=104050, end=104330, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='amazing', start=104330, end=104810, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='and', start=104810, end=105170, confidence=0.9902344, speaker='B', channel=None), UtteranceWord(text='that', start=105890, end=106250, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='got', start=106250, end=106530, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='me', start=106530, end=106730, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='into', start=106730, end=106970, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='this', start=106970, end=107330, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='journey', start=107810, end=108450, confidence=0.99934894, speaker='B', channel=None), UtteranceWord(text='on', start=108850, end=109210, confidence=0.98876953, speaker='B', channel=None), UtteranceWord(text='ML', start=109210, end=109770, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='and', start=109770, end=110090, confidence=0.93115234, speaker='B', channel=None), UtteranceWord(text='then', start=110090, end=110370, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='DL', start=110370, end=110810, confidence=0.78930664, speaker='B', channel=None), UtteranceWord(text='and', start=110810, end=111050, confidence=0.97558594, speaker='B', channel=None), UtteranceWord(text='Genai', start=111050, end=111570, confidence=0.88964844, speaker='B', channel=None), UtteranceWord(text='stuff', start=111570, end=112090, confidence=0.99348956, speaker='B', channel=None), UtteranceWord(text='and', start=112090, end=112450, confidence=0.97802734, speaker='B', channel=None), UtteranceWord(text=\"that's\", start=113320, end=113560, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='how', start=113560, end=113760, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='I', start=113760, end=114040, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='thought', start=114040, end=114280, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='that', start=114280, end=114520, confidence=0.98828125, speaker='B', channel=None), UtteranceWord(text='yeah,', start=114520, end=114800, confidence=0.9791667, speaker='B', channel=None), UtteranceWord(text='this', start=114800, end=114920, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='is', start=114920, end=115000, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='the', start=115000, end=115160, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='field', start=115160, end=115400, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='for', start=115400, end=115560, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='me.', start=115560, end=115720, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=115720, end=116000, confidence=0.98811847, speaker='B', channel=None), UtteranceWord(text='very', start=116000, end=116160, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='interested', start=116160, end=116680, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='in', start=116680, end=116920, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='this', start=116920, end=117240, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='field.', start=117320, end=117720, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='I', start=118040, end=118440, confidence=0.5600586, speaker='B', channel=None), UtteranceWord(text='like,', start=118600, end=118920, confidence=0.96533203, speaker='B', channel=None), UtteranceWord(text='I', start=118920, end=119240, confidence=0.8510742, speaker='B', channel=None), UtteranceWord(text='like', start=120200, end=120480, confidence=0.9238281, speaker='B', channel=None), UtteranceWord(text='it', start=120480, end=120640, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='is', start=120640, end=120800, confidence=0.98535156, speaker='B', channel=None), UtteranceWord(text='amazing', start=120800, end=121320, confidence=0.88378906, speaker='B', channel=None), UtteranceWord(text='what', start=121400, end=121680, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='we', start=121680, end=121840, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='do', start=121840, end=122120, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='and', start=122520, end=122920, confidence=0.82666016, speaker='B', channel=None), UtteranceWord(text='I', start=123080, end=123440, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='saw', start=123440, end=123720, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=123720, end=123920, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='possibilities', start=123920, end=124360, confidence=0.85042316, speaker='B', channel=None), UtteranceWord(text='that', start=124520, end=124840, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='what', start=124840, end=125080, confidence=0.9658203, speaker='B', channel=None), UtteranceWord(text='we', start=125080, end=125280, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='can', start=125280, end=125480, confidence=0.98876953, speaker='B', channel=None), UtteranceWord(text='build', start=125480, end=125760, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='from', start=125760, end=126040, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='this', start=126040, end=126360, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='ever', start=127080, end=127400, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='growing', start=127400, end=127880, confidence=0.8845215, speaker='B', channel=None), UtteranceWord(text='field.', start=128520, end=128920, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='Right.', start=129160, end=129560, confidence=0.8803711, speaker='B', channel=None), UtteranceWord(text='So', start=129960, end=130360, confidence=0.9770508, speaker='B', channel=None), UtteranceWord(text=\"that's\", start=130920, end=131320, confidence=0.99934894, speaker='B', channel=None), UtteranceWord(text='why', start=131320, end=131560, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='I', start=131560, end=131960, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='chose', start=132040, end=132440, confidence=0.8935547, speaker='B', channel=None), UtteranceWord(text='this', start=132440, end=132680, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='field', start=132680, end=132960, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='and', start=132960, end=133200, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text=\"that's\", start=133200, end=133480, confidence=0.99869794, speaker='B', channel=None), UtteranceWord(text='why', start=133480, end=133600, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=133600, end=133960, confidence=0.98616534, speaker='B', channel=None), UtteranceWord(text='in', start=134200, end=134480, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='front', start=134480, end=134680, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='of', start=134680, end=134880, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='you', start=134880, end=135040, confidence=0.7841797, speaker='B', channel=None), UtteranceWord(text='interviewing', start=135040, end=135600, confidence=0.85465497, speaker='B', channel=None), UtteranceWord(text='for', start=135600, end=135760, confidence=0.99072266, speaker='B', channel=None), UtteranceWord(text='this', start=135760, end=135960, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='role', start=135960, end=136200, confidence=0.9824219, speaker='B', channel=None), UtteranceWord(text='here.', start=136200, end=136520, confidence=0.50439453, speaker='B', channel=None)], translated_texts=None),\n",
       " Utterance(text=\"That's a great background and it's always awesome to hear how those initial courses and projects really hooked you in. Now let me dive a bit deeper into the technical side. So for the next question, imagine you're working on a machine learning project where you have a data set that isn't perfectly clean. How would you go about handling missing data or noisy data in that data set before you actually train your model?\", start=139650, end=162370, confidence=0.97751033, speaker='A', channel=None, words=[UtteranceWord(text=\"That's\", start=139650, end=139890, confidence=0.99820966, speaker='A', channel=None), UtteranceWord(text='a', start=139890, end=140010, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='great', start=140010, end=140210, confidence=0.9951172, speaker='A', channel=None), UtteranceWord(text='background', start=140210, end=140770, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='and', start=141010, end=141290, confidence=0.6220703, speaker='A', channel=None), UtteranceWord(text=\"it's\", start=141290, end=141490, confidence=0.99934894, speaker='A', channel=None), UtteranceWord(text='always', start=141490, end=141690, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='awesome', start=141690, end=142090, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='to', start=142090, end=142250, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='hear', start=142250, end=142450, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='how', start=142450, end=142770, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='those', start=142930, end=143250, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='initial', start=143250, end=143690, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='courses', start=143690, end=144130, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='and', start=144130, end=144330, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='projects', start=144330, end=144890, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='really', start=144890, end=145170, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='hooked', start=145170, end=145530, confidence=0.96972656, speaker='A', channel=None), UtteranceWord(text='you', start=145530, end=145690, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='in.', start=145690, end=145970, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='Now', start=146370, end=146690, confidence=0.9707031, speaker='A', channel=None), UtteranceWord(text='let', start=146690, end=146850, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='me', start=146850, end=146970, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='dive', start=146970, end=147170, confidence=0.93408203, speaker='A', channel=None), UtteranceWord(text='a', start=147170, end=147250, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='bit', start=147250, end=147370, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='deeper', start=147370, end=147690, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='into', start=147690, end=147850, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='the', start=147850, end=148010, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='technical', start=148010, end=148450, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='side.', start=148450, end=148770, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='So', start=149410, end=149690, confidence=0.53125, speaker='A', channel=None), UtteranceWord(text='for', start=149690, end=149850, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='the', start=149850, end=150010, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='next', start=150010, end=150210, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='question,', start=150210, end=150530, confidence=0.9819336, speaker='A', channel=None), UtteranceWord(text='imagine', start=150930, end=151450, confidence=0.9798177, speaker='A', channel=None), UtteranceWord(text=\"you're\", start=151450, end=151650, confidence=0.99527997, speaker='A', channel=None), UtteranceWord(text='working', start=151650, end=151810, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='on', start=151810, end=151970, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='a', start=151970, end=152090, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='machine', start=152090, end=152410, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='learning', start=152410, end=152690, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='project', start=152690, end=153010, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='where', start=153090, end=153370, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='you', start=153370, end=153530, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='have', start=153530, end=153650, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='a', start=153650, end=153770, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='data', start=153770, end=153970, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='set', start=153970, end=154290, confidence=0.7504883, speaker='A', channel=None), UtteranceWord(text='that', start=154369, end=154690, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text=\"isn't\", start=154690, end=155090, confidence=0.88098145, speaker='A', channel=None), UtteranceWord(text='perfectly', start=155090, end=155530, confidence=0.9699707, speaker='A', channel=None), UtteranceWord(text='clean.', start=155530, end=155890, confidence=0.9848633, speaker='A', channel=None), UtteranceWord(text='How', start=156290, end=156570, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='would', start=156570, end=156730, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='you', start=156730, end=156890, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='go', start=156890, end=157010, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='about', start=157010, end=157170, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='handling', start=157170, end=157690, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='missing', start=157690, end=158130, confidence=0.9992676, speaker='A', channel=None), UtteranceWord(text='data', start=158130, end=158450, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='or', start=158530, end=158930, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='noisy', start=158930, end=159450, confidence=0.9746094, speaker='A', channel=None), UtteranceWord(text='data', start=159450, end=159650, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='in', start=159650, end=159850, confidence=0.9765625, speaker='A', channel=None), UtteranceWord(text='that', start=159850, end=160010, confidence=0.9746094, speaker='A', channel=None), UtteranceWord(text='data', start=160010, end=160250, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='set', start=160250, end=160610, confidence=0.8574219, speaker='A', channel=None), UtteranceWord(text='before', start=160690, end=161050, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='you', start=161050, end=161290, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='actually', start=161290, end=161490, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='train', start=161490, end=161770, confidence=0.9946289, speaker='A', channel=None), UtteranceWord(text='your', start=161770, end=161930, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='model?', start=161930, end=162370, confidence=0.9995117, speaker='A', channel=None)], translated_texts=None),\n",
       " Utterance(text=\"Yeah, so handling or cleaning the data set is obviously one of the like major parts of any, any ML project or whatever I'm doing. But it really depends on what type of data I'm working with. Right. So for some Data Actually missing data might be a new info. So you don't, you can't do like you, you don't have to remove it, but for some, for some like field or for some data you actually have to remove it. And it also depends on what algorithm I'm using, right? So if I'm, if I'm using, for example, for example, if I'm using linear regression, you, you don't want these like NAN values in your data set. So you, what we can do is what, we can simply fill them up with the mean values or like mode values. But.\", start=163490, end=217580, confidence=0.9637693, speaker='B', channel=None, words=[UtteranceWord(text='Yeah,', start=163490, end=163930, confidence=0.7630208, speaker='B', channel=None), UtteranceWord(text='so', start=163930, end=164290, confidence=0.59228516, speaker='B', channel=None), UtteranceWord(text='handling', start=164840, end=165240, confidence=0.9880371, speaker='B', channel=None), UtteranceWord(text='or', start=165240, end=165440, confidence=0.9824219, speaker='B', channel=None), UtteranceWord(text='cleaning', start=165440, end=165840, confidence=0.84244794, speaker='B', channel=None), UtteranceWord(text='the', start=165840, end=165960, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='data', start=165960, end=166160, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='set', start=166160, end=166440, confidence=0.88720703, speaker='B', channel=None), UtteranceWord(text='is', start=166440, end=166680, confidence=0.96972656, speaker='B', channel=None), UtteranceWord(text='obviously', start=166680, end=167320, confidence=0.9996745, speaker='B', channel=None), UtteranceWord(text='one', start=167320, end=167600, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='of', start=167600, end=167760, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='the', start=167760, end=168000, confidence=0.9902344, speaker='B', channel=None), UtteranceWord(text='like', start=168000, end=168320, confidence=0.703125, speaker='B', channel=None), UtteranceWord(text='major', start=168320, end=168680, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='parts', start=168680, end=169160, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='of', start=169160, end=169320, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='any,', start=169320, end=169640, confidence=0.95996094, speaker='B', channel=None), UtteranceWord(text='any', start=170200, end=170560, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='ML', start=170560, end=171000, confidence=0.9772949, speaker='B', channel=None), UtteranceWord(text='project', start=171000, end=171320, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='or', start=171320, end=171640, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='whatever', start=171640, end=172000, confidence=1.0, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=172000, end=172240, confidence=0.94661456, speaker='B', channel=None), UtteranceWord(text='doing.', start=172240, end=172520, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='But', start=172920, end=173240, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='it', start=173240, end=173480, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='really', start=173480, end=173760, confidence=0.6904297, speaker='B', channel=None), UtteranceWord(text='depends', start=173760, end=174360, confidence=0.99869794, speaker='B', channel=None), UtteranceWord(text='on', start=174360, end=174680, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='what', start=174840, end=175240, confidence=0.5620117, speaker='B', channel=None), UtteranceWord(text='type', start=175240, end=175560, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='of', start=175560, end=175680, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='data', start=175680, end=175920, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=175920, end=176240, confidence=0.9477539, speaker='B', channel=None), UtteranceWord(text='working', start=176240, end=176440, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='with.', start=176440, end=176760, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='Right.', start=176760, end=177160, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='So', start=177560, end=177960, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='for', start=178200, end=178600, confidence=0.98339844, speaker='B', channel=None), UtteranceWord(text='some', start=178600, end=178920, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='Data', start=178920, end=179240, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='Actually', start=179400, end=179760, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='missing', start=179760, end=180160, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='data', start=180160, end=180439, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='might', start=180439, end=180719, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='be', start=180719, end=180880, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='a', start=180880, end=181000, confidence=0.9897461, speaker='B', channel=None), UtteranceWord(text='new', start=181000, end=181160, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='info.', start=181160, end=181720, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='So', start=181800, end=182080, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='you', start=182080, end=182240, confidence=0.96240234, speaker='B', channel=None), UtteranceWord(text=\"don't,\", start=182240, end=182440, confidence=0.92089844, speaker='B', channel=None), UtteranceWord(text='you', start=182440, end=182560, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text=\"can't\", start=182560, end=182880, confidence=0.99576825, speaker='B', channel=None), UtteranceWord(text='do', start=182880, end=183120, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='like', start=183120, end=183400, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='you,', start=183400, end=183680, confidence=0.9238281, speaker='B', channel=None), UtteranceWord(text='you', start=183680, end=183920, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text=\"don't\", start=183920, end=184160, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='have', start=184160, end=184280, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='to', start=184280, end=184400, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='remove', start=184400, end=184720, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='it,', start=184720, end=185000, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='but', start=185480, end=185880, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='for', start=185960, end=186240, confidence=0.96191406, speaker='B', channel=None), UtteranceWord(text='some,', start=186240, end=186520, confidence=0.59521484, speaker='B', channel=None), UtteranceWord(text='for', start=186680, end=187000, confidence=0.97802734, speaker='B', channel=None), UtteranceWord(text='some', start=187000, end=187320, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='like', start=187400, end=187800, confidence=0.98876953, speaker='B', channel=None), UtteranceWord(text='field', start=188440, end=188800, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='or', start=188800, end=189040, confidence=0.9350586, speaker='B', channel=None), UtteranceWord(text='for', start=189040, end=189240, confidence=0.98339844, speaker='B', channel=None), UtteranceWord(text='some', start=189240, end=189480, confidence=0.9707031, speaker='B', channel=None), UtteranceWord(text='data', start=189480, end=189800, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='you', start=190690, end=190850, confidence=0.9741211, speaker='B', channel=None), UtteranceWord(text='actually', start=190850, end=191130, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='have', start=191130, end=191370, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='to', start=191370, end=191530, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='remove', start=191530, end=191770, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='it.', start=191770, end=192050, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='And', start=192370, end=192770, confidence=0.96240234, speaker='B', channel=None), UtteranceWord(text='it', start=194050, end=194330, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='also', start=194330, end=194570, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='depends', start=194570, end=195050, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='on', start=195050, end=195290, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='what', start=195290, end=195650, confidence=0.91503906, speaker='B', channel=None), UtteranceWord(text='algorithm', start=195890, end=196650, confidence=0.9928711, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=196650, end=196970, confidence=0.9895833, speaker='B', channel=None), UtteranceWord(text='using,', start=196970, end=197250, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='right?', start=197330, end=197650, confidence=0.93896484, speaker='B', channel=None), UtteranceWord(text='So', start=197650, end=197850, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='if', start=197850, end=198010, confidence=0.8173828, speaker='B', channel=None), UtteranceWord(text=\"I'm,\", start=198010, end=198250, confidence=0.9690755, speaker='B', channel=None), UtteranceWord(text='if', start=198250, end=198410, confidence=0.98095703, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=198410, end=198650, confidence=0.87027997, speaker='B', channel=None), UtteranceWord(text='using,', start=198650, end=198930, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='for', start=198930, end=199210, confidence=0.94628906, speaker='B', channel=None), UtteranceWord(text='example,', start=199210, end=199730, confidence=0.84244794, speaker='B', channel=None), UtteranceWord(text='for', start=201090, end=201370, confidence=0.9667969, speaker='B', channel=None), UtteranceWord(text='example,', start=201370, end=201690, confidence=0.99934894, speaker='B', channel=None), UtteranceWord(text='if', start=201690, end=201850, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=201850, end=202090, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='using', start=202090, end=202370, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='linear', start=203010, end=203450, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='regression,', start=203450, end=204130, confidence=0.8929036, speaker='B', channel=None), UtteranceWord(text='you,', start=204130, end=204530, confidence=0.73095703, speaker='B', channel=None), UtteranceWord(text='you', start=204530, end=204810, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text=\"don't\", start=204810, end=205090, confidence=0.991862, speaker='B', channel=None), UtteranceWord(text='want', start=205090, end=205370, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='these', start=205370, end=205730, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='like', start=205730, end=206130, confidence=0.9794922, speaker='B', channel=None), UtteranceWord(text='NAN', start=206210, end=206770, confidence=0.9880371, speaker='B', channel=None), UtteranceWord(text='values', start=206850, end=207490, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='in', start=207570, end=207850, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='your', start=207850, end=208050, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='data', start=208050, end=208330, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='set.', start=208330, end=208690, confidence=0.95410156, speaker='B', channel=None), UtteranceWord(text='So', start=209010, end=209410, confidence=0.98583984, speaker='B', channel=None), UtteranceWord(text='you,', start=209490, end=209890, confidence=0.8515625, speaker='B', channel=None), UtteranceWord(text='what', start=209890, end=210170, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='we', start=210170, end=210330, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='can', start=210330, end=210530, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='do', start=210530, end=210770, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=210770, end=211090, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='what,', start=211250, end=211650, confidence=0.921875, speaker='B', channel=None), UtteranceWord(text='we', start=211890, end=212210, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='can', start=212210, end=212410, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='simply', start=212410, end=212850, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='fill', start=212930, end=213290, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='them', start=213290, end=213490, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='up', start=213490, end=213770, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='with', start=213770, end=214050, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=214050, end=214210, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='mean', start=214210, end=214450, confidence=0.6635742, speaker='B', channel=None), UtteranceWord(text='values', start=214450, end=215010, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='or', start=215010, end=215250, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='like', start=215250, end=215490, confidence=0.9584961, speaker='B', channel=None), UtteranceWord(text='mode', start=215490, end=215850, confidence=0.96313477, speaker='B', channel=None), UtteranceWord(text='values.', start=215850, end=216370, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='But.', start=217340, end=217580, confidence=0.9975586, speaker='B', channel=None)], translated_texts=None),\n",
       " Utterance(text='Those are not always the right choices.', start=219100, end=221900, confidence=0.99893045, speaker='B', channel=None, words=[UtteranceWord(text='Those', start=219100, end=219500, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='are', start=219580, end=219860, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='not', start=219860, end=220100, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='always', start=220100, end=220460, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=220620, end=220900, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='right', start=220900, end=221180, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='choices.', start=221180, end=221900, confidence=0.9930013, speaker='B', channel=None)], translated_texts=None),\n",
       " Utterance(text=\"Right? And you can like, there are many like choices here about how, how would you clean the data? And if the, if the data is like, if the data is what if the data is like time series data, right. If the data is time series data, then you can fill the, fill the NN values with only the previous, previous time period value. Right. This is also a way or if you like. So there are multiple ways and if you want one single answer, it is a bit difficult to give one because it highly depends on which model are you using and what type of data you have got and what the data is related to which field. Right. There are multiple types of data, cross sectional data and panel data. So it highly depends what type of data you're working with, which model are we trying to use and accordingly, I'll try to clean the data.\", start=223900, end=282730, confidence=0.9837275, speaker='B', channel=None, words=[UtteranceWord(text='Right?', start=223900, end=224260, confidence=0.98339844, speaker='B', channel=None), UtteranceWord(text='And', start=224260, end=224620, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='you', start=224620, end=224900, confidence=0.98583984, speaker='B', channel=None), UtteranceWord(text='can', start=224900, end=225180, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='like,', start=225260, end=225580, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='there', start=225580, end=225780, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='are', start=225780, end=226060, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='many', start=226460, end=226860, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='like', start=227260, end=227660, confidence=0.9819336, speaker='B', channel=None), UtteranceWord(text='choices', start=227980, end=228620, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='here', start=228620, end=229020, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='about', start=229340, end=229700, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='how,', start=229700, end=230060, confidence=0.9902344, speaker='B', channel=None), UtteranceWord(text='how', start=230060, end=230380, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='would', start=230380, end=230580, confidence=0.8417969, speaker='B', channel=None), UtteranceWord(text='you', start=230580, end=230740, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='clean', start=230740, end=231020, confidence=0.98779297, speaker='B', channel=None), UtteranceWord(text='the', start=231020, end=231220, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='data?', start=231220, end=231500, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='And', start=231820, end=232220, confidence=0.9902344, speaker='B', channel=None), UtteranceWord(text='if', start=232459, end=232780, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='the,', start=232780, end=232980, confidence=0.9667969, speaker='B', channel=None), UtteranceWord(text='if', start=232980, end=233140, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='the', start=233140, end=233300, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='data', start=233300, end=233540, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=233540, end=233900, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='like,', start=233980, end=234380, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='if', start=235260, end=235540, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='the', start=235540, end=235700, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='data', start=235700, end=235940, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=235940, end=236300, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='what', start=236700, end=237100, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='if', start=237180, end=237460, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='the', start=237460, end=237580, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data', start=237580, end=237820, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='is', start=237820, end=238140, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='like', start=238140, end=238460, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='time', start=239180, end=239540, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='series', start=239540, end=239860, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='data,', start=239860, end=240220, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='right.', start=240460, end=240860, confidence=0.9848633, speaker='B', channel=None), UtteranceWord(text='If', start=240860, end=241140, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=241140, end=241300, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='data', start=241300, end=241500, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=241500, end=241660, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='time', start=241660, end=241820, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='series', start=241820, end=242140, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data,', start=242140, end=242460, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='then', start=242460, end=242660, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='you', start=242660, end=242820, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='can', start=242820, end=243100, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='fill', start=243640, end=243800, confidence=0.9406738, speaker='B', channel=None), UtteranceWord(text='the,', start=243800, end=244040, confidence=0.9121094, speaker='B', channel=None), UtteranceWord(text='fill', start=244040, end=244400, confidence=0.98779297, speaker='B', channel=None), UtteranceWord(text='the', start=244400, end=244680, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='NN', start=244920, end=245520, confidence=0.8239746, speaker='B', channel=None), UtteranceWord(text='values', start=245520, end=246120, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='with', start=246120, end=246520, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='only', start=246680, end=247000, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=247000, end=247200, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='previous,', start=247200, end=247480, confidence=0.85839844, speaker='B', channel=None), UtteranceWord(text='previous', start=247720, end=248120, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='time', start=248680, end=249080, confidence=0.9897461, speaker='B', channel=None), UtteranceWord(text='period', start=249320, end=249720, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='value.', start=249720, end=250120, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='Right.', start=250280, end=250680, confidence=0.9082031, speaker='B', channel=None), UtteranceWord(text='This', start=250840, end=251120, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='is', start=251120, end=251280, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='also', start=251280, end=251520, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='a', start=251520, end=251760, confidence=0.95654297, speaker='B', channel=None), UtteranceWord(text='way', start=251760, end=252040, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='or', start=252440, end=252840, confidence=0.9819336, speaker='B', channel=None), UtteranceWord(text='if', start=253240, end=253520, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='you', start=253520, end=253800, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='like.', start=253880, end=254280, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='So', start=255080, end=255320, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='there', start=255320, end=255440, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='are', start=255440, end=255640, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='multiple', start=255640, end=256040, confidence=0.8642578, speaker='B', channel=None), UtteranceWord(text='ways', start=256040, end=256400, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='and', start=256400, end=256680, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='if', start=256680, end=256960, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='you', start=256960, end=257160, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='want', start=257160, end=257480, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='one', start=258280, end=258600, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='single', start=258600, end=258960, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='answer,', start=258960, end=259280, confidence=0.9998372, speaker='B', channel=None), UtteranceWord(text='it', start=259280, end=259440, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='is', start=259440, end=259599, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='a', start=259599, end=259719, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='bit', start=259719, end=259960, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='difficult', start=260600, end=261120, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='to', start=261120, end=261280, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='give', start=261280, end=261480, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='one', start=261480, end=261760, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='because', start=261760, end=262120, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='it', start=262680, end=263000, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='highly', start=263000, end=263360, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='depends', start=263360, end=263720, confidence=0.9998372, speaker='B', channel=None), UtteranceWord(text='on', start=263720, end=263840, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='which', start=263840, end=264040, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='model', start=264040, end=264400, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='are', start=264400, end=264560, confidence=0.9916992, speaker='B', channel=None), UtteranceWord(text='you', start=264560, end=264760, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='using', start=264760, end=265080, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='and', start=265080, end=265440, confidence=0.5620117, speaker='B', channel=None), UtteranceWord(text='what', start=265440, end=265720, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='type', start=265720, end=266000, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='of', start=266000, end=266160, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='data', start=266160, end=266360, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='you', start=266360, end=266560, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='have', start=266560, end=266720, confidence=0.9589844, speaker='B', channel=None), UtteranceWord(text='got', start=266720, end=266960, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='and', start=266960, end=267240, confidence=0.99365234, speaker='B', channel=None), UtteranceWord(text='what', start=267240, end=267560, confidence=0.91308594, speaker='B', channel=None), UtteranceWord(text='the', start=267720, end=268000, confidence=0.98876953, speaker='B', channel=None), UtteranceWord(text='data', start=268000, end=268240, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='is', start=268240, end=268560, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='related', start=268560, end=268880, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='to', start=268880, end=269120, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='which', start=269120, end=269360, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='field.', start=269360, end=269720, confidence=0.98876953, speaker='B', channel=None), UtteranceWord(text='Right.', start=269720, end=270120, confidence=0.9370117, speaker='B', channel=None), UtteranceWord(text='There', start=270570, end=270690, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='are', start=270690, end=270850, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='multiple', start=270850, end=271170, confidence=0.9996745, speaker='B', channel=None), UtteranceWord(text='types', start=271170, end=271410, confidence=0.89868164, speaker='B', channel=None), UtteranceWord(text='of', start=271410, end=271570, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='data,', start=271570, end=271810, confidence=0.98779297, speaker='B', channel=None), UtteranceWord(text='cross', start=271810, end=272130, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='sectional', start=272130, end=272570, confidence=0.85131836, speaker='B', channel=None), UtteranceWord(text='data', start=272570, end=272850, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='and', start=272850, end=273210, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='panel', start=273690, end=274170, confidence=0.98950195, speaker='B', channel=None), UtteranceWord(text='data.', start=274170, end=274490, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='So', start=274650, end=274890, confidence=0.97021484, speaker='B', channel=None), UtteranceWord(text='it', start=274890, end=275090, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='highly', start=275090, end=275490, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='depends', start=275490, end=276010, confidence=0.9996745, speaker='B', channel=None), UtteranceWord(text='what', start=276170, end=276450, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='type', start=276450, end=276690, confidence=0.9953613, speaker='B', channel=None), UtteranceWord(text='of', start=276690, end=276850, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='data', start=276850, end=277050, confidence=1.0, speaker='B', channel=None), UtteranceWord(text=\"you're\", start=277050, end=277410, confidence=0.8466797, speaker='B', channel=None), UtteranceWord(text='working', start=277410, end=277610, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='with,', start=277610, end=277930, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='which', start=277930, end=278290, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='model', start=278290, end=278690, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='are', start=278690, end=278850, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='we', start=278850, end=279050, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='trying', start=279050, end=279250, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='to', start=279250, end=279410, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='use', start=279410, end=279690, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='and', start=279850, end=280250, confidence=0.96435547, speaker='B', channel=None), UtteranceWord(text='accordingly,', start=280250, end=280930, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text=\"I'll\", start=280930, end=281170, confidence=0.93408203, speaker='B', channel=None), UtteranceWord(text='try', start=281170, end=281370, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='to', start=281370, end=281690, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='clean', start=281850, end=282250, confidence=0.8520508, speaker='B', channel=None), UtteranceWord(text='the', start=282250, end=282450, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='data.', start=282450, end=282730, confidence=0.99853516, speaker='B', channel=None)], translated_texts=None),\n",
       " Utterance(text='Yeah.', start=284250, end=284730, confidence=0.9064128, speaker='B', channel=None, words=[UtteranceWord(text='Yeah.', start=284250, end=284730, confidence=0.9064128, speaker='B', channel=None)], translated_texts=None),\n",
       " Utterance(text=\"Absolutely. That makes a lot of sense and I think you nailed it. It's all about the context of the data and the model you're using. There's definitely no one size fits all solution. So your approach of considering the type of data in the algorithm is spot on. All right, let's move on to another question. Suppose you're working on a project where you need to evaluate how well your ML model is performing. Could you walk me through how you would choose evaluation metrics and what metrics you might consider depending on the type of problem.\", start=288010, end=315180, confidence=0.981247, speaker='A', channel=None, words=[UtteranceWord(text='Absolutely.', start=288010, end=288730, confidence=0.99726564, speaker='A', channel=None), UtteranceWord(text='That', start=288730, end=288970, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='makes', start=288970, end=289210, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='a', start=289210, end=289370, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='lot', start=289370, end=289490, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='of', start=289490, end=289650, confidence=0.99560547, speaker='A', channel=None), UtteranceWord(text='sense', start=289650, end=290010, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='and', start=290090, end=290370, confidence=0.92822266, speaker='A', channel=None), UtteranceWord(text='I', start=290370, end=290530, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='think', start=290530, end=290690, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='you', start=290690, end=290850, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='nailed', start=290850, end=291170, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='it.', start=291170, end=291450, confidence=0.99609375, speaker='A', channel=None), UtteranceWord(text=\"It's\", start=291530, end=291930, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='all', start=291930, end=292050, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='about', start=292050, end=292210, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='the', start=292210, end=292370, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='context', start=292370, end=292770, confidence=0.9860026, speaker='A', channel=None), UtteranceWord(text='of', start=292770, end=292930, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='the', start=292930, end=293050, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='data', start=293050, end=293210, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='and', start=293210, end=293450, confidence=0.6508789, speaker='A', channel=None), UtteranceWord(text='the', start=293450, end=293610, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='model', start=293610, end=293890, confidence=0.9975586, speaker='A', channel=None), UtteranceWord(text=\"you're\", start=293890, end=294090, confidence=0.9972331, speaker='A', channel=None), UtteranceWord(text='using.', start=294090, end=294330, confidence=1.0, speaker='A', channel=None), UtteranceWord(text=\"There's\", start=294650, end=295050, confidence=0.9947917, speaker='A', channel=None), UtteranceWord(text='definitely', start=295050, end=295330, confidence=0.9772949, speaker='A', channel=None), UtteranceWord(text='no', start=295330, end=295530, confidence=0.9975586, speaker='A', channel=None), UtteranceWord(text='one', start=295530, end=295730, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='size', start=295730, end=296010, confidence=0.9851074, speaker='A', channel=None), UtteranceWord(text='fits', start=296010, end=296290, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='all', start=296290, end=296450, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='solution.', start=296450, end=296890, confidence=0.8522949, speaker='A', channel=None), UtteranceWord(text='So', start=297050, end=297370, confidence=0.9873047, speaker='A', channel=None), UtteranceWord(text='your', start=297370, end=297610, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='approach', start=297610, end=297890, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='of', start=297890, end=298130, confidence=0.9946289, speaker='A', channel=None), UtteranceWord(text='considering', start=298130, end=298530, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='the', start=298530, end=298650, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='type', start=298650, end=298810, confidence=0.9975586, speaker='A', channel=None), UtteranceWord(text='of', start=298810, end=298890, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='data', start=298890, end=299050, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='in', start=299050, end=299250, confidence=0.7294922, speaker='A', channel=None), UtteranceWord(text='the', start=299250, end=299370, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='algorithm', start=299370, end=299850, confidence=0.99990237, speaker='A', channel=None), UtteranceWord(text='is', start=299850, end=300090, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='spot', start=300090, end=300370, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='on.', start=300370, end=300650, confidence=0.9946289, speaker='A', channel=None), UtteranceWord(text='All', start=301340, end=301420, confidence=0.73828125, speaker='A', channel=None), UtteranceWord(text='right,', start=301420, end=301580, confidence=0.8354492, speaker='A', channel=None), UtteranceWord(text=\"let's\", start=301580, end=301820, confidence=0.99886066, speaker='A', channel=None), UtteranceWord(text='move', start=301820, end=301900, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='on', start=301900, end=302020, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='to', start=302020, end=302180, confidence=0.97021484, speaker='A', channel=None), UtteranceWord(text='another', start=302180, end=302420, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='question.', start=302420, end=302780, confidence=0.9946289, speaker='A', channel=None), UtteranceWord(text='Suppose', start=303100, end=303540, confidence=0.9953613, speaker='A', channel=None), UtteranceWord(text=\"you're\", start=303540, end=303780, confidence=0.94954425, speaker='A', channel=None), UtteranceWord(text='working', start=303780, end=303940, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='on', start=303940, end=304100, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='a', start=304100, end=304260, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='project', start=304260, end=304540, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='where', start=304620, end=304940, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='you', start=304940, end=305140, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='need', start=305140, end=305300, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='to', start=305300, end=305460, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='evaluate', start=305460, end=306060, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='how', start=306060, end=306300, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='well', start=306300, end=306500, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='your', start=306500, end=306660, confidence=0.9975586, speaker='A', channel=None), UtteranceWord(text='ML', start=306660, end=307060, confidence=0.99780273, speaker='A', channel=None), UtteranceWord(text='model', start=307060, end=307340, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='is', start=307340, end=307500, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='performing.', start=307500, end=308060, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='Could', start=308300, end=308580, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='you', start=308580, end=308780, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='walk', start=308780, end=308980, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='me', start=308980, end=309140, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='through', start=309140, end=309340, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='how', start=309340, end=309580, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='you', start=309580, end=309780, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='would', start=309780, end=309980, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='choose', start=309980, end=310340, confidence=0.99934894, speaker='A', channel=None), UtteranceWord(text='evaluation', start=310340, end=310940, confidence=0.92366534, speaker='A', channel=None), UtteranceWord(text='metrics', start=311020, end=311660, confidence=0.88346356, speaker='A', channel=None), UtteranceWord(text='and', start=311660, end=312060, confidence=0.8520508, speaker='A', channel=None), UtteranceWord(text='what', start=312140, end=312460, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='metrics', start=312460, end=312980, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='you', start=312980, end=313140, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='might', start=313140, end=313300, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='consider', start=313300, end=313580, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='depending', start=313900, end=314340, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='on', start=314340, end=314500, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='the', start=314500, end=314620, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='type', start=314620, end=314780, confidence=0.99731445, speaker='A', channel=None), UtteranceWord(text='of', start=314780, end=314900, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='problem.', start=314900, end=315180, confidence=0.99902344, speaker='A', channel=None)], translated_texts=None),\n",
       " Utterance(text=\"Yeah, so this also depends on what like on what type of data or what type of application I'm working with. So for example, the most common one. So most common one you can say, for example, like some regression tasks. So you are actually predict, predicting some actual value about what actual value that variable could be. So for example, for housing prices, for example, you are making a model that predicts the housing prices, giving given some features. Right. So what you do to like evaluate how well your model is performing a simple metric, is that like a simple metrics, is that that we do is like we could like we calculate the cost and cost is nothing but cumulated errors, right? But that is not a very like good metric because initially when we got the data we like split the data into two parts. So we got the training data, not two parts. It actually it is three parts. So the training data, the dev data and then the test. Right? So the best way to like evaluate it, evaluate the model you are working with is to like first define these like metrics, these cost. So for example root mean square cost. Right? So it, it measures the overall error. I'm I'm talking about the regression task. So in this case what you do is that what we do while we, we are choosing the model, we try different models and we train the model and on the training set we try to minimize the cost as much as we, we can. Right? But the problem here is the training cost error if it is minimized, if it is too much minimized, then there is chances of overfitting. Then we test it in from the test data. And here is the thing. In the test data you want the data in the test should be a production quality data. I mean the data which, on which the model is going to like be perform like like on which the model is going to work on. So in the actual production what kind of data you will get and what kind of data you are expecting the model to do well on, right? You will put that data into the test data so test set and you will check the errors or root mean square error. How much error is the model giving on that set? So that is how you'll know that how well the model is generalized, right? So this is the, in the case of regression task, for example you get classification task. In the case of classification task it is very tough, not very tough. But the thing is you can't just check if it is correct or non correct, right? Because if the data set is skewed so you know the 70% of the data is like it is a classification task. So for example you are testing if the patient has a heart disease or not. And the data set actually has 70% patients which have like diseases and they have heart disease. So if the model just predicts all to. If the model just predicts that all have heart disease still it got, it gets 70% accuracy, right? So we don't want that. So so here we, what we do is that we like we calculate this confusion matrix and what this confusion matrix gives us is that we, what we do is that we calculate false positive like false negatives true positive, true negatives. And then we calculate recall precision and F1 score. So recall precision. These are very like important metrics, especially for the classification tasks. And they actually tell you, precision tells you how much, like how much correct answer is. It gives for the answer which were actually correct. Correct. Right. So these are some of the metrics that, that I would use. And there are all like. There are also multiple metrics, new metrics for multiple applications. You can actually, if I, if I'm like, like for certain applications, I can also like go through or custom, like I'll, I'll try to create some custom matrix, like matrix, not like matrix on which I'll test the system. So it also highly depends on what type of application I'm working with. Yeah. And what type of model I'm working with. Yeah.\", start=317580, end=597500, confidence=0.96937436, speaker='B', channel=None, words=[UtteranceWord(text='Yeah,', start=317580, end=318060, confidence=0.9667969, speaker='B', channel=None), UtteranceWord(text='so', start=318060, end=318460, confidence=0.8666992, speaker='B', channel=None), UtteranceWord(text='this', start=319100, end=319420, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='also', start=319420, end=319700, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='depends', start=319700, end=320340, confidence=0.9996745, speaker='B', channel=None), UtteranceWord(text='on', start=320340, end=320700, confidence=0.91503906, speaker='B', channel=None), UtteranceWord(text='what', start=320860, end=321260, confidence=0.73046875, speaker='B', channel=None), UtteranceWord(text='like', start=321820, end=322220, confidence=0.96191406, speaker='B', channel=None), UtteranceWord(text='on', start=322380, end=322700, confidence=0.9321289, speaker='B', channel=None), UtteranceWord(text='what', start=322700, end=322980, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='type', start=322980, end=323300, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='of', start=323300, end=323580, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data', start=323980, end=324340, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='or', start=324340, end=324580, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='what', start=324580, end=324780, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='type', start=324780, end=325180, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='of', start=325420, end=325740, confidence=0.9741211, speaker='B', channel=None), UtteranceWord(text='application', start=325740, end=326220, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=326220, end=326500, confidence=0.86279297, speaker='B', channel=None), UtteranceWord(text='working', start=326500, end=326700, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='with.', start=326700, end=327020, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='So', start=327260, end=327540, confidence=0.9873047, speaker='B', channel=None), UtteranceWord(text='for', start=327540, end=327700, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='example,', start=327700, end=328100, confidence=0.87402344, speaker='B', channel=None), UtteranceWord(text='the', start=328100, end=328340, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='most', start=328340, end=328580, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='common', start=328580, end=328940, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='one.', start=328940, end=329260, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='So', start=329670, end=329790, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='most', start=329790, end=329990, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='common', start=329990, end=330310, confidence=0.765625, speaker='B', channel=None), UtteranceWord(text='one', start=330310, end=330510, confidence=0.7392578, speaker='B', channel=None), UtteranceWord(text='you', start=330510, end=330670, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='can', start=330670, end=330870, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='say,', start=330870, end=331150, confidence=0.98535156, speaker='B', channel=None), UtteranceWord(text='for', start=331150, end=331430, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='example,', start=331430, end=332070, confidence=0.9938151, speaker='B', channel=None), UtteranceWord(text='like', start=333350, end=333670, confidence=0.94433594, speaker='B', channel=None), UtteranceWord(text='some', start=333670, end=333870, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='regression', start=333870, end=334390, confidence=0.9921875, speaker='B', channel=None), UtteranceWord(text='tasks.', start=334390, end=334870, confidence=0.97314453, speaker='B', channel=None), UtteranceWord(text='So', start=334870, end=335190, confidence=0.9604492, speaker='B', channel=None), UtteranceWord(text='you', start=335190, end=335390, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='are', start=335390, end=335590, confidence=0.97558594, speaker='B', channel=None), UtteranceWord(text='actually', start=335590, end=335870, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='predict,', start=335870, end=336390, confidence=0.8614909, speaker='B', channel=None), UtteranceWord(text='predicting', start=336630, end=337230, confidence=0.97998047, speaker='B', channel=None), UtteranceWord(text='some', start=337230, end=337590, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='actual', start=337590, end=338070, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='value', start=338070, end=338390, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='about', start=338710, end=339110, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='what', start=339110, end=339470, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='actual', start=339470, end=339830, confidence=0.984375, speaker='B', channel=None), UtteranceWord(text='value', start=339830, end=340150, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that', start=341350, end=341750, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='variable', start=341830, end=342350, confidence=0.91064453, speaker='B', channel=None), UtteranceWord(text='could', start=342350, end=342630, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='be.', start=342630, end=342950, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='So', start=343270, end=343590, confidence=0.98339844, speaker='B', channel=None), UtteranceWord(text='for', start=343590, end=343790, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='example,', start=343790, end=344230, confidence=0.9557292, speaker='B', channel=None), UtteranceWord(text='for', start=344230, end=344430, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='housing', start=344430, end=344750, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='prices,', start=344750, end=345110, confidence=0.9802246, speaker='B', channel=None), UtteranceWord(text='for', start=345110, end=345270, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='example,', start=345270, end=345629, confidence=0.91520184, speaker='B', channel=None), UtteranceWord(text='you', start=345629, end=345790, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='are', start=345790, end=345950, confidence=0.9824219, speaker='B', channel=None), UtteranceWord(text='making', start=345950, end=346190, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='a', start=346190, end=346550, confidence=0.9916992, speaker='B', channel=None), UtteranceWord(text='model', start=347110, end=347750, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='that', start=348630, end=348990, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='predicts', start=348990, end=349430, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='the', start=349430, end=349550, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='housing', start=349550, end=349950, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='prices,', start=349950, end=350270, confidence=0.9560547, speaker='B', channel=None), UtteranceWord(text='giving', start=350270, end=350630, confidence=0.8569336, speaker='B', channel=None), UtteranceWord(text='given', start=350630, end=350990, confidence=0.97558594, speaker='B', channel=None), UtteranceWord(text='some', start=350990, end=351230, confidence=0.98046875, speaker='B', channel=None), UtteranceWord(text='features.', start=351230, end=351670, confidence=0.96972656, speaker='B', channel=None), UtteranceWord(text='Right.', start=351670, end=351990, confidence=0.94189453, speaker='B', channel=None), UtteranceWord(text='So', start=352310, end=352710, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='what', start=352790, end=353070, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='you', start=353070, end=353350, confidence=0.87158203, speaker='B', channel=None), UtteranceWord(text='do', start=353350, end=353750, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='to', start=354710, end=354990, confidence=0.9873047, speaker='B', channel=None), UtteranceWord(text='like', start=354990, end=355230, confidence=0.77490234, speaker='B', channel=None), UtteranceWord(text='evaluate', start=355230, end=355910, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='how', start=356460, end=356660, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='well', start=356660, end=356900, confidence=0.9848633, speaker='B', channel=None), UtteranceWord(text='your', start=356900, end=357180, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='model', start=357180, end=357620, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='is', start=357620, end=357820, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='performing', start=357820, end=358460, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='a', start=358540, end=358820, confidence=0.99365234, speaker='B', channel=None), UtteranceWord(text='simple', start=358820, end=359260, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='metric,', start=359260, end=359660, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='is', start=359660, end=359900, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='that', start=359900, end=360220, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='like', start=360700, end=361100, confidence=0.9873047, speaker='B', channel=None), UtteranceWord(text='a', start=361180, end=361460, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='simple', start=361460, end=361780, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='metrics,', start=361780, end=362300, confidence=0.7519531, speaker='B', channel=None), UtteranceWord(text='is', start=362460, end=362780, confidence=0.8144531, speaker='B', channel=None), UtteranceWord(text='that', start=362780, end=363100, confidence=0.7055664, speaker='B', channel=None), UtteranceWord(text='that', start=364380, end=364660, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='we', start=364660, end=364860, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='do', start=364860, end=365180, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='is', start=365260, end=365580, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='like', start=365580, end=365780, confidence=0.97998047, speaker='B', channel=None), UtteranceWord(text='we', start=365780, end=365940, confidence=0.9350586, speaker='B', channel=None), UtteranceWord(text='could', start=365940, end=366220, confidence=0.5834961, speaker='B', channel=None), UtteranceWord(text='like', start=366380, end=366780, confidence=0.9760742, speaker='B', channel=None), UtteranceWord(text='we', start=366780, end=367060, confidence=0.99365234, speaker='B', channel=None), UtteranceWord(text='calculate', start=367060, end=367540, confidence=0.9897461, speaker='B', channel=None), UtteranceWord(text='the', start=367540, end=367780, confidence=0.9819336, speaker='B', channel=None), UtteranceWord(text='cost', start=367780, end=368100, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='and', start=368100, end=368380, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='cost', start=368380, end=368660, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='is', start=368660, end=368900, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='nothing', start=368900, end=369140, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='but', start=369140, end=369340, confidence=0.9667969, speaker='B', channel=None), UtteranceWord(text='cumulated', start=369340, end=369980, confidence=0.92126465, speaker='B', channel=None), UtteranceWord(text='errors,', start=369980, end=370500, confidence=0.9397461, speaker='B', channel=None), UtteranceWord(text='right?', start=370500, end=370860, confidence=0.9316406, speaker='B', channel=None), UtteranceWord(text='But', start=371100, end=371500, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that', start=371740, end=372020, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=372020, end=372219, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='not', start=372219, end=372419, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='a', start=372419, end=372540, confidence=0.98828125, speaker='B', channel=None), UtteranceWord(text='very', start=372540, end=372780, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='like', start=372860, end=373260, confidence=0.9238281, speaker='B', channel=None), UtteranceWord(text='good', start=373660, end=374060, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='metric', start=374140, end=374660, confidence=0.99487305, speaker='B', channel=None), UtteranceWord(text='because', start=374660, end=375020, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='initially', start=375340, end=375900, confidence=0.90844727, speaker='B', channel=None), UtteranceWord(text='when', start=375980, end=376260, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='we', start=376260, end=376420, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='got', start=376420, end=376660, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=376660, end=376900, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data', start=376900, end=377180, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='we', start=377260, end=377580, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='like', start=377580, end=377900, confidence=0.9423828, speaker='B', channel=None), UtteranceWord(text='split', start=377900, end=378460, confidence=0.9379883, speaker='B', channel=None), UtteranceWord(text='the', start=378460, end=378660, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='data', start=378660, end=378940, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='into', start=378940, end=379300, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='two', start=379300, end=379540, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='parts.', start=379540, end=379980, confidence=0.9987793, speaker='B', channel=None), UtteranceWord(text='So', start=380060, end=380340, confidence=0.81103516, speaker='B', channel=None), UtteranceWord(text='we', start=380340, end=380500, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='got', start=380500, end=380740, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='the', start=380740, end=381020, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='training', start=381020, end=381380, confidence=0.99780273, speaker='B', channel=None), UtteranceWord(text='data,', start=381380, end=381740, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='not', start=381820, end=382140, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='two', start=382140, end=382340, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='parts.', start=382340, end=382660, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='It', start=382660, end=382900, confidence=0.62060547, speaker='B', channel=None), UtteranceWord(text='actually', start=382900, end=383220, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='it', start=383220, end=383460, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='is', start=383460, end=383740, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='three', start=383740, end=384060, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='parts.', start=384060, end=384540, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='So', start=385340, end=385660, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='the', start=385660, end=385860, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='training', start=385860, end=386180, confidence=0.9189453, speaker='B', channel=None), UtteranceWord(text='data,', start=386180, end=386500, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='the', start=386500, end=386740, confidence=0.98535156, speaker='B', channel=None), UtteranceWord(text='dev', start=386740, end=386980, confidence=0.99072266, speaker='B', channel=None), UtteranceWord(text='data', start=386980, end=387220, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='and', start=387220, end=387380, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='then', start=387380, end=387500, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='the', start=387500, end=387620, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='test.', start=387620, end=387900, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='Right?', start=388360, end=388600, confidence=0.9760742, speaker='B', channel=None), UtteranceWord(text='So', start=388840, end=389120, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='the', start=389120, end=389280, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='best', start=389280, end=389520, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='way', start=389520, end=389800, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='to', start=389800, end=390120, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='like', start=390440, end=390800, confidence=0.94384766, speaker='B', channel=None), UtteranceWord(text='evaluate', start=390800, end=391440, confidence=0.99780273, speaker='B', channel=None), UtteranceWord(text='it,', start=391440, end=391680, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='evaluate', start=391680, end=392240, confidence=0.9991455, speaker='B', channel=None), UtteranceWord(text='the', start=392240, end=392400, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='model', start=392400, end=392840, confidence=0.79589844, speaker='B', channel=None), UtteranceWord(text='you', start=393080, end=393360, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='are', start=393360, end=393520, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='working', start=393520, end=393720, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='with', start=393720, end=394040, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='is', start=394120, end=394440, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='to', start=394440, end=394640, confidence=0.99365234, speaker='B', channel=None), UtteranceWord(text='like', start=394640, end=394840, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='first', start=394840, end=395080, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='define', start=395080, end=395480, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='these', start=395480, end=395760, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='like', start=395760, end=396080, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='metrics,', start=396080, end=396760, confidence=0.99072266, speaker='B', channel=None), UtteranceWord(text='these', start=397160, end=397560, confidence=0.9736328, speaker='B', channel=None), UtteranceWord(text='cost.', start=397560, end=397960, confidence=0.5307617, speaker='B', channel=None), UtteranceWord(text='So', start=398440, end=398720, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='for', start=398720, end=398880, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='example', start=398880, end=399280, confidence=0.90527344, speaker='B', channel=None), UtteranceWord(text='root', start=399280, end=399600, confidence=0.9772949, speaker='B', channel=None), UtteranceWord(text='mean', start=399600, end=399800, confidence=0.88623047, speaker='B', channel=None), UtteranceWord(text='square', start=399800, end=400200, confidence=0.97249347, speaker='B', channel=None), UtteranceWord(text='cost.', start=400200, end=400520, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='Right?', start=400600, end=401000, confidence=0.98876953, speaker='B', channel=None), UtteranceWord(text='So', start=401320, end=401560, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='it,', start=401560, end=401800, confidence=0.96533203, speaker='B', channel=None), UtteranceWord(text='it', start=401800, end=402120, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='measures', start=402120, end=402480, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=402480, end=402640, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='overall', start=402640, end=403000, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='error.', start=403000, end=403480, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=403480, end=403880, confidence=0.77734375, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=403880, end=404200, confidence=0.9148763, speaker='B', channel=None), UtteranceWord(text='talking', start=404200, end=404440, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='about', start=404440, end=404600, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=404600, end=404800, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='regression', start=404800, end=405360, confidence=0.8531901, speaker='B', channel=None), UtteranceWord(text='task.', start=405360, end=405800, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='So', start=406200, end=406440, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='in', start=406440, end=406560, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='this', start=406560, end=406800, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='case', start=406800, end=407160, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='what', start=407480, end=407800, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='you', start=407800, end=408040, confidence=0.98828125, speaker='B', channel=None), UtteranceWord(text='do', start=408040, end=408360, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=408600, end=408920, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that', start=408920, end=409240, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='what', start=409560, end=409880, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='we', start=409880, end=410080, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='do', start=410080, end=410280, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='while', start=410280, end=410560, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='we,', start=410560, end=410880, confidence=0.5888672, speaker='B', channel=None), UtteranceWord(text='we', start=410880, end=411120, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='are', start=411120, end=411280, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='choosing', start=411280, end=411560, confidence=0.9355469, speaker='B', channel=None), UtteranceWord(text='the', start=411560, end=411720, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='model,', start=411720, end=412080, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='we', start=412080, end=412280, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='try', start=412280, end=412440, confidence=0.9316406, speaker='B', channel=None), UtteranceWord(text='different', start=412440, end=412760, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='models', start=412760, end=413280, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='and', start=413280, end=413520, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='we', start=413520, end=413800, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='train', start=414170, end=414330, confidence=0.93408203, speaker='B', channel=None), UtteranceWord(text='the', start=414330, end=414450, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='model', start=414450, end=414890, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='and', start=414970, end=415250, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='on', start=415250, end=415410, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='the', start=415410, end=415570, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='training', start=415570, end=415850, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='set', start=415850, end=416170, confidence=0.5654297, speaker='B', channel=None), UtteranceWord(text='we', start=416250, end=416650, confidence=0.77685547, speaker='B', channel=None), UtteranceWord(text='try', start=416730, end=417050, confidence=0.9819336, speaker='B', channel=None), UtteranceWord(text='to', start=417050, end=417250, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='minimize', start=417250, end=417730, confidence=0.9978841, speaker='B', channel=None), UtteranceWord(text='the', start=417730, end=417890, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='cost', start=417890, end=418130, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='as', start=418130, end=418410, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='much', start=418410, end=418610, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='as', start=418610, end=418770, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='we,', start=418770, end=419050, confidence=0.79785156, speaker='B', channel=None), UtteranceWord(text='we', start=419290, end=419610, confidence=0.94921875, speaker='B', channel=None), UtteranceWord(text='can.', start=419610, end=419890, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='Right?', start=419890, end=420250, confidence=0.91796875, speaker='B', channel=None), UtteranceWord(text='But', start=420330, end=420650, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='the', start=420650, end=420850, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='problem', start=420850, end=421090, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='here', start=421090, end=421370, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='is', start=421370, end=421690, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='the', start=422330, end=422650, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='training', start=422650, end=422970, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='cost', start=422970, end=423250, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='error', start=423250, end=423610, confidence=0.9727783, speaker='B', channel=None), UtteranceWord(text='if', start=423610, end=423810, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='it', start=423810, end=423930, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='is', start=423930, end=424090, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='minimized,', start=424090, end=424650, confidence=0.9353841, speaker='B', channel=None), UtteranceWord(text='if', start=424650, end=424810, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='it', start=424810, end=424930, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=424930, end=425090, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='too', start=425090, end=425250, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='much', start=425250, end=425450, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='minimized,', start=425450, end=426010, confidence=0.8330078, speaker='B', channel=None), UtteranceWord(text='then', start=426010, end=426290, confidence=0.98339844, speaker='B', channel=None), UtteranceWord(text='there', start=426290, end=426530, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=426530, end=426690, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='chances', start=426690, end=426970, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='of', start=426970, end=427170, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='overfitting.', start=427170, end=427930, confidence=0.8864746, speaker='B', channel=None), UtteranceWord(text='Then', start=428170, end=428450, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='we', start=428450, end=428650, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='test', start=428650, end=428930, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='it', start=428930, end=429290, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='in', start=429450, end=429850, confidence=0.9135742, speaker='B', channel=None), UtteranceWord(text='from', start=429850, end=430129, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=430129, end=430289, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='test', start=430289, end=430530, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data.', start=430530, end=430890, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='And', start=430890, end=431290, confidence=0.99365234, speaker='B', channel=None), UtteranceWord(text='here', start=431450, end=431770, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='is', start=431770, end=431970, confidence=0.96191406, speaker='B', channel=None), UtteranceWord(text='the', start=431970, end=432130, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='thing.', start=432130, end=432410, confidence=0.98583984, speaker='B', channel=None), UtteranceWord(text='In', start=432410, end=432690, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=432690, end=432850, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='test', start=432850, end=433090, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data', start=433090, end=433450, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='you', start=433610, end=433930, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='want', start=433930, end=434210, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='the', start=434210, end=434450, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='data', start=434450, end=434690, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='in', start=434690, end=434890, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='the', start=434890, end=435010, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='test', start=435010, end=435290, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='should', start=435530, end=435810, confidence=0.94433594, speaker='B', channel=None), UtteranceWord(text='be', start=435810, end=436010, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='a', start=436010, end=436210, confidence=0.9897461, speaker='B', channel=None), UtteranceWord(text='production', start=436210, end=436650, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='quality', start=436650, end=437050, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='data.', start=437050, end=437370, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='I', start=437690, end=438050, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='mean', start=438050, end=438410, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=438570, end=438890, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='data', start=438890, end=439210, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='which,', start=439290, end=439690, confidence=0.95166016, speaker='B', channel=None), UtteranceWord(text='on', start=439770, end=440090, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='which', start=440090, end=440370, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=440370, end=440610, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='model', start=440610, end=440930, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='is', start=440930, end=441090, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='going', start=441090, end=441290, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='to', start=441290, end=441610, confidence=0.9897461, speaker='B', channel=None), UtteranceWord(text='like', start=442190, end=442430, confidence=0.94628906, speaker='B', channel=None), UtteranceWord(text='be', start=442750, end=443150, confidence=0.7685547, speaker='B', channel=None), UtteranceWord(text='perform', start=443230, end=443630, confidence=0.5151367, speaker='B', channel=None), UtteranceWord(text='like', start=443710, end=444110, confidence=0.9873047, speaker='B', channel=None), UtteranceWord(text='like', start=444670, end=445030, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='on', start=445030, end=445270, confidence=0.99121094, speaker='B', channel=None), UtteranceWord(text='which', start=445270, end=445550, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='the', start=445550, end=445830, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='model', start=445830, end=446150, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='is', start=446150, end=446310, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='going', start=446310, end=446470, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='to', start=446470, end=446630, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='work', start=446630, end=446830, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='on.', start=446830, end=447150, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='So', start=447390, end=447630, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='in', start=447630, end=447710, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='the', start=447710, end=447830, confidence=0.98828125, speaker='B', channel=None), UtteranceWord(text='actual', start=447830, end=448110, confidence=0.9831543, speaker='B', channel=None), UtteranceWord(text='production', start=448110, end=448750, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='what', start=448910, end=449230, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='kind', start=449230, end=449430, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='of', start=449430, end=449590, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data', start=449590, end=449830, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='you', start=449830, end=450070, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='will', start=450070, end=450230, confidence=0.5415039, speaker='B', channel=None), UtteranceWord(text='get', start=450230, end=450470, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='and', start=450470, end=450790, confidence=0.8808594, speaker='B', channel=None), UtteranceWord(text='what', start=450790, end=451070, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='kind', start=451070, end=451270, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='of', start=451270, end=451430, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='data', start=451430, end=451630, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='you', start=451630, end=451830, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='are', start=451830, end=452030, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='expecting', start=452030, end=452590, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=452590, end=452870, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='model', start=452870, end=453270, confidence=0.9987793, speaker='B', channel=None), UtteranceWord(text='to', start=453270, end=453550, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='do', start=453790, end=454110, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='well', start=454110, end=454310, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='on,', start=454310, end=454510, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='right?', start=454510, end=454830, confidence=0.9863281, speaker='B', channel=None), UtteranceWord(text='You', start=454910, end=455190, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='will', start=455190, end=455390, confidence=0.98828125, speaker='B', channel=None), UtteranceWord(text='put', start=455390, end=455630, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that', start=455630, end=455870, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='data', start=455870, end=456150, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='into', start=456150, end=456430, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=456430, end=456630, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='test', start=456630, end=456870, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data', start=456870, end=457230, confidence=0.9902344, speaker='B', channel=None), UtteranceWord(text='so', start=458110, end=458390, confidence=0.94628906, speaker='B', channel=None), UtteranceWord(text='test', start=458390, end=458590, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='set', start=458590, end=458910, confidence=0.71777344, speaker='B', channel=None), UtteranceWord(text='and', start=459070, end=459390, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='you', start=459390, end=459630, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='will', start=459630, end=459950, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='check', start=459950, end=460430, confidence=0.9255371, speaker='B', channel=None), UtteranceWord(text='the', start=460830, end=461230, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='errors', start=461630, end=462270, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='or', start=462270, end=462590, confidence=0.97509766, speaker='B', channel=None), UtteranceWord(text='root', start=462590, end=462910, confidence=0.97802734, speaker='B', channel=None), UtteranceWord(text='mean', start=462910, end=463110, confidence=0.94140625, speaker='B', channel=None), UtteranceWord(text='square', start=463110, end=463470, confidence=0.8616536, speaker='B', channel=None), UtteranceWord(text='error.', start=463470, end=463950, confidence=0.9986572, speaker='B', channel=None), UtteranceWord(text='How', start=464030, end=464310, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='much', start=464310, end=464510, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='error', start=464510, end=464990, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='is', start=464990, end=465270, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='the', start=465270, end=465470, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='model', start=465470, end=465950, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='giving', start=465950, end=466390, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='on', start=466390, end=466670, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that', start=466670, end=466950, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='set?', start=466950, end=467310, confidence=0.9873047, speaker='B', channel=None), UtteranceWord(text='So', start=468140, end=468380, confidence=0.98095703, speaker='B', channel=None), UtteranceWord(text='that', start=468380, end=468700, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=468700, end=468900, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='how', start=468900, end=469100, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text=\"you'll\", start=469100, end=469460, confidence=0.8380534, speaker='B', channel=None), UtteranceWord(text='know', start=469460, end=469740, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that', start=469740, end=470060, confidence=0.9892578, speaker='B', channel=None), UtteranceWord(text='how', start=470060, end=470340, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='well', start=470340, end=470580, confidence=0.9916992, speaker='B', channel=None), UtteranceWord(text='the', start=470580, end=470860, confidence=0.9897461, speaker='B', channel=None), UtteranceWord(text='model', start=471180, end=471620, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='is', start=471620, end=471900, confidence=0.33666992, speaker='B', channel=None), UtteranceWord(text='generalized,', start=471900, end=472700, confidence=0.9326172, speaker='B', channel=None), UtteranceWord(text='right?', start=472700, end=473100, confidence=0.97265625, speaker='B', channel=None), UtteranceWord(text='So', start=473260, end=473580, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='this', start=473580, end=473780, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='is', start=473780, end=473900, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='the,', start=473900, end=474100, confidence=0.9482422, speaker='B', channel=None), UtteranceWord(text='in', start=474100, end=474340, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='the', start=474340, end=474500, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='case', start=474500, end=474660, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='of', start=474660, end=474860, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='regression', start=474860, end=475420, confidence=0.86653644, speaker='B', channel=None), UtteranceWord(text='task,', start=475420, end=475820, confidence=0.8982747, speaker='B', channel=None), UtteranceWord(text='for', start=475820, end=476020, confidence=0.98583984, speaker='B', channel=None), UtteranceWord(text='example', start=476020, end=476420, confidence=0.9998372, speaker='B', channel=None), UtteranceWord(text='you', start=476420, end=476580, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='get', start=476580, end=476860, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='classification', start=476860, end=477740, confidence=0.9998372, speaker='B', channel=None), UtteranceWord(text='task.', start=477740, end=478220, confidence=0.94873047, speaker='B', channel=None), UtteranceWord(text='In', start=478300, end=478540, confidence=0.9892578, speaker='B', channel=None), UtteranceWord(text='the', start=478540, end=478660, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='case', start=478660, end=478820, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='of', start=478820, end=478980, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='classification', start=478980, end=479700, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='task', start=479700, end=480060, confidence=0.93880206, speaker='B', channel=None), UtteranceWord(text='it', start=480060, end=480260, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='is', start=480260, end=480420, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='very', start=480420, end=480620, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='tough,', start=480620, end=481020, confidence=0.89127606, speaker='B', channel=None), UtteranceWord(text='not', start=481260, end=481580, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='very', start=481580, end=481820, confidence=0.70214844, speaker='B', channel=None), UtteranceWord(text='tough.', start=481820, end=482100, confidence=0.9659831, speaker='B', channel=None), UtteranceWord(text='But', start=482100, end=482300, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='the', start=482300, end=482500, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='thing', start=482500, end=482700, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='is', start=482700, end=482900, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='you', start=482900, end=483060, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text=\"can't\", start=483060, end=483300, confidence=0.96028644, speaker='B', channel=None), UtteranceWord(text='just', start=483300, end=483580, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='check', start=484300, end=484620, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='if', start=484620, end=484780, confidence=0.9145508, speaker='B', channel=None), UtteranceWord(text='it', start=484780, end=484980, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='is', start=484980, end=485220, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='correct', start=485220, end=485700, confidence=0.99934894, speaker='B', channel=None), UtteranceWord(text='or', start=485700, end=486060, confidence=0.9760742, speaker='B', channel=None), UtteranceWord(text='non', start=486460, end=486780, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='correct,', start=486780, end=487260, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='right?', start=487260, end=487660, confidence=0.94384766, speaker='B', channel=None), UtteranceWord(text='Because', start=487820, end=488220, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='if', start=488460, end=488860, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='the', start=489260, end=489540, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='data', start=489540, end=489780, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='set', start=489780, end=490060, confidence=0.95166016, speaker='B', channel=None), UtteranceWord(text='is', start=490060, end=490260, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='skewed', start=490260, end=490860, confidence=0.79003906, speaker='B', channel=None), UtteranceWord(text='so', start=490860, end=491140, confidence=0.9765625, speaker='B', channel=None), UtteranceWord(text='you', start=491140, end=491300, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='know', start=491300, end=491540, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=491540, end=491820, confidence=0.7314453, speaker='B', channel=None), UtteranceWord(text='70%', start=491820, end=492420, confidence=0.98096, speaker='B', channel=None), UtteranceWord(text='of', start=492420, end=492660, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='the', start=492660, end=492820, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='data', start=492820, end=493100, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=493100, end=493500, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='like', start=493500, end=493900, confidence=0.9873047, speaker='B', channel=None), UtteranceWord(text='it', start=494460, end=494740, confidence=0.9916992, speaker='B', channel=None), UtteranceWord(text='is', start=494740, end=494900, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='a', start=494900, end=495060, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='classification', start=495060, end=495740, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='task.', start=495740, end=496140, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='So', start=496140, end=496460, confidence=0.92871094, speaker='B', channel=None), UtteranceWord(text='for', start=496620, end=496900, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='example', start=496900, end=497260, confidence=0.91796875, speaker='B', channel=None), UtteranceWord(text='you', start=497260, end=497460, confidence=0.9863281, speaker='B', channel=None), UtteranceWord(text='are', start=497460, end=497580, confidence=0.98583984, speaker='B', channel=None), UtteranceWord(text='testing', start=497580, end=497980, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='if', start=498300, end=498580, confidence=0.9692383, speaker='B', channel=None), UtteranceWord(text='the', start=498580, end=498740, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='patient', start=498740, end=499020, confidence=0.9423828, speaker='B', channel=None), UtteranceWord(text='has', start=499020, end=499220, confidence=0.9824219, speaker='B', channel=None), UtteranceWord(text='a', start=499220, end=499410, confidence=0.5136719, speaker='B', channel=None), UtteranceWord(text='heart', start=499560, end=499720, confidence=0.9824219, speaker='B', channel=None), UtteranceWord(text='disease', start=499720, end=500200, confidence=0.9996745, speaker='B', channel=None), UtteranceWord(text='or', start=500200, end=500520, confidence=0.99609375, speaker='B', channel=None), UtteranceWord(text='not.', start=500520, end=500840, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='And', start=501160, end=501440, confidence=0.9892578, speaker='B', channel=None), UtteranceWord(text='the', start=501440, end=501600, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='data', start=501600, end=501840, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='set', start=501840, end=502120, confidence=0.96875, speaker='B', channel=None), UtteranceWord(text='actually', start=502120, end=502400, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='has', start=502400, end=502680, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='70%', start=502680, end=503280, confidence=0.91626, speaker='B', channel=None), UtteranceWord(text='patients', start=503280, end=503760, confidence=0.9938965, speaker='B', channel=None), UtteranceWord(text='which', start=503760, end=504040, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='have', start=504040, end=504360, confidence=0.99365234, speaker='B', channel=None), UtteranceWord(text='like', start=505240, end=505600, confidence=0.6777344, speaker='B', channel=None), UtteranceWord(text='diseases', start=505600, end=506120, confidence=0.9816081, speaker='B', channel=None), UtteranceWord(text='and', start=506360, end=506760, confidence=0.7006836, speaker='B', channel=None), UtteranceWord(text='they', start=506840, end=507120, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='have', start=507120, end=507400, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='heart', start=507960, end=508280, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='disease.', start=508280, end=508680, confidence=0.80843097, speaker='B', channel=None), UtteranceWord(text='So', start=509000, end=509400, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='if', start=509400, end=509680, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='the', start=509680, end=509840, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='model', start=509840, end=510160, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='just', start=510160, end=510360, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='predicts', start=510360, end=510920, confidence=0.99731445, speaker='B', channel=None), UtteranceWord(text='all', start=511080, end=511480, confidence=0.9794922, speaker='B', channel=None), UtteranceWord(text='to.', start=511480, end=511880, confidence=0.62646484, speaker='B', channel=None), UtteranceWord(text='If', start=511960, end=512240, confidence=0.9638672, speaker='B', channel=None), UtteranceWord(text='the', start=512240, end=512400, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='model', start=512400, end=512800, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='just', start=512800, end=513040, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='predicts', start=513040, end=513440, confidence=0.97888184, speaker='B', channel=None), UtteranceWord(text='that', start=513440, end=513600, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='all', start=513600, end=513800, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='have', start=513800, end=514120, confidence=0.77685547, speaker='B', channel=None), UtteranceWord(text='heart', start=514120, end=514440, confidence=0.94921875, speaker='B', channel=None), UtteranceWord(text='disease', start=514440, end=514840, confidence=0.9864909, speaker='B', channel=None), UtteranceWord(text='still', start=514840, end=515040, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='it', start=515040, end=515240, confidence=0.89208984, speaker='B', channel=None), UtteranceWord(text='got,', start=515240, end=515560, confidence=0.71240234, speaker='B', channel=None), UtteranceWord(text='it', start=515720, end=516000, confidence=0.9790039, speaker='B', channel=None), UtteranceWord(text='gets', start=516000, end=516360, confidence=0.9916992, speaker='B', channel=None), UtteranceWord(text='70%', start=516360, end=517000, confidence=0.93311, speaker='B', channel=None), UtteranceWord(text='accuracy,', start=517640, end=518240, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='right?', start=518240, end=518600, confidence=0.9892578, speaker='B', channel=None), UtteranceWord(text='So', start=518600, end=518880, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='we', start=518880, end=519040, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text=\"don't\", start=519040, end=519320, confidence=0.9983724, speaker='B', channel=None), UtteranceWord(text='want', start=519320, end=519600, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that.', start=519600, end=519960, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='So', start=520600, end=521000, confidence=0.70410156, speaker='B', channel=None), UtteranceWord(text='so', start=521080, end=521360, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='here', start=521360, end=521600, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='we,', start=521600, end=521920, confidence=0.9794922, speaker='B', channel=None), UtteranceWord(text='what', start=521920, end=522160, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='we', start=522160, end=522360, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='do', start=522360, end=522600, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='is', start=522600, end=522800, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that', start=522800, end=523000, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='we', start=523000, end=523320, confidence=0.99072266, speaker='B', channel=None), UtteranceWord(text='like', start=523480, end=523880, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='we', start=524200, end=524560, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='calculate', start=524560, end=525160, confidence=0.96643066, speaker='B', channel=None), UtteranceWord(text='this', start=525160, end=525400, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='confusion', start=525400, end=526000, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='matrix', start=526000, end=526400, confidence=0.9996338, speaker='B', channel=None), UtteranceWord(text='and', start=526400, end=526560, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='what', start=526560, end=526760, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='this', start=526760, end=527080, confidence=0.7998047, speaker='B', channel=None), UtteranceWord(text='confusion', start=527160, end=527800, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='matrix', start=527800, end=528280, confidence=0.9436035, speaker='B', channel=None), UtteranceWord(text='gives', start=528440, end=528880, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='us', start=528880, end=529160, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='is', start=529320, end=529640, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='that', start=529640, end=529960, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='we,', start=530730, end=530970, confidence=0.7763672, speaker='B', channel=None), UtteranceWord(text='what', start=531850, end=532130, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='we', start=532130, end=532290, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='do', start=532290, end=532450, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='is', start=532450, end=532650, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='that', start=532650, end=532850, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='we', start=532850, end=533090, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='calculate', start=533090, end=533690, confidence=0.9786377, speaker='B', channel=None), UtteranceWord(text='false', start=533690, end=534050, confidence=0.9943034, speaker='B', channel=None), UtteranceWord(text='positive', start=534050, end=534490, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='like', start=534890, end=535290, confidence=0.9819336, speaker='B', channel=None), UtteranceWord(text='false', start=535370, end=535770, confidence=0.87386066, speaker='B', channel=None), UtteranceWord(text='negatives', start=535770, end=536490, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='true', start=536970, end=537330, confidence=0.99780273, speaker='B', channel=None), UtteranceWord(text='positive,', start=537330, end=537730, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='true', start=537730, end=538050, confidence=0.9953613, speaker='B', channel=None), UtteranceWord(text='negatives.', start=538050, end=538650, confidence=0.99397784, speaker='B', channel=None), UtteranceWord(text='And', start=538650, end=539050, confidence=0.9897461, speaker='B', channel=None), UtteranceWord(text='then', start=539050, end=539410, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='we', start=539410, end=539650, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='calculate', start=539650, end=540170, confidence=0.96276855, speaker='B', channel=None), UtteranceWord(text='recall', start=540170, end=540730, confidence=0.9433594, speaker='B', channel=None), UtteranceWord(text='precision', start=540890, end=541530, confidence=0.99869794, speaker='B', channel=None), UtteranceWord(text='and', start=541690, end=542090, confidence=0.7060547, speaker='B', channel=None), UtteranceWord(text='F1', start=542570, end=543210, confidence=0.99731, speaker='B', channel=None), UtteranceWord(text='score.', start=543210, end=543690, confidence=0.99731445, speaker='B', channel=None), UtteranceWord(text='So', start=544170, end=544570, confidence=0.9736328, speaker='B', channel=None), UtteranceWord(text='recall', start=544570, end=545130, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='precision.', start=545130, end=545650, confidence=0.8486328, speaker='B', channel=None), UtteranceWord(text='These', start=545650, end=545890, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='are', start=545890, end=546170, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='very', start=546250, end=546650, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='like', start=546650, end=547050, confidence=0.9238281, speaker='B', channel=None), UtteranceWord(text='important', start=547130, end=547530, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='metrics,', start=547610, end=548330, confidence=0.992513, speaker='B', channel=None), UtteranceWord(text='especially', start=548650, end=549050, confidence=0.65625, speaker='B', channel=None), UtteranceWord(text='for', start=549130, end=549410, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=549410, end=549570, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='classification', start=549570, end=550250, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='tasks.', start=550250, end=550730, confidence=0.9633789, speaker='B', channel=None), UtteranceWord(text='And', start=550890, end=551290, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='they', start=551690, end=552090, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='actually', start=552330, end=552730, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='tell', start=552810, end=553090, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='you,', start=553090, end=553370, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='precision', start=553370, end=554010, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='tells', start=554010, end=554370, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='you', start=554370, end=554570, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='how', start=554570, end=554810, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='much,', start=554810, end=555130, confidence=0.9746094, speaker='B', channel=None), UtteranceWord(text='like', start=556000, end=556240, confidence=0.9838867, speaker='B', channel=None), UtteranceWord(text='how', start=556880, end=557200, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='much', start=557200, end=557520, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='correct', start=557760, end=558240, confidence=0.9998372, speaker='B', channel=None), UtteranceWord(text='answer', start=558240, end=558560, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='is.', start=558560, end=558760, confidence=0.75, speaker='B', channel=None), UtteranceWord(text='It', start=558760, end=559000, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='gives', start=559000, end=559320, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='for', start=559320, end=559480, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='the', start=559480, end=559600, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='answer', start=559600, end=559960, confidence=0.9930013, speaker='B', channel=None), UtteranceWord(text='which', start=559960, end=560120, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='were', start=560120, end=560280, confidence=0.95703125, speaker='B', channel=None), UtteranceWord(text='actually', start=560280, end=560520, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='correct.', start=560520, end=561040, confidence=0.9894206, speaker='B', channel=None), UtteranceWord(text='Correct.', start=561040, end=561560, confidence=0.8261719, speaker='B', channel=None), UtteranceWord(text='Right.', start=561560, end=561920, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='So', start=562000, end=562240, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='these', start=562240, end=562360, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='are', start=562360, end=562560, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='some', start=562560, end=562760, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='of', start=562760, end=562880, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=562880, end=563000, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='metrics', start=563000, end=563440, confidence=0.90999347, speaker='B', channel=None), UtteranceWord(text='that,', start=563440, end=563680, confidence=0.98046875, speaker='B', channel=None), UtteranceWord(text='that', start=563840, end=564120, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='I', start=564120, end=564280, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='would', start=564280, end=564440, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='use.', start=564440, end=564720, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='And', start=564800, end=565120, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='there', start=565120, end=565320, confidence=0.7089844, speaker='B', channel=None), UtteranceWord(text='are', start=565320, end=565520, confidence=0.9946289, speaker='B', channel=None), UtteranceWord(text='all', start=565520, end=565840, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='like.', start=565840, end=566160, confidence=0.98876953, speaker='B', channel=None), UtteranceWord(text='There', start=566160, end=566360, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='are', start=566360, end=566560, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='also', start=566560, end=566840, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='multiple', start=566840, end=567360, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='metrics,', start=567360, end=568000, confidence=0.88671875, speaker='B', channel=None), UtteranceWord(text='new', start=568080, end=568400, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='metrics', start=568400, end=568840, confidence=0.90625, speaker='B', channel=None), UtteranceWord(text='for', start=568840, end=569120, confidence=0.9355469, speaker='B', channel=None), UtteranceWord(text='multiple', start=569120, end=569760, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='applications.', start=570000, end=570720, confidence=0.99975586, speaker='B', channel=None), UtteranceWord(text='You', start=571200, end=571480, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='can', start=571480, end=571720, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='actually,', start=571720, end=572079, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='if', start=572640, end=572920, confidence=0.9770508, speaker='B', channel=None), UtteranceWord(text='I,', start=572920, end=573120, confidence=0.9868164, speaker='B', channel=None), UtteranceWord(text='if', start=573120, end=573320, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=573320, end=573680, confidence=0.9798177, speaker='B', channel=None), UtteranceWord(text='like,', start=573680, end=574000, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text='like', start=574560, end=574960, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='for', start=574960, end=575360, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='certain', start=575440, end=575840, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='applications,', start=575840, end=576560, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='I', start=576720, end=577000, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='can', start=577000, end=577200, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='also', start=577200, end=577520, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='like', start=578080, end=578480, confidence=0.99560547, speaker='B', channel=None), UtteranceWord(text='go', start=578560, end=578920, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='through', start=578920, end=579280, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='or', start=579920, end=580320, confidence=0.99316406, speaker='B', channel=None), UtteranceWord(text='custom,', start=580400, end=580800, confidence=0.9941406, speaker='B', channel=None), UtteranceWord(text='like', start=580880, end=581200, confidence=0.99853516, speaker='B', channel=None), UtteranceWord(text=\"I'll,\", start=581200, end=581600, confidence=0.8649089, speaker='B', channel=None), UtteranceWord(text=\"I'll\", start=581680, end=582160, confidence=0.7993164, speaker='B', channel=None), UtteranceWord(text='try', start=582240, end=582560, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='to', start=582560, end=582760, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='create', start=582760, end=583000, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='some', start=583000, end=583240, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='custom', start=583240, end=583520, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='matrix,', start=583520, end=584160, confidence=0.8922119, speaker='B', channel=None), UtteranceWord(text='like', start=584940, end=585180, confidence=0.81689453, speaker='B', channel=None), UtteranceWord(text='matrix,', start=585420, end=585980, confidence=0.9180908, speaker='B', channel=None), UtteranceWord(text='not', start=585980, end=586260, confidence=0.9482422, speaker='B', channel=None), UtteranceWord(text='like', start=586260, end=586620, confidence=0.95654297, speaker='B', channel=None), UtteranceWord(text='matrix', start=587020, end=587660, confidence=0.8586426, speaker='B', channel=None), UtteranceWord(text='on', start=588140, end=588420, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='which', start=588420, end=588620, confidence=1.0, speaker='B', channel=None), UtteranceWord(text=\"I'll\", start=588620, end=588900, confidence=0.96809894, speaker='B', channel=None), UtteranceWord(text='test', start=588900, end=589180, confidence=1.0, speaker='B', channel=None), UtteranceWord(text='the', start=589340, end=589740, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='system.', start=589740, end=590140, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='So', start=590540, end=590940, confidence=0.77685547, speaker='B', channel=None), UtteranceWord(text='it', start=591100, end=591380, confidence=0.99658203, speaker='B', channel=None), UtteranceWord(text='also', start=591380, end=591580, confidence=0.99365234, speaker='B', channel=None), UtteranceWord(text='highly', start=591580, end=591940, confidence=0.9980469, speaker='B', channel=None), UtteranceWord(text='depends', start=591940, end=592380, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='on', start=592380, end=592700, confidence=0.99902344, speaker='B', channel=None), UtteranceWord(text='what', start=592700, end=592900, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='type', start=592900, end=593100, confidence=0.9992676, speaker='B', channel=None), UtteranceWord(text='of', start=593100, end=593260, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='application', start=593260, end=593820, confidence=0.9650879, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=593820, end=594100, confidence=0.98502606, speaker='B', channel=None), UtteranceWord(text='working', start=594100, end=594300, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='with.', start=594300, end=594540, confidence=0.9970703, speaker='B', channel=None), UtteranceWord(text='Yeah.', start=594540, end=595020, confidence=0.83935547, speaker='B', channel=None), UtteranceWord(text='And', start=595180, end=595500, confidence=0.9951172, speaker='B', channel=None), UtteranceWord(text='what', start=595500, end=595700, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='type', start=595700, end=595900, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='of', start=595900, end=596060, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='model', start=596060, end=596420, confidence=1.0, speaker='B', channel=None), UtteranceWord(text=\"I'm\", start=596420, end=596620, confidence=0.9926758, speaker='B', channel=None), UtteranceWord(text='working', start=596620, end=596780, confidence=0.9995117, speaker='B', channel=None), UtteranceWord(text='with.', start=596780, end=597020, confidence=0.9975586, speaker='B', channel=None), UtteranceWord(text='Yeah.', start=597020, end=597500, confidence=0.85530597, speaker='B', channel=None)], translated_texts=None),\n",
       " Utterance(text=\"Absolutely. And that's a fantastic breakdown. You're spot on that the choice of evaluation metrics really depends on the type of problem you're tackling, whether it's regression, classification or something else. And it's great that you brought up things like the confusion matrix, precision, recall. Those are super critical in classification. And like you said, for regression you might go with something like RMSE or mae, but it all depends on what you're trying to measure and how you want to balance things like bias and variance. So yeah, that's a really solid approach.\", start=603740, end=631780, confidence=0.9703762, speaker='A', channel=None, words=[UtteranceWord(text='Absolutely.', start=603740, end=604460, confidence=0.98896486, speaker='A', channel=None), UtteranceWord(text='And', start=604460, end=604660, confidence=0.9897461, speaker='A', channel=None), UtteranceWord(text=\"that's\", start=604660, end=604940, confidence=0.99934894, speaker='A', channel=None), UtteranceWord(text='a', start=604940, end=605060, confidence=0.9970703, speaker='A', channel=None), UtteranceWord(text='fantastic', start=605060, end=605580, confidence=0.8828125, speaker='A', channel=None), UtteranceWord(text='breakdown.', start=605580, end=606140, confidence=0.99658203, speaker='A', channel=None), UtteranceWord(text=\"You're\", start=606460, end=606900, confidence=0.98307294, speaker='A', channel=None), UtteranceWord(text='spot', start=606900, end=607180, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='on', start=607180, end=607420, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='that', start=607420, end=607620, confidence=0.99365234, speaker='A', channel=None), UtteranceWord(text='the', start=607620, end=607780, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='choice', start=607780, end=608020, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='of', start=608020, end=608180, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='evaluation', start=608180, end=608700, confidence=0.9477539, speaker='A', channel=None), UtteranceWord(text='metrics', start=608700, end=609340, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='really', start=609340, end=609540, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='depends', start=609540, end=609900, confidence=0.99934894, speaker='A', channel=None), UtteranceWord(text='on', start=609900, end=610020, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='the', start=610020, end=610140, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='type', start=610140, end=610300, confidence=0.9953613, speaker='A', channel=None), UtteranceWord(text='of', start=610300, end=610420, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='problem', start=610420, end=610660, confidence=1.0, speaker='A', channel=None), UtteranceWord(text=\"you're\", start=610660, end=610940, confidence=0.9977214, speaker='A', channel=None), UtteranceWord(text='tackling,', start=610940, end=611340, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='whether', start=611780, end=611940, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text=\"it's\", start=611940, end=612260, confidence=0.99332684, speaker='A', channel=None), UtteranceWord(text='regression,', start=612260, end=612860, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='classification', start=612860, end=613660, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='or', start=613660, end=613980, confidence=0.53125, speaker='A', channel=None), UtteranceWord(text='something', start=613980, end=614300, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='else.', start=614300, end=614740, confidence=0.99975586, speaker='A', channel=None), UtteranceWord(text='And', start=614900, end=615180, confidence=0.77685547, speaker='A', channel=None), UtteranceWord(text=\"it's\", start=615180, end=615380, confidence=0.99609375, speaker='A', channel=None), UtteranceWord(text='great', start=615380, end=615500, confidence=0.9926758, speaker='A', channel=None), UtteranceWord(text='that', start=615500, end=615660, confidence=0.9970703, speaker='A', channel=None), UtteranceWord(text='you', start=615660, end=615780, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='brought', start=615780, end=615940, confidence=0.9996338, speaker='A', channel=None), UtteranceWord(text='up', start=615940, end=616100, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='things', start=616100, end=616300, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='like', start=616300, end=616460, confidence=0.99658203, speaker='A', channel=None), UtteranceWord(text='the', start=616460, end=616620, confidence=0.9970703, speaker='A', channel=None), UtteranceWord(text='confusion', start=616620, end=617100, confidence=0.99869794, speaker='A', channel=None), UtteranceWord(text='matrix,', start=617100, end=617580, confidence=0.9986572, speaker='A', channel=None), UtteranceWord(text='precision,', start=617580, end=618060, confidence=0.9996745, speaker='A', channel=None), UtteranceWord(text='recall.', start=618060, end=618620, confidence=0.9992676, speaker='A', channel=None), UtteranceWord(text='Those', start=618620, end=618860, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='are', start=618860, end=619060, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='super', start=619060, end=619300, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='critical', start=619300, end=619700, confidence=0.9975586, speaker='A', channel=None), UtteranceWord(text='in', start=619700, end=619900, confidence=0.90771484, speaker='A', channel=None), UtteranceWord(text='classification.', start=619900, end=620580, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='And', start=620900, end=621180, confidence=0.73095703, speaker='A', channel=None), UtteranceWord(text='like', start=621180, end=621340, confidence=0.9970703, speaker='A', channel=None), UtteranceWord(text='you', start=621340, end=621460, confidence=0.99658203, speaker='A', channel=None), UtteranceWord(text='said,', start=621460, end=621620, confidence=0.97216797, speaker='A', channel=None), UtteranceWord(text='for', start=621620, end=621820, confidence=0.9970703, speaker='A', channel=None), UtteranceWord(text='regression', start=621820, end=622340, confidence=0.79589844, speaker='A', channel=None), UtteranceWord(text='you', start=622340, end=622540, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='might', start=622540, end=622700, confidence=0.9951172, speaker='A', channel=None), UtteranceWord(text='go', start=622700, end=622860, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='with', start=622860, end=623020, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='something', start=623020, end=623180, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='like', start=623180, end=623380, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='RMSE', start=623380, end=624100, confidence=0.9654948, speaker='A', channel=None), UtteranceWord(text='or', start=624100, end=624300, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='mae,', start=624300, end=624820, confidence=0.9082031, speaker='A', channel=None), UtteranceWord(text='but', start=624820, end=625020, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='it', start=625020, end=625140, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='all', start=625140, end=625260, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='depends', start=625260, end=625660, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='on', start=625660, end=625900, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='what', start=625900, end=626140, confidence=1.0, speaker='A', channel=None), UtteranceWord(text=\"you're\", start=626140, end=626340, confidence=0.99593097, speaker='A', channel=None), UtteranceWord(text='trying', start=626340, end=626460, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='to', start=626460, end=626620, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='measure', start=626620, end=626980, confidence=1.0, speaker='A', channel=None), UtteranceWord(text='and', start=626980, end=627300, confidence=0.6513672, speaker='A', channel=None), UtteranceWord(text='how', start=627300, end=627539, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='you', start=627539, end=627739, confidence=0.9975586, speaker='A', channel=None), UtteranceWord(text='want', start=627739, end=627860, confidence=0.9511719, speaker='A', channel=None), UtteranceWord(text='to', start=627860, end=627940, confidence=0.99853516, speaker='A', channel=None), UtteranceWord(text='balance', start=627940, end=628220, confidence=0.9998372, speaker='A', channel=None), UtteranceWord(text='things', start=628220, end=628380, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='like', start=628380, end=628580, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='bias', start=628580, end=628860, confidence=0.9248047, speaker='A', channel=None), UtteranceWord(text='and', start=628860, end=629020, confidence=0.53027344, speaker='A', channel=None), UtteranceWord(text='variance.', start=629020, end=629620, confidence=0.97998047, speaker='A', channel=None), UtteranceWord(text='So', start=630100, end=630420, confidence=0.9238281, speaker='A', channel=None), UtteranceWord(text='yeah,', start=630420, end=630740, confidence=0.984375, speaker='A', channel=None), UtteranceWord(text=\"that's\", start=630740, end=630980, confidence=0.9980469, speaker='A', channel=None), UtteranceWord(text='a', start=630980, end=631060, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='really', start=631060, end=631180, confidence=0.99902344, speaker='A', channel=None), UtteranceWord(text='solid', start=631180, end=631500, confidence=0.9995117, speaker='A', channel=None), UtteranceWord(text='approach.', start=631500, end=631780, confidence=0.9995117, speaker='A', channel=None)], translated_texts=None)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript.utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "276cf3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>confidence</th>\n",
       "      <th>speaker</th>\n",
       "      <th>channel</th>\n",
       "      <th>words</th>\n",
       "      <th>translated_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alright, we're starting now, so welcome to the...</td>\n",
       "      <td>80</td>\n",
       "      <td>9680</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>[text='Alright,' start=80 end=280 confidence=0...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, so like right now I'm in third year of m...</td>\n",
       "      <td>11040</td>\n",
       "      <td>136520</td>\n",
       "      <td>0.975275</td>\n",
       "      <td>B</td>\n",
       "      <td>None</td>\n",
       "      <td>[text='Yeah,' start=11040 end=11600 confidence...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That's a great background and it's always awes...</td>\n",
       "      <td>139650</td>\n",
       "      <td>162370</td>\n",
       "      <td>0.977510</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>[text=\"That's\" start=139650 end=139890 confide...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeah, so handling or cleaning the data set is ...</td>\n",
       "      <td>163490</td>\n",
       "      <td>217580</td>\n",
       "      <td>0.963769</td>\n",
       "      <td>B</td>\n",
       "      <td>None</td>\n",
       "      <td>[text='Yeah,' start=163490 end=163930 confiden...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those are not always the right choices.</td>\n",
       "      <td>219100</td>\n",
       "      <td>221900</td>\n",
       "      <td>0.998930</td>\n",
       "      <td>B</td>\n",
       "      <td>None</td>\n",
       "      <td>[text='Those' start=219100 end=219500 confiden...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   start     end  \\\n",
       "0  Alright, we're starting now, so welcome to the...      80    9680   \n",
       "1  Yeah, so like right now I'm in third year of m...   11040  136520   \n",
       "2  That's a great background and it's always awes...  139650  162370   \n",
       "3  Yeah, so handling or cleaning the data set is ...  163490  217580   \n",
       "4            Those are not always the right choices.  219100  221900   \n",
       "\n",
       "   confidence speaker channel  \\\n",
       "0    0.988734       A    None   \n",
       "1    0.975275       B    None   \n",
       "2    0.977510       A    None   \n",
       "3    0.963769       B    None   \n",
       "4    0.998930       B    None   \n",
       "\n",
       "                                               words translated_texts  \n",
       "0  [text='Alright,' start=80 end=280 confidence=0...             None  \n",
       "1  [text='Yeah,' start=11040 end=11600 confidence...             None  \n",
       "2  [text=\"That's\" start=139650 end=139890 confide...             None  \n",
       "3  [text='Yeah,' start=163490 end=163930 confiden...             None  \n",
       "4  [text='Those' start=219100 end=219500 confiden...             None  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's convert this into a dataframe\n",
    "utt_data = []\n",
    "for utt in transcript.utterances:\n",
    "    row = {\n",
    "        'text': utt.text,\n",
    "        'start': utt.start,\n",
    "        'end': utt.end,\n",
    "        'confidence': utt.confidence,\n",
    "        'speaker': utt.speaker,\n",
    "        'channel': utt.channel,\n",
    "        'words': utt.words,\n",
    "        'translated_texts': utt.translated_texts\n",
    "    }\n",
    "    utt_data.append(row)\n",
    "    \n",
    "utt_data = pd.DataFrame(utt_data)\n",
    "utt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6f73b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_data.to_csv(\"../data/processed/utterances_data/Interview_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaaa6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
